This file is a merged representation of a subset of the codebase, containing specifically included files and files not matching ignore patterns, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: **/*.ml, **/*.mli
- Files matching these patterns are excluded: test/
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
bin/
  generate_test_data.ml
  high_performance_scheduler.ml
  hybrid_performance_test.ml
  main.ml
  native_performance_test.ml
  performance_tests_parallel.ml
  performance_tests.ml
  pragma_performance_test.ml
  scheduler_cli.ml
  visualizer_cli.ml
lib/
  db/
    database.ml
    database.mli
  domain/
    contact.ml
    types.ml
  rules/
    dsl.ml
    exclusion_window.ml
  scheduling/
    date_calc.ml
    email_scheduler.ml
    load_balancer.ml
  utils/
    audit_simple.ml
    config.ml
    date_time.ml
    simple_date.ml
    zip_data.ml
  visualizer/
    ast_analyzer.ml
    call_graph.ml
    doc_extractor.ml
    json_serializer.ml
  scheduler.ml
standalone_visualizer/
  visualizer_cli.ml

================================================================
Files
================================================================

================
File: bin/generate_test_data.ml
================
open Printf

(* Configuration for test data generation *)
let states = [|"CA"; "NY"; "TX"; "FL"; "IL"; "PA"; "OH"; "GA"; "NC"; "MI"; 
               "NJ"; "VA"; "WA"; "AZ"; "MA"; "TN"; "IN"; "MO"; "MD"; "WI";
               "CO"; "MN"; "SC"; "AL"; "LA"; "KY"; "OR"; "OK"; "CT"; "UT";
               "IA"; "NV"; "AR"; "MS"; "KS"; "NM"; "NE"; "WV"; "ID"; "HI";
               "NH"; "ME"; "MT"; "RI"; "DE"; "SD"; "ND"; "AK"; "VT"; "WY"|]

let carriers = [|"UnitedHealthcare"; "Anthem"; "Aetna"; "Cigna"; "Humana"; 
                 "Kaiser Permanente"; "Molina"; "Centene"; "Independence Blue Cross"|]

let plan_types = [|"HMO"; "PPO"; "EPO"; "POS"; "HDHP"|]

let first_names = [|"James"; "Mary"; "John"; "Patricia"; "Robert"; "Jennifer"; 
                    "Michael"; "Linda"; "William"; "Elizabeth"; "David"; "Barbara";
                    "Richard"; "Susan"; "Joseph"; "Jessica"; "Thomas"; "Sarah";
                    "Charles"; "Karen"; "Christopher"; "Lisa"; "Daniel"; "Nancy";
                    "Matthew"; "Betty"; "Anthony"; "Helen"; "Mark"; "Sandra"|]

let last_names = [|"Smith"; "Johnson"; "Williams"; "Brown"; "Jones"; "Garcia";
                   "Miller"; "Davis"; "Rodriguez"; "Martinez"; "Hernandez"; "Lopez";
                   "Gonzalez"; "Wilson"; "Anderson"; "Thomas"; "Taylor"; "Moore";
                   "Jackson"; "Martin"; "Lee"; "Perez"; "Thompson"; "White";
                   "Harris"; "Sanchez"; "Clark"; "Ramirez"; "Lewis"; "Robinson"|]

(* Random generators *)
let random_from_array arr = arr.(Random.int (Array.length arr))

let random_date_between start_year end_year =
  let year = start_year + Random.int (end_year - start_year + 1) in
  let month = 1 + Random.int 12 in
  let day = 1 + Random.int 28 in  (* Keep it simple, avoid Feb 29 issues *)
  Printf.sprintf "%04d-%02d-%02d" year month day

let random_email first last batch_start index =
  let providers = [|"gmail.com"; "yahoo.com"; "hotmail.com"; "aol.com"; "outlook.com"|] in
  let provider = random_from_array providers in
  let unique_id = batch_start + index in
  let timestamp = int_of_float (Unix.time ()) in
  Printf.sprintf "%s.%s.%d.%d@%s" 
    (String.lowercase_ascii first) 
    (String.lowercase_ascii last) 
    unique_id timestamp provider

let random_zip_code state =
  (* Generate realistic zip codes for states (simplified) *)
  match state with
  | "CA" -> Printf.sprintf "9%04d" (Random.int 10000)
  | "NY" -> Printf.sprintf "1%04d" (Random.int 10000)
  | "TX" -> Printf.sprintf "7%04d" (Random.int 10000)
  | "FL" -> Printf.sprintf "3%04d" (Random.int 10000)
  | _ -> Printf.sprintf "%05d" (10000 + Random.int 90000)

let random_phone () =
  Printf.sprintf "(%03d) %03d-%04d" 
    (200 + Random.int 800) 
    (200 + Random.int 800) 
    (Random.int 10000)

(* Create database schema *)
let create_schema db =
  (* Write schema to temporary file *)
  let temp_file = "/tmp/schema.sql" in
  let oc = open_out temp_file in
  output_string oc "CREATE TABLE IF NOT EXISTS contacts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    first_name TEXT NOT NULL,
    last_name TEXT NOT NULL,
    email TEXT NOT NULL UNIQUE,
    current_carrier TEXT NOT NULL,
    plan_type TEXT NOT NULL,
    effective_date TEXT NOT NULL,
    birth_date TEXT NOT NULL,
    tobacco_user INTEGER NOT NULL,
    gender TEXT NOT NULL,
    state TEXT NOT NULL,
    zip_code TEXT NOT NULL,
    agent_id INTEGER,
    last_emailed DATETIME,
    phone_number TEXT NOT NULL DEFAULT '',
    status TEXT NOT NULL DEFAULT 'active',
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
  );

  CREATE TABLE IF NOT EXISTS email_schedules (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    contact_id INTEGER NOT NULL,
    email_type TEXT NOT NULL,
    scheduled_send_date TEXT NOT NULL,
    scheduled_send_time TEXT NOT NULL DEFAULT '08:30:00',
    status TEXT NOT NULL DEFAULT 'scheduled',
    skip_reason TEXT,
    created_at TEXT NOT NULL DEFAULT (datetime('now')),
    updated_at TEXT NOT NULL DEFAULT (datetime('now')),
    batch_id TEXT,
    event_year INTEGER,
    event_month INTEGER,
    event_day INTEGER,
    catchup_note TEXT,
    sent_at TEXT,
    sendgrid_message_id TEXT,
    sms_sent_at TEXT,
    twilio_sms_id TEXT,
    actual_send_datetime TEXT,
    priority INTEGER DEFAULT 10,
    campaign_instance_id INTEGER,
    email_template TEXT,
    sms_template TEXT,
    scheduler_run_id TEXT,
    metadata TEXT,
    FOREIGN KEY (contact_id) REFERENCES contacts(id) ON DELETE CASCADE
  );

  CREATE INDEX IF NOT EXISTS idx_contacts_birth_date ON contacts(birth_date);
  CREATE INDEX IF NOT EXISTS idx_contacts_effective_date ON contacts(effective_date);
  CREATE INDEX IF NOT EXISTS idx_contacts_state ON contacts(state);
  CREATE INDEX IF NOT EXISTS idx_email_schedules_date_time_status ON email_schedules(scheduled_send_date, scheduled_send_time, status);
  CREATE UNIQUE INDEX IF NOT EXISTS idx_email_schedules_unique ON email_schedules(contact_id, email_type, scheduled_send_date);
  CREATE INDEX IF NOT EXISTS idx_email_schedules_org_contact ON email_schedules(contact_id);
  CREATE INDEX IF NOT EXISTS idx_email_schedules_org_send_date ON email_schedules(scheduled_send_date);
  CREATE INDEX IF NOT EXISTS idx_email_schedules_status ON email_schedules(status);
  CREATE UNIQUE INDEX IF NOT EXISTS idx_email_schedules_unique_event ON email_schedules(contact_id, email_type, event_year);
  CREATE INDEX IF NOT EXISTS idx_email_schedules_event_date ON email_schedules(event_year, event_month, event_day);
  CREATE INDEX IF NOT EXISTS idx_schedules_lookup ON email_schedules(contact_id, email_type, scheduled_send_date);
  CREATE INDEX IF NOT EXISTS idx_schedules_status_date ON email_schedules(status, scheduled_send_date);
  CREATE INDEX IF NOT EXISTS idx_schedules_run_id ON email_schedules(scheduler_run_id);
  
  CREATE TRIGGER IF NOT EXISTS update_email_schedules_updated_at
  AFTER UPDATE ON email_schedules
  FOR EACH ROW
  BEGIN
      UPDATE email_schedules
      SET updated_at = CURRENT_TIMESTAMP
      WHERE id = OLD.id;
  END;
  ";
  close_out oc;
  
  let cmd = Printf.sprintf "sqlite3 %s < %s" db temp_file in
  let exit_code = Sys.command cmd in
  let _ = Sys.command ("rm " ^ temp_file) in
  if exit_code <> 0 then
    failwith ("Failed to create schema in " ^ db)

(* Helper function to convert contact data to string array for prepared statement *)
let contact_to_values first_name last_name email carrier plan_type effective_date birth_date tobacco_user gender state zip_code agent_id phone =
  [|
    first_name; last_name; email; carrier; plan_type; effective_date; birth_date;
    string_of_int tobacco_user; gender; state; zip_code; string_of_int agent_id; phone; "active"
  |]

(* Fixed batch generation using prepared statements instead of huge SQL strings *)
let generate_contacts_batch_fixed db start_id count =
  printf "Generating contacts batch %d-%d using prepared statements...\n%!" start_id (start_id + count - 1);
  
  (* Set database path for the Database module *)
  Scheduler.Db.Database.set_db_path db;
  
  (* Prepare contact data *)
  let contacts_data = ref [] in
  
  for i = 0 to count - 1 do
    let first_name = random_from_array first_names in
    let last_name = random_from_array last_names in
    let email = random_email first_name last_name start_id i in
    let carrier = random_from_array carriers in
    let plan_type = random_from_array plan_types in
    let state = random_from_array states in
    let zip_code = random_zip_code state in
    let phone = random_phone () in
    let birth_date = random_date_between 1940 2005 in
    let effective_date = random_date_between 2020 2024 in
    let tobacco_user = Random.int 2 in
    let gender = if Random.bool () then "M" else "F" in
    let agent_id = 1 + Random.int 50 in
    
    let values = contact_to_values first_name last_name email carrier plan_type 
                   effective_date birth_date tobacco_user gender state zip_code agent_id phone in
    contacts_data := values :: !contacts_data;
  done;
  
  (* Use the existing batch_insert_with_prepared_statement function *)
  let insert_sql = "INSERT INTO contacts (first_name, last_name, email, current_carrier, plan_type, effective_date, birth_date, tobacco_user, gender, state, zip_code, agent_id, phone_number, status) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)" in
  
  match Scheduler.Db.Database.batch_insert_with_prepared_statement insert_sql (List.rev !contacts_data) with
  | Ok inserted_count ->
      printf "✅ Successfully inserted %d contacts\n%!" inserted_count
  | Error err ->
      failwith ("Failed to insert contacts batch: " ^ Scheduler.Db.Database.string_of_db_error err)

(* Generate batch of contacts - keeping the old version for fallback *)
let generate_contacts_batch db start_id count =
  printf "Generating contacts batch %d-%d...\n%!" start_id (start_id + count - 1);
  
  let contacts = Buffer.create (count * 200) in
  Buffer.add_string contacts "BEGIN TRANSACTION;\n";
  
  for i = 0 to count - 1 do
    let first_name = random_from_array first_names in
    let last_name = random_from_array last_names in
    let email = random_email first_name last_name start_id i in
    let carrier = random_from_array carriers in
    let plan_type = random_from_array plan_types in
    let state = random_from_array states in
    let zip_code = random_zip_code state in
    let phone = random_phone () in
    let birth_date = random_date_between 1940 2005 in
    let effective_date = random_date_between 2020 2024 in
    let tobacco_user = Random.int 2 in
    let gender = if Random.bool () then "M" else "F" in
    let agent_id = 1 + Random.int 50 in
    
    let sql = Printf.sprintf 
      "INSERT INTO contacts (first_name, last_name, email, current_carrier, plan_type, effective_date, birth_date, tobacco_user, gender, state, zip_code, agent_id, phone_number, status) VALUES ('%s', '%s', '%s', '%s', '%s', '%s', '%s', %d, '%s', '%s', '%s', %d, '%s', 'active');\n"
      (String.escaped first_name) (String.escaped last_name) (String.escaped email)
      (String.escaped carrier) (String.escaped plan_type) effective_date birth_date
      tobacco_user gender state zip_code agent_id phone in
    
    Buffer.add_string contacts sql;
  done;
  
  Buffer.add_string contacts "COMMIT;\n";
  
  (* Write to temporary file and execute *)
  let temp_file = Printf.sprintf "/tmp/contacts_batch_%d.sql" start_id in
  let oc = open_out temp_file in
  output_string oc (Buffer.contents contacts);
  close_out oc;
  
  let cmd = Printf.sprintf "sqlite3 %s < %s" db temp_file in
  let exit_code = Sys.command cmd in
  let _ = Sys.command ("rm " ^ temp_file) in
  
  if exit_code <> 0 then
    failwith ("Failed to insert contacts batch starting at " ^ string_of_int start_id)

(* Generate large dataset with fixed batch insertion *)
let generate_dataset db_name total_contacts batch_size use_prepared_statements =
  printf "🚀 Generating %d contacts in database: %s\n" total_contacts db_name;
  printf "Using batch size: %d contacts per batch\n" batch_size;
  printf "Method: %s\n\n" (if use_prepared_statements then "Prepared statements (FIXED)" else "SQL strings (legacy)");
  
  (* Initialize random seed *)
  Random.self_init ();
  
  (* Remove existing database *)
  if Sys.file_exists db_name then
    Sys.remove db_name;
  
  (* Create schema *)
  printf "📋 Creating database schema...\n";
  create_schema db_name;
  
  (* Generate contacts in batches *)
  let batches = (total_contacts + batch_size - 1) / batch_size in
  printf "📊 Generating %d batches of contacts...\n\n" batches;
  
  let start_time = Unix.time () in
  
  for batch = 0 to batches - 1 do
    let start_id = batch * batch_size + 1 in
    let remaining = total_contacts - batch * batch_size in
    let current_batch_size = min batch_size remaining in
    
    if current_batch_size > 0 then (
      let batch_start = Unix.time () in
      
      (* Use the new fixed method or fall back to legacy *)
      if use_prepared_statements then
        generate_contacts_batch_fixed db_name start_id current_batch_size
      else
        generate_contacts_batch db_name start_id current_batch_size;
        
      let batch_time = Unix.time () -. batch_start in
      
      printf "   Batch %d/%d completed in %.2f seconds (%.0f contacts/second)\n%!" 
        (batch + 1) batches batch_time (float_of_int current_batch_size /. batch_time);
    )
  done;
  
  let total_time = Unix.time () -. start_time in
  
  printf "\n✅ Database generation complete!\n";
  printf "📈 Performance Summary:\n";
  printf "   • Total contacts: %d\n" total_contacts;
  printf "   • Generation time: %.2f seconds\n" total_time;
  printf "   • Average throughput: %.0f contacts/second\n" (float_of_int total_contacts /. total_time);
  
  (* Verify the database *)
  printf "\n🔍 Verifying database...\n";
  let cmd = Printf.sprintf "sqlite3 %s \"SELECT COUNT(*) FROM contacts;\"" db_name in
  let exit_code = Sys.command cmd in
  if exit_code = 0 then
    printf "✅ Database verification successful!\n"
  else
    printf "❌ Database verification failed!\n"

(* Generate realistic distribution based on golden dataset *)
let analyze_golden_dataset () =
  if not (Sys.file_exists "golden_dataset.sqlite3") then (
    printf "❌ golden_dataset.sqlite3 not found\n";
    exit 1
  );
  
  printf "📊 Analyzing golden dataset for realistic patterns...\n\n";
  
  (* Analyze state distribution *)
  let cmd = "sqlite3 golden_dataset.sqlite3 \"SELECT state, COUNT(*) as count FROM contacts GROUP BY state ORDER BY count DESC LIMIT 10;\"" in
  printf "🗺️  Top 10 states by contact count:\n";
  let _ = Sys.command cmd in
  
  (* Analyze birth date distribution *)
  printf "\n📅 Birth date year distribution:\n";
  let cmd2 = "sqlite3 golden_dataset.sqlite3 \"SELECT substr(birth_date, 1, 4) as year, COUNT(*) as count FROM contacts GROUP BY year ORDER BY count DESC LIMIT 10;\"" in
  let _ = Sys.command cmd2 in
  
  (* Analyze effective date distribution *)
  printf "\n📋 Effective date distribution:\n";
  let cmd3 = "sqlite3 golden_dataset.sqlite3 \"SELECT substr(effective_date, 1, 7) as month, COUNT(*) as count FROM contacts GROUP BY month ORDER BY month DESC LIMIT 10;\"" in
  let _ = Sys.command cmd3 in
  
  printf "\n✅ Golden dataset analysis complete!\n"

let main () =
  let argc = Array.length Sys.argv in
  if argc < 2 then (
    printf "Usage: %s <command> [args]\n" Sys.argv.(0);
    printf "Commands:\n";
    printf "  generate <db_name> <count> [batch_size] [--use-prepared]  - Generate test database\n";
    printf "  analyze                                                   - Analyze golden dataset patterns\n";
    printf "\nExamples:\n";
    printf "  %s generate large_test_dataset.sqlite3 25000 1000 --use-prepared\n" Sys.argv.(0);
    printf "  %s generate huge_test_dataset.sqlite3 100000 2000\n" Sys.argv.(0);
    printf "  %s analyze\n" Sys.argv.(0);
    exit 1
  );
  
  let command = Sys.argv.(1) in
  match command with
  | "generate" when argc >= 4 ->
      let db_name = Sys.argv.(2) in
      let count = int_of_string Sys.argv.(3) in
      
      (* Check for --use-prepared flag in remaining arguments *)
      let use_prepared = 
        let remaining_args = Array.sub Sys.argv 4 (argc - 4) in
        Array.exists (fun arg -> arg = "--use-prepared") remaining_args
      in
      
      (* Parse batch_size from remaining non-flag arguments *)
      let batch_size = 
        if argc >= 5 && Sys.argv.(4) <> "--use-prepared" then
          int_of_string Sys.argv.(4)
        else
          1000
      in
      
      generate_dataset db_name count batch_size use_prepared
  | "analyze" ->
      analyze_golden_dataset ()
  | _ ->
      printf "Invalid command or arguments\n";
      exit 1

(* Entry point *)
let () = main ()

================
File: bin/high_performance_scheduler.ml
================
open Scheduler.Email_scheduler
open Scheduler.Db.Database

(* High-performance scheduler implementing Python's query-driven approach *)

(* Simple wrapper to schedule emails for a contact *)
let schedule_contact_emails contact scheduler_run_id =
  let config = Scheduler.Config.default in
  let context = create_context config 1000 in  (* Use default total contacts *)
  let context_with_run_id = { context with run_id = scheduler_run_id } in
  match calculate_schedules_for_contact context_with_run_id contact with
  | Ok schedules -> schedules
  | Error _err -> []  (* On error, return empty list *)

let run_high_performance_scheduler db_path =
  Printf.printf "=== High-Performance OCaml Email Scheduler ===\n\n";
  
  (* Set database path *)
  set_db_path db_path;
  
  (* Initialize database with proper error handling *)
  match initialize_database () with
  | Error err -> 
      Printf.printf "❌ Database initialization failed: %s\n" (string_of_db_error err);
      exit 1
  | Ok () ->
      Printf.printf "✅ Database connected successfully\n";
      
      (* Load ZIP data *)
      let _ = Scheduler.Zip_data.ensure_loaded () in
      Printf.printf "✅ ZIP data loaded\n";
      
      (* Generate run_id for this scheduling run *)
      let scheduler_run_id = 
        let now = Unix.time () in
        let tm = Unix.localtime now in
        Printf.sprintf "run_%04d%02d%02d_%02d%02d%02d" 
          (tm.tm_year + 1900) (tm.tm_mon + 1) tm.tm_mday 
          tm.tm_hour tm.tm_min tm.tm_sec
      in
      Printf.printf "🆔 Generated scheduler run ID: %s\n" scheduler_run_id;
      
      (* PERFORMANCE OPTIMIZATION: Use query-driven contact fetching *)
      Printf.printf "📊 Loading contacts using query-driven approach...\n";
      let lookahead_days = 60 in  (* Look ahead 2 months *)
      let lookback_days = 14 in   (* Look back 2 weeks for catch-up *)
      
      match get_contacts_in_scheduling_window lookahead_days lookback_days with
      | Error err ->
          Printf.printf "❌ Failed to load contacts: %s\n" (string_of_db_error err);
          exit 1
      | Ok relevant_contacts ->
          let contact_count = List.length relevant_contacts in
          Printf.printf "   Found %d contacts with anniversaries in scheduling window\n" contact_count;
          Printf.printf "   (This is a massive performance improvement over loading all %s contacts)\n" 
            (match get_total_contact_count () with 
             | Ok total -> string_of_int total 
             | Error _ -> "unknown");
          
          if contact_count = 0 then (
            Printf.printf "✅ No contacts need scheduling at this time\n";
            exit 0
          );
          
          (* Generate scheduler run ID *)
          let scheduler_run_id = "hiperf_" ^ string_of_float (Unix.time ()) in
          Printf.printf "📋 Scheduler run ID: %s\n\n" scheduler_run_id;
          
          (* Process contacts and generate schedules *)
          Printf.printf "⚡ Processing contacts with high-performance engine...\n";
          let all_schedules = ref [] in
          let scheduled_count = ref 0 in
          let skipped_count = ref 0 in
          
          (* Process each contact using the sophisticated business logic *)
          List.iter (fun contact ->
            let contact_schedules = schedule_contact_emails contact scheduler_run_id in
            all_schedules := contact_schedules @ !all_schedules;
            
            (* Count schedules vs skips - simplified counting *)
            let schedule_count = List.length contact_schedules in
            scheduled_count := !scheduled_count + schedule_count;
            
          ) relevant_contacts;
          
          Printf.printf "   Generated %d total schedules (%d to send, %d skipped)\n" 
            (List.length !all_schedules) !scheduled_count !skipped_count;
          
          (* Apply load balancing and smoothing *)
          Printf.printf "⚖️  Applying load balancing and smoothing...\n";
          let total_contacts_for_lb = match get_total_contact_count () with
            | Ok count -> count
            | Error _ -> 1000  (* fallback *)
          in
          let lb_config = Scheduler.Load_balancer.default_config total_contacts_for_lb in
          (match Scheduler.Load_balancer.distribute_schedules !all_schedules lb_config with
           | Ok balanced_schedules ->
               Printf.printf "   Load balancing complete\n";
               
               (* NEW: Smart update approach - preserves scheduler_run_id when content unchanged *)
               Printf.printf "🧠 Using smart update to minimize diff size...\n";
               (match update_email_schedules ~use_smart_update:true balanced_schedules scheduler_run_id with
                | Ok changes ->
                    Printf.printf "   Smart update completed: %d schedules processed\n" changes;
                    Printf.printf "✅ High-performance scheduling complete!\n\n";
                    
                    (* Display summary statistics *)
                    Printf.printf "📈 Performance Summary:\n";
                    Printf.printf "   • Query-driven filtering: %d/%s contacts processed (major speedup)\n" 
                      contact_count 
                      (match get_total_contact_count () with Ok total -> string_of_int total | Error _ -> "?");
                    Printf.printf "   • Smart diff optimization: Preserves scheduler_run_id when content unchanged\n";
                    Printf.printf "   • Minimal database writes: Only updates rows that actually changed\n";
                    Printf.printf "   • Turso sync-friendly: Dramatically reduces diff file size\n";
                    Printf.printf "   • Type-safe error handling: All operations checked at compile time\n";
                    Printf.printf "   • State exclusion rules: Applied with mathematical precision\n";
                    Printf.printf "   • Load balancing: Sophisticated smoothing algorithms applied\n";
                    
                | Error err ->
                    Printf.printf "❌ Failed to insert schedules: %s\n" (string_of_db_error err))
           | Error (Scheduler.Types.LoadBalancingError msg) ->
               Printf.printf "❌ Load balancing failed: %s\n" msg
           | Error err ->
               Printf.printf "❌ Load balancing failed: %s\n" (Scheduler.Types.string_of_error err))

let run_performance_demo db_path =
  Printf.printf "=== Performance Comparison Demo ===\n\n";
  
  set_db_path db_path;
  
  match initialize_database () with
  | Error err -> 
      Printf.printf "❌ Database initialization failed: %s\n" (string_of_db_error err)
  | Ok () ->
      (* Demonstrate the performance difference *)
      
      Printf.printf "🐌 OLD APPROACH: Get all contacts first...\n";
      let start_time = Unix.time () in
      (match get_all_contacts () with
       | Ok all_contacts -> 
           let old_time = Unix.time () -. start_time in
           Printf.printf "   Loaded %d contacts in %.3f seconds\n" (List.length all_contacts) old_time;
           
           Printf.printf "\n⚡ NEW APPROACH: Query-driven pre-filtering...\n";
           let start_time2 = Unix.time () in
           (match get_contacts_in_scheduling_window 60 14 with
            | Ok relevant_contacts ->
                let new_time = Unix.time () -. start_time2 in
                Printf.printf "   Loaded %d relevant contacts in %.3f seconds\n" 
                  (List.length relevant_contacts) new_time;
                Printf.printf "\n🚀 PERFORMANCE IMPROVEMENT:\n";
                Printf.printf "   • Data reduction: %d → %d contacts (%.1f%% reduction)\n"
                  (List.length all_contacts) (List.length relevant_contacts)
                  (100.0 *. (1.0 -. float_of_int (List.length relevant_contacts) /. float_of_int (List.length all_contacts)));
                Printf.printf "   • Speed improvement: %.1fx faster\n" (old_time /. new_time);
                Printf.printf "   • Memory usage: %.1fx less data in memory\n"
                  (float_of_int (List.length all_contacts) /. float_of_int (List.length relevant_contacts));
            | Error err ->
                Printf.printf "   Error: %s\n" (string_of_db_error err))
       | Error err ->
           Printf.printf "   Error: %s\n" (string_of_db_error err))

let main () =
  let argc = Array.length Sys.argv in
  if argc < 2 then (
    Printf.printf "Usage: %s <database_path> [--demo]\n" Sys.argv.(0);
    Printf.printf "  --demo: Run performance comparison demo\n";
    exit 1
  );
  
  let db_path = Sys.argv.(1) in
  let is_demo = argc >= 3 && Sys.argv.(2) = "--demo" in
  
  if is_demo then
    run_performance_demo db_path
  else
    run_high_performance_scheduler db_path

(* Entry point *)
let () = main ()

================
File: bin/hybrid_performance_test.ml
================
open Scheduler.Email_scheduler
open Scheduler.Db.Database

(* Performance measurement utilities with high precision *)
let time_it f =
  let start_time = Unix.gettimeofday () in
  let result = f () in
  let end_time = Unix.gettimeofday () in
  (result, end_time -. start_time)

let measure_memory_usage () =
  let gc_stats = Gc.stat () in
  (int_of_float gc_stats.major_words, int_of_float gc_stats.minor_words, gc_stats.top_heap_words)

(* Progress logging with thread safety *)
let log_mutex = Mutex.create ()
let log_progress message =
  Mutex.lock log_mutex;
  let timestamp = Unix.time () |> Unix.localtime in
  Printf.printf "[%02d:%02d:%02d] %s\n%!" 
    timestamp.tm_hour timestamp.tm_min timestamp.tm_sec message;
  Mutex.unlock log_mutex

(* Parallel schedule generation - optimal threading *)
let parallel_generate_schedules contacts scheduler_run_id contact_count =
  let num_threads = min 4 (max 1 (contact_count / 1000)) in  (* Optimal thread count *)
  let chunk_size = (List.length contacts + num_threads - 1) / num_threads in
  
  log_progress (Printf.sprintf "🧵 Parallelizing schedule generation: %d threads, ~%d contacts each" 
    num_threads chunk_size);
  
  (* Split contacts into chunks *)
  let rec chunk_list lst size =
    match lst with
    | [] -> []
    | _ ->
        let rec take n acc = function
          | [] -> (List.rev acc, [])
          | x :: xs when n > 0 -> take (n-1) (x::acc) xs
          | xs -> (List.rev acc, xs)
        in
        let (chunk, rest) = take size [] lst in
        chunk :: chunk_list rest size
  in
  
  let chunks = chunk_list contacts chunk_size in
  let results = Array.make (List.length chunks) [] in
  let threads = ref [] in
  
  (* Process each chunk in a separate thread *)
  List.iteri (fun i chunk ->
    let thread = Thread.create (fun () ->
      let thread_id = i + 1 in
      
      let thread_schedules = ref [] in
      List.iter (fun contact ->
        let config = Scheduler.Config.default in
        let context = create_context config contact_count in
        let context_with_run_id = { context with run_id = scheduler_run_id } in
        match calculate_schedules_for_contact context_with_run_id contact with
        | Ok contact_schedules -> thread_schedules := contact_schedules @ !thread_schedules
        | Error _ -> ()
      ) chunk;
      
      log_progress (Printf.sprintf "   Thread %d completed: %d schedules" 
        thread_id (List.length !thread_schedules));
      results.(i) <- !thread_schedules;
    ) () in
    threads := thread :: !threads
  ) chunks;
  
  (* Wait for all threads to complete *)
  List.iter Thread.join (List.rev !threads);
  
  (* Combine results *)
  let all_schedules = Array.fold_left (fun acc schedules -> schedules @ acc) [] results in
  log_progress (Printf.sprintf "✅ Parallel generation complete: %d total schedules" (List.length all_schedules));
  all_schedules

(* Sequential database insertion with optimizations *)
let sequential_insert_schedules schedules =
  log_progress "💾 Sequential database insertion with WAL optimizations...";
  batch_insert_schedules_optimized schedules

(* Hybrid performance test - best of both worlds *)
let run_hybrid_performance_test db_path test_name =
  log_progress (Printf.sprintf "🚀 Starting hybrid performance test: %s" test_name);
  log_progress "=================================================";
  log_progress "Strategy: Parallel schedule generation + Sequential database insertion";
  
  set_db_path db_path;
  
  match initialize_database () with
  | Error err -> 
      log_progress (Printf.sprintf "❌ Database initialization failed: %s" (string_of_db_error err));
      (0, 0.0, 0, 0)
  | Ok () ->
      (* Measure contact loading *)
      log_progress "📊 Loading contacts...";
      let (contacts_result, load_time) = time_it (fun () ->
        get_contacts_in_scheduling_window 60 14
      ) in
      
      match contacts_result with
      | Error err ->
          log_progress (Printf.sprintf "❌ Contact loading failed: %s" (string_of_db_error err));
          (0, load_time, 0, 0)
      | Ok contacts ->
          let contact_count = List.length contacts in
          log_progress (Printf.sprintf "   Loaded %d contacts in %.3f seconds" contact_count load_time);
          
          if contact_count = 0 then (
            log_progress "   No contacts need scheduling";
            (0, load_time, 0, 0)
          ) else (
            (* Measure memory before scheduling *)
            let (major_before, minor_before, _heap_before) = measure_memory_usage () in
            
            (* PARALLEL: Schedule generation *)
            log_progress "⚡ Generating schedules (parallel threads)...";
            let scheduler_run_id = Printf.sprintf "hybrid_test_%s_%f" test_name (Unix.time ()) in
            
            let (all_schedules, schedule_time) = time_it (fun () ->
              parallel_generate_schedules contacts scheduler_run_id contact_count
            ) in
            
            let schedule_count = List.length all_schedules in
            log_progress (Printf.sprintf "   Generated %d schedules in %.3f seconds" schedule_count schedule_time);
            log_progress (Printf.sprintf "   Throughput: %.0f schedules/second" 
              (float_of_int schedule_count /. schedule_time));
            
            (* Measure memory after scheduling *)
            let (major_after, minor_after, _heap_after) = measure_memory_usage () in
            let memory_used = (major_after - major_before) + (minor_after - minor_before) in
            log_progress (Printf.sprintf "   Memory used: %d words (%.1f MB)" 
              memory_used (float_of_int memory_used *. 8.0 /. 1024.0 /. 1024.0));
            
            (* Load balancing *)
            log_progress "⚖️  Applying load balancing...";
            let total_contacts = match get_total_contact_count () with
              | Ok count -> count
              | Error _ -> contact_count
            in
            let lb_config = Scheduler.Load_balancer.default_config total_contacts in
            let (lb_result, lb_time) = time_it (fun () ->
              Scheduler.Load_balancer.distribute_schedules all_schedules lb_config
            ) in
            
            match lb_result with
            | Error err ->
                log_progress (Printf.sprintf "❌ Load balancing failed: %s" (Scheduler.Types.string_of_error err));
                (contact_count, load_time +. schedule_time, schedule_count, 0)
            | Ok balanced_schedules ->
                log_progress (Printf.sprintf "   Load balancing completed in %.3f seconds" lb_time);
                
                (* SEQUENTIAL: Database insertion with optimizations *)
                log_progress "💾 Inserting schedules (sequential with WAL)...";
                let (insert_result, insert_time) = time_it (fun () ->
                  sequential_insert_schedules balanced_schedules
                ) in
                
                match insert_result with
                | Error err ->
                    log_progress (Printf.sprintf "❌ Database insertion failed: %s" (string_of_db_error err));
                    (contact_count, load_time +. schedule_time +. lb_time, schedule_count, 0)
                | Ok inserted_count ->
                    log_progress (Printf.sprintf "   Inserted %d schedules in %.3f seconds" inserted_count insert_time);
                    log_progress (Printf.sprintf "   Throughput: %.0f inserts/second" 
                      (float_of_int inserted_count /. insert_time));
                    
                    let total_time = load_time +. schedule_time +. lb_time +. insert_time in
                    log_progress "";
                    log_progress "📈 HYBRID PERFORMANCE SUMMARY:";
                    log_progress "===============================";
                    log_progress (Printf.sprintf "   • Total time: %.3f seconds" total_time);
                    log_progress (Printf.sprintf "   • Contacts processed: %d" contact_count);
                    log_progress (Printf.sprintf "   • Schedules generated: %d" schedule_count);
                    log_progress (Printf.sprintf "   • Schedules inserted: %d" inserted_count);
                    log_progress (Printf.sprintf "   • Overall throughput: %.0f contacts/second" 
                      (float_of_int contact_count /. total_time));
                    log_progress (Printf.sprintf "   • Memory efficiency: %.1f KB per contact" 
                      (float_of_int memory_used *. 8.0 /. 1024.0 /. float_of_int contact_count));
                    log_progress "";
                    log_progress "🧠 OPTIMIZATION BREAKDOWN:";
                    log_progress (Printf.sprintf "   • Schedule generation: PARALLEL (%.1fx faster potential)" 
                      (float_of_int (min 4 (contact_count / 1000))));
                    log_progress "   • Database insertion: SEQUENTIAL + WAL (optimal for SQLite)";
                    log_progress "   • Result: Best of both worlds! 🎉";
                    
                    (contact_count, total_time, schedule_count, inserted_count)
          )

let main () =
  let argc = Array.length Sys.argv in
  if argc < 3 then (
    Printf.printf "Usage: %s <database_path> <test_name>\n" Sys.argv.(0);
    Printf.printf "Example: %s massive_test_dataset.sqlite3 \"500k Hybrid Test\"\n" Sys.argv.(0);
    exit 1
  );
  
  let db_path = Sys.argv.(1) in
  let test_name = Sys.argv.(2) in
  
  let _ = run_hybrid_performance_test db_path test_name in
  ()

let () = main ()

================
File: bin/main.ml
================
open Scheduler.Types
open Scheduler.Date_time
open Scheduler.Contact
open Scheduler.Email_scheduler
open Scheduler.Load_balancer

let create_sample_contact id email zip birthday_year birthday_month birthday_day ed_year ed_month ed_day =
  let birthday = if birthday_year > 0 then Some (birthday_year, birthday_month, birthday_day) else None in
  let effective_date = if ed_year > 0 then Some (ed_year, ed_month, ed_day) else None in
  let contact = {
    id;
    email;
    zip_code = Some zip;
    state = None;
    birthday;
    effective_date;
    carrier = None;
    failed_underwriting = false;
  } in
  update_contact_state contact

let demo_comprehensive_scheduling () =
  Printf.printf "=== Advanced Email Scheduler Demo ===\n\n";
  
  let _ = Scheduler.Zip_data.load_zip_data () in
  
  let contacts = [
    create_sample_contact 1 "alice@example.com" "90210" 1990 6 15 2020 1 1;  (* CA contact *)
    create_sample_contact 2 "bob@example.com" "10001" 1985 12 25 2019 3 15;  (* NY contact *)
    create_sample_contact 3 "charlie@example.com" "06830" 1992 2 29 2021 2 1; (* CT contact *)
    create_sample_contact 4 "diana@example.com" "89101" 1988 3 10 2020 7 1;   (* NV contact *)
    create_sample_contact 5 "eve@example.com" "63101" 1995 8 22 2022 6 1;     (* MO contact *)
    create_sample_contact 6 "frank@example.com" "97201" 1987 11 5 0 0 0;      (* OR contact, no ED *)
  ] in
  
  Printf.printf "📊 Processing %d contacts...\n\n" (List.length contacts);
  
  (* Skip detailed validation for now - type issue to debug later *)
  
  let config = Scheduler.Config.default in
  let total_contacts = List.length contacts in
  
  match schedule_emails_streaming ~contacts ~config ~total_contacts with
  | Ok result ->
      Printf.printf "✅ Scheduling completed successfully!\n\n";
      
      Printf.printf "%s\n\n" (get_scheduling_summary result);
      
      let analysis = analyze_distribution result.schedules in
      Printf.printf "📈 Load Balancing Analysis:\n";
      Printf.printf "  - Distribution variance: %d emails\n" analysis.distribution_variance;
      Printf.printf "  - Peak day: %d emails\n" analysis.max_day;
      Printf.printf "  - Average per day: %.1f emails\n\n" analysis.avg_per_day;
      
      Printf.printf "📅 Scheduled Email Summary:\n";
      let schedule_counts = Hashtbl.create 10 in
      List.iter (fun schedule ->
        let date_str = string_of_date schedule.scheduled_date in
        let current_count = match Hashtbl.find_opt schedule_counts date_str with
          | Some count -> count
          | None -> 0
        in
        Hashtbl.replace schedule_counts date_str (current_count + 1)
      ) result.schedules;
      
      Hashtbl.iter (fun date count ->
        Printf.printf "  %s: %d emails\n" date count
      ) schedule_counts;
      
      Printf.printf "\n🎯 Email Type Breakdown:\n";
      let type_counts = Hashtbl.create 10 in
      List.iter (fun schedule ->
        let type_str = string_of_email_type schedule.email_type in
        let current_count = match Hashtbl.find_opt type_counts type_str with
          | Some count -> count
          | None -> 0
        in
        Hashtbl.replace type_counts type_str (current_count + 1)
      ) result.schedules;
      
      Hashtbl.iter (fun email_type count ->
        Printf.printf "  %s: %d\n" email_type count
      ) type_counts;
      
      if result.errors <> [] then (
        Printf.printf "\n⚠️  Errors encountered:\n";
        List.iter (fun error ->
          Printf.printf "  - %s\n" (string_of_error error)
        ) result.errors
      );
      
  | Error error ->
      Printf.printf "❌ Scheduling failed: %s\n" (string_of_error error);
  
  Printf.printf "\n🎉 Advanced demo completed!\n"

let () = demo_comprehensive_scheduling ()

================
File: bin/native_performance_test.ml
================
open Scheduler.Email_scheduler
open Scheduler.Db.Database

(* Performance measurement utilities *)
let time_it f =
  let start_time = Unix.time () in
  let result = f () in
  let end_time = Unix.time () in
  (result, end_time -. start_time)

let measure_memory_usage () =
  let gc_stats = Gc.stat () in
  (int_of_float gc_stats.major_words, int_of_float gc_stats.minor_words, gc_stats.top_heap_words)

(* Progress logging *)
let log_progress message =
  let timestamp = Unix.time () |> Unix.localtime in
  Printf.printf "[%02d:%02d:%02d] %s\n%!" 
    timestamp.tm_hour timestamp.tm_min timestamp.tm_sec message

(* Native SQLite performance test *)
let run_native_performance_test db_path test_name =
  log_progress (Printf.sprintf "🚀 Starting NATIVE SQLite performance test: %s" test_name);
  log_progress "==================================================";
  log_progress "🔥 Using NATIVE sqlite3-ocaml bindings (NO SHELL COMMANDS!)";
  
  set_db_path db_path;
  
  match initialize_database () with
  | Error err -> 
      log_progress (Printf.sprintf "❌ Database initialization failed: %s" (string_of_db_error err));
      (0, 0.0, 0, 0)
  | Ok () ->
      (* Measure contact loading *)
      log_progress "📊 Loading contacts with native SQLite...";
      let (contacts_result, load_time) = time_it (fun () ->
        get_contacts_in_scheduling_window 60 14
      ) in
      
      match contacts_result with
      | Error err ->
          log_progress (Printf.sprintf "❌ Contact loading failed: %s" (string_of_db_error err));
          (0, load_time, 0, 0)
      | Ok contacts ->
          let contact_count = List.length contacts in
          log_progress (Printf.sprintf "   Loaded %d contacts in %.3f seconds" contact_count load_time);
          log_progress (Printf.sprintf "   Throughput: %.0f contacts/second" 
            (float_of_int contact_count /. load_time));
          
          if contact_count = 0 then (
            log_progress "   No contacts need scheduling";
            (0, load_time, 0, 0)
          ) else (
            (* Measure memory before scheduling *)
            let (major_before, minor_before, _heap_before) = measure_memory_usage () in
            
            (* Schedule generation *)
            log_progress "⚡ Generating schedules...";
            let scheduler_run_id = Printf.sprintf "native_test_%s_%f" test_name (Unix.time ()) in
            
            let (all_schedules, schedule_time) = time_it (fun () ->
              let schedule_contact contact =
                let config = Scheduler.Config.default in
                let context = create_context config contact_count in
                let context_with_run_id = { context with run_id = scheduler_run_id } in
                match calculate_schedules_for_contact context_with_run_id contact with
                | Ok contact_schedules -> contact_schedules
                | Error _ -> []
              in
              List.fold_left (fun acc contact -> 
                (schedule_contact contact) @ acc
              ) [] contacts
            ) in
            
            let schedule_count = List.length all_schedules in
            log_progress (Printf.sprintf "   Generated %d schedules in %.3f seconds" schedule_count schedule_time);
            log_progress (Printf.sprintf "   Throughput: %.0f schedules/second" 
              (float_of_int schedule_count /. schedule_time));
            
            (* Measure memory after scheduling *)
            let (major_after, minor_after, _heap_after) = measure_memory_usage () in
            let memory_used = (major_after - major_before) + (minor_after - minor_before) in
            log_progress (Printf.sprintf "   Memory used: %d words (%.1f MB)" 
              memory_used (float_of_int memory_used *. 8.0 /. 1024.0 /. 1024.0));
            
            (* Load balancing *)
            log_progress "⚖️  Applying load balancing...";
            let total_contacts = match get_total_contact_count () with
              | Ok count -> count
              | Error _ -> contact_count
            in
            let lb_config = Scheduler.Load_balancer.default_config total_contacts in
            let (lb_result, lb_time) = time_it (fun () ->
              Scheduler.Load_balancer.distribute_schedules all_schedules lb_config
            ) in
            
            match lb_result with
            | Error err ->
                log_progress (Printf.sprintf "❌ Load balancing failed: %s" (Scheduler.Types.string_of_error err));
                (contact_count, load_time +. schedule_time, schedule_count, 0)
            | Ok balanced_schedules ->
                log_progress (Printf.sprintf "   Load balancing completed in %.3f seconds" lb_time);
                
                (* NATIVE database insertion with prepared statements *)
                log_progress "💾 Inserting schedules with NATIVE SQLite + prepared statements...";
                let (insert_result, insert_time) = time_it (fun () ->
                  batch_insert_schedules_optimized balanced_schedules
                ) in
                
                match insert_result with
                | Error err ->
                    log_progress (Printf.sprintf "❌ Database insertion failed: %s" (string_of_db_error err));
                    (contact_count, load_time +. schedule_time +. lb_time, schedule_count, 0)
                | Ok inserted_count ->
                    log_progress (Printf.sprintf "   Inserted %d schedules in %.3f seconds" inserted_count insert_time);
                    log_progress (Printf.sprintf "   NATIVE Throughput: %.0f inserts/second" 
                      (float_of_int inserted_count /. insert_time));
                    
                    let total_time = load_time +. schedule_time +. lb_time +. insert_time in
                    log_progress "";
                    log_progress "📈 NATIVE SQLITE PERFORMANCE SUMMARY:";
                    log_progress "====================================";
                    log_progress (Printf.sprintf "   • Total time: %.3f seconds" total_time);
                    log_progress (Printf.sprintf "   • Contacts processed: %d" contact_count);
                    log_progress (Printf.sprintf "   • Schedules generated: %d" schedule_count);
                    log_progress (Printf.sprintf "   • Schedules inserted: %d" inserted_count);
                    log_progress (Printf.sprintf "   • Overall throughput: %.0f contacts/second" 
                      (float_of_int contact_count /. total_time));
                    log_progress (Printf.sprintf "   • Memory efficiency: %.1f KB per contact" 
                      (float_of_int memory_used *. 8.0 /. 1024.0 /. float_of_int contact_count));
                    log_progress "";
                    log_progress "🔥 NATIVE ADVANTAGES:";
                    log_progress "   • Persistent database connection (no process spawning)";
                    log_progress "   • Prepared statements (no SQL parsing overhead)";
                    log_progress "   • Direct C bindings (no shell command overhead)";
                    log_progress "   • Native data types (no string conversion)";
                    
                    (* Close database connection *)
                    close_database ();
                    
                    (contact_count, total_time, schedule_count, inserted_count)
          )

let main () =
  let argc = Array.length Sys.argv in
  if argc < 3 then (
    Printf.printf "Usage: %s <database_path> <test_name>\n" Sys.argv.(0);
    Printf.printf "Example: %s golden_dataset.sqlite3 \"Golden Native Test\"\n" Sys.argv.(0);
    exit 1
  );
  
  let db_path = Sys.argv.(1) in
  let test_name = Sys.argv.(2) in
  
  let _ = run_native_performance_test db_path test_name in
  ()

let () = main ()

================
File: bin/performance_tests_parallel.ml
================
open Scheduler.Email_scheduler
open Scheduler.Db.Database

(* Performance measurement utilities *)
let time_it f =
  let start_time = Unix.time () in
  let result = f () in
  let end_time = Unix.time () in
  (result, end_time -. start_time)

let measure_memory_usage () =
  let gc_stats = Gc.stat () in
  (int_of_float gc_stats.major_words, int_of_float gc_stats.minor_words, gc_stats.top_heap_words)

(* Progress logging *)
let log_progress message =
  let timestamp = Unix.time () |> Unix.localtime in
  Printf.printf "[%02d:%02d:%02d] %s\n%!" 
    timestamp.tm_hour timestamp.tm_min timestamp.tm_sec message

(* Parallel processing using threading *)
let parallel_map_chunks chunk_size f lst =
  let chunks = 
    let rec chunk acc current_chunk remaining =
      match remaining with
      | [] -> if current_chunk = [] then acc else current_chunk :: acc
      | x :: xs ->
          if List.length current_chunk >= chunk_size then
            chunk (current_chunk :: acc) [x] xs
          else
            chunk acc (x :: current_chunk) xs
    in
    chunk [] [] lst |> List.rev
  in
  
  log_progress (Printf.sprintf "Processing %d items in %d chunks of %d" 
    (List.length lst) (List.length chunks) chunk_size);
  
  (* Process chunks in parallel using threads *)
  let process_chunk chunk_id chunk =
    log_progress (Printf.sprintf "Processing chunk %d/%d (%d items)" 
      (chunk_id + 1) (List.length chunks) (List.length chunk));
    let results = List.map f chunk in
    log_progress (Printf.sprintf "Completed chunk %d/%d" (chunk_id + 1) (List.length chunks));
    results
  in
  
  (* For now, let's use sequential processing with better logging *)
  (* TODO: Add proper threading with Domain.spawn in OCaml 5.0+ *)
  List.mapi process_chunk chunks |> List.flatten

(* High-performance scheduler run with parallel processing *)
let run_parallel_scheduler_with_metrics db_path test_name =
  log_progress (Printf.sprintf "=== %s ===" test_name);
  
  set_db_path db_path;
  
  match initialize_database () with
  | Error err -> 
      log_progress (Printf.sprintf "❌ Database initialization failed: %s" (string_of_db_error err));
      (0, 0.0, 0, 0)
  | Ok () ->
      log_progress "✅ Database connected successfully";
      let _ = Scheduler.Zip_data.ensure_loaded () in
      log_progress "✅ ZIP data loaded";
      
      (* Measure contact loading performance *)
      log_progress "📊 Loading contacts with window filtering...";
      let (contacts_result, load_time) = time_it (fun () ->
        get_contacts_in_scheduling_window 60 14
      ) in
      
      match contacts_result with
      | Error err ->
          log_progress (Printf.sprintf "❌ Failed to load contacts: %s" (string_of_db_error err));
          (0, 0.0, 0, 0)
      | Ok contacts ->
          let contact_count = List.length contacts in
          log_progress (Printf.sprintf "   Loaded %d contacts in %.3f seconds (%.0f contacts/second)" 
            contact_count load_time (float_of_int contact_count /. load_time));
          
          if contact_count = 0 then (
            log_progress "   No contacts need scheduling";
            (0, load_time, 0, 0)
          ) else (
            (* Measure memory before scheduling *)
            let (major_before, minor_before, _heap_before) = measure_memory_usage () in
            log_progress (Printf.sprintf "📊 Memory before processing: %d words (%.1f MB)" 
              (major_before + minor_before) 
              (float_of_int (major_before + minor_before) *. 8.0 /. 1024.0 /. 1024.0));
            
            (* Parallel schedule generation *)
            log_progress "⚡ Generating schedules in parallel...";
            let scheduler_run_id = Printf.sprintf "parallel_test_%s_%f" test_name (Unix.time ()) in
            
            (* Determine optimal chunk size based on contact count *)
            let chunk_size = 
              if contact_count > 50000 then 1000      (* Large datasets: 1k chunks *)
              else if contact_count > 10000 then 500  (* Medium datasets: 500 chunks *)
              else 100                                 (* Small datasets: 100 chunks *)
            in
            
            let (all_schedules, schedule_time) = time_it (fun () ->
              let schedule_contact contact =
                let config = Scheduler.Config.default in
                let context = create_context config contact_count in
                let context_with_run_id = { context with run_id = scheduler_run_id } in
                match calculate_schedules_for_contact context_with_run_id contact with
                | Ok contact_schedules -> contact_schedules
                | Error _ -> []
              in
              
              parallel_map_chunks chunk_size schedule_contact contacts |> List.flatten
            ) in
            
            let schedule_count = List.length all_schedules in
            log_progress (Printf.sprintf "   Generated %d schedules in %.3f seconds (%.0f schedules/second)" 
              schedule_count schedule_time (float_of_int schedule_count /. schedule_time));
            
            (* Measure memory after scheduling *)
            let (major_after, minor_after, _heap_after) = measure_memory_usage () in
            let memory_used = (major_after - major_before) + (minor_after - minor_before) in
            log_progress (Printf.sprintf "📊 Memory used for processing: %d words (%.1f MB)" 
              memory_used (float_of_int memory_used *. 8.0 /. 1024.0 /. 1024.0));
            
            (* Measure load balancing performance *)
            log_progress "⚖️  Applying load balancing...";
            let total_contacts = match get_total_contact_count () with
              | Ok count -> count
              | Error _ -> contact_count
            in
            let lb_config = Scheduler.Load_balancer.default_config total_contacts in
            let (lb_result, lb_time) = time_it (fun () ->
              Scheduler.Load_balancer.distribute_schedules all_schedules lb_config
            ) in
            
            match lb_result with
            | Error err ->
                log_progress (Printf.sprintf "❌ Load balancing failed: %s" (Scheduler.Types.string_of_error err));
                (contact_count, load_time +. schedule_time, schedule_count, 0)
            | Ok balanced_schedules ->
                log_progress (Printf.sprintf "   Load balancing completed in %.3f seconds" lb_time);
                
                (* High-performance database insertion with large chunks *)
                log_progress "💾 Inserting schedules with optimized batching...";
                let large_chunk_size = 
                  if schedule_count > 100000 then 1000  (* Very large: 1000 per chunk - optimal balance *)
                  else if schedule_count > 10000 then 1000   (* Large: 1000 per chunk *)
                  else 500                                   (* Standard: 500 per chunk *)
                in
                
                log_progress (Printf.sprintf "   Using chunk size: %d schedules per batch" large_chunk_size);
                
                let (insert_result, insert_time) = time_it (fun () ->
                  let total_chunks = (schedule_count + large_chunk_size - 1) / large_chunk_size in
                  log_progress (Printf.sprintf "   Processing %d schedules in %d chunks" 
                    schedule_count total_chunks);
                  
                  (* Custom chunked insertion with progress logging *)
                  let rec insert_chunks chunks_remaining inserted_so_far chunk_num =
                    match chunks_remaining with
                    | [] -> inserted_so_far
                    | chunk :: rest ->
                        if chunk_num mod 10 = 0 then
                          log_progress (Printf.sprintf "   Inserting chunk %d/%d (%d schedules inserted so far)" 
                            chunk_num total_chunks inserted_so_far);
                        
                        match batch_insert_schedules_chunked chunk large_chunk_size with
                        | Ok count -> insert_chunks rest (inserted_so_far + count) (chunk_num + 1)
                        | Error _ -> inserted_so_far
                  in
                  
                  (* Split schedules into chunks *)
                  let rec split_into_chunks lst chunk_size =
                    let rec take n acc = function
                      | [] -> (List.rev acc, [])
                      | x :: xs when n > 0 -> take (n-1) (x::acc) xs
                      | xs -> (List.rev acc, xs)
                    in
                    match lst with
                    | [] -> []
                    | _ -> 
                        let (chunk, rest) = take chunk_size [] lst in
                        chunk :: split_into_chunks rest chunk_size
                  in
                  
                  let chunks = split_into_chunks balanced_schedules large_chunk_size in
                  insert_chunks chunks 0 1
                ) in
                
                match insert_result with
                | 0 ->
                    log_progress "❌ Database insertion failed";
                    (contact_count, load_time +. schedule_time +. lb_time, schedule_count, 0)
                | inserted_count ->
                    log_progress (Printf.sprintf "   Inserted %d schedules in %.3f seconds (%.0f inserts/second)" 
                      inserted_count insert_time (float_of_int inserted_count /. insert_time));
                    
                    let total_time = load_time +. schedule_time +. lb_time +. insert_time in
                    log_progress "\n📈 Performance Summary:";
                    log_progress (Printf.sprintf "   • Total time: %.3f seconds" total_time);
                    log_progress (Printf.sprintf "   • Contacts processed: %d" contact_count);
                    log_progress (Printf.sprintf "   • Schedules generated: %d" schedule_count);
                    log_progress (Printf.sprintf "   • Schedules inserted: %d" inserted_count);
                    log_progress (Printf.sprintf "   • Overall throughput: %.0f contacts/second" 
                      (float_of_int contact_count /. total_time));
                    log_progress (Printf.sprintf "   • Memory efficiency: %.1f KB per contact" 
                      (float_of_int memory_used *. 8.0 /. 1024.0 /. float_of_int contact_count));
                    
                    (contact_count, total_time, schedule_count, inserted_count)
          )

(* Fast performance test for massive datasets *)
let run_massive_performance_test db_path =
  log_progress "🚀 High-Performance Massive Dataset Test";
  log_progress "========================================";
  
  let (contacts, time, schedules, inserts) = 
    run_parallel_scheduler_with_metrics db_path "Massive Dataset Performance Test" in
  
  log_progress "\n🎯 Final Results:";
  log_progress (Printf.sprintf "✅ Processed %d contacts in %.2f seconds" contacts time);
  log_progress (Printf.sprintf "✅ Generated %d schedules" schedules);
  log_progress (Printf.sprintf "✅ Inserted %d schedules" inserts);
  log_progress (Printf.sprintf "✅ Achieved %.0f contacts/second throughput" 
    (if time > 0.0 then float_of_int contacts /. time else 0.0));
  
  log_progress "\n🏆 Performance test complete!"

let main () =
  let argc = Array.length Sys.argv in
  if argc < 2 then (
    Printf.printf "Usage: %s <command> [database_path]\n" Sys.argv.(0);
    Printf.printf "Commands:\n";
    Printf.printf "  massive <db_path>   - High-performance test for large datasets\n";
    Printf.printf "  single <db_path>    - Single database test with detailed logging\n";
    exit 1
  );
  
  let command = Sys.argv.(1) in
  match command with
  | "massive" when argc >= 3 ->
      let db_path = Sys.argv.(2) in
      run_massive_performance_test db_path
  | "single" when argc >= 3 -> 
      let db_path = Sys.argv.(2) in
      let _ = run_parallel_scheduler_with_metrics db_path "Single Database Test" in
      ()
  | _ ->
      Printf.printf "Invalid command or missing database path\n";
      exit 1

(* Entry point *)
let () = main ()

================
File: bin/performance_tests.ml
================
open Scheduler.Email_scheduler
open Scheduler.Db.Database

(* Performance measurement utilities *)
let time_it f =
  let start_time = Unix.time () in
  let result = f () in
  let end_time = Unix.time () in
  (result, end_time -. start_time)

let measure_memory_usage () =
  let gc_stats = Gc.stat () in
  (int_of_float gc_stats.major_words, int_of_float gc_stats.minor_words, gc_stats.top_heap_words)

(* Scheduler run with performance measurement *)
let run_scheduler_with_metrics db_path test_name =
  Printf.printf "\n=== %s ===\n" test_name;
  
  set_db_path db_path;
  
  match initialize_database () with
  | Error err -> 
      Printf.printf "❌ Database initialization failed: %s\n" (string_of_db_error err);
      (0, 0.0, 0, 0)
  | Ok () ->
      let _ = Scheduler.Zip_data.ensure_loaded () in
      
      (* Measure contact loading performance *)
      Printf.printf "📊 Loading contacts...\n";
      let (contacts_result, load_time) = time_it (fun () ->
        get_contacts_in_scheduling_window 60 14
      ) in
      
      match contacts_result with
      | Error err ->
          Printf.printf "❌ Failed to load contacts: %s\n" (string_of_db_error err);
          (0, 0.0, 0, 0)
      | Ok contacts ->
          let contact_count = List.length contacts in
          Printf.printf "   Loaded %d contacts in %.3f seconds\n" contact_count load_time;
          Printf.printf "   Throughput: %.0f contacts/second\n" (float_of_int contact_count /. load_time);
          
          if contact_count = 0 then (
            Printf.printf "   No contacts need scheduling\n";
            (0, load_time, 0, 0)
          ) else (
            (* Measure memory before scheduling *)
            let (major_before, minor_before, _heap_before) = measure_memory_usage () in
            
            (* Measure scheduling performance *)
            Printf.printf "⚡ Generating schedules...\n";
            let scheduler_run_id = Printf.sprintf "perf_test_%s_%f" test_name (Unix.time ()) in
            
            let (all_schedules, schedule_time) = time_it (fun () ->
              let schedules = ref [] in
              List.iter (fun contact ->
                let config = Scheduler.Config.default in
                let context = create_context config contact_count in
                let context_with_run_id = { context with run_id = scheduler_run_id } in
                match calculate_schedules_for_contact context_with_run_id contact with
                | Ok contact_schedules -> schedules := contact_schedules @ !schedules
                | Error _ -> ()
              ) contacts;
              !schedules
            ) in
            
            let schedule_count = List.length all_schedules in
            Printf.printf "   Generated %d schedules in %.3f seconds\n" schedule_count schedule_time;
            Printf.printf "   Throughput: %.0f schedules/second\n" (float_of_int schedule_count /. schedule_time);
            
            (* Measure memory after scheduling *)
            let (major_after, minor_after, _heap_after) = measure_memory_usage () in
            let memory_used = (major_after - major_before) + (minor_after - minor_before) in
            Printf.printf "   Memory used: %d words (%.1f MB)\n" memory_used 
              (float_of_int memory_used *. 8.0 /. 1024.0 /. 1024.0);
            
            (* Measure load balancing performance *)
            Printf.printf "⚖️  Load balancing...\n";
            let total_contacts = match get_total_contact_count () with
              | Ok count -> count
              | Error _ -> contact_count
            in
            let lb_config = Scheduler.Load_balancer.default_config total_contacts in
            let (lb_result, lb_time) = time_it (fun () ->
              Scheduler.Load_balancer.distribute_schedules all_schedules lb_config
            ) in
            
            match lb_result with
            | Error err ->
                Printf.printf "❌ Load balancing failed: %s\n" (Scheduler.Types.string_of_error err);
                (contact_count, load_time +. schedule_time, schedule_count, 0)
            | Ok balanced_schedules ->
                Printf.printf "   Load balancing completed in %.3f seconds\n" lb_time;
                
                (* Measure database insertion performance *)
                Printf.printf "💾 Inserting schedules...\n";
                let (insert_result, insert_time) = time_it (fun () ->
                  (* Use optimized batch insertion for large datasets *)
                  if schedule_count > 1000 then
                    batch_insert_schedules_optimized balanced_schedules
                  else
                    batch_insert_schedules_chunked balanced_schedules 500
                ) in
                
                match insert_result with
                | Error err ->
                    Printf.printf "❌ Database insertion failed: %s\n" (string_of_db_error err);
                    (contact_count, load_time +. schedule_time +. lb_time, schedule_count, 0)
                | Ok inserted_count ->
                    Printf.printf "   Inserted %d schedules in %.3f seconds\n" inserted_count insert_time;
                    Printf.printf "   Throughput: %.0f inserts/second\n" (float_of_int inserted_count /. insert_time);
                    
                    let total_time = load_time +. schedule_time +. lb_time +. insert_time in
                    Printf.printf "\n📈 Performance Summary:\n";
                    Printf.printf "   • Total time: %.3f seconds\n" total_time;
                    Printf.printf "   • Contacts processed: %d\n" contact_count;
                    Printf.printf "   • Schedules generated: %d\n" schedule_count;
                    Printf.printf "   • Schedules inserted: %d\n" inserted_count;
                    Printf.printf "   • Overall throughput: %.0f contacts/second\n" (float_of_int contact_count /. total_time);
                    Printf.printf "   • Memory efficiency: %.1f KB per contact\n" 
                      (float_of_int memory_used *. 8.0 /. 1024.0 /. float_of_int contact_count);
                    
                    (contact_count, total_time, schedule_count, inserted_count)
          )

(* Test with different dataset sizes *)
let run_performance_suite () =
  Printf.printf "🚀 OCaml Email Scheduler Performance Test Suite\n";
  Printf.printf "==============================================\n";
  
  let results = ref [] in
  
  (* Test 1: Small dataset (original org-206.sqlite3) *)
  if Sys.file_exists "org-206.sqlite3" then (
    let (contacts1, time1, schedules1, inserts1) = 
      run_scheduler_with_metrics "org-206.sqlite3" "Small Dataset (org-206)" in
    results := ("Small Dataset", contacts1, time1, schedules1, inserts1) :: !results
  );
  
  (* Test 2: Golden dataset (~25k contacts) *)
  if Sys.file_exists "golden_dataset.sqlite3" then (
    let (contacts2, time2, schedules2, inserts2) = 
      run_scheduler_with_metrics "golden_dataset.sqlite3" "Golden Dataset (~25k contacts)" in
    results := ("Golden Dataset", contacts2, time2, schedules2, inserts2) :: !results
  );
  
  (* Test 3: Generated large dataset (if exists) *)
  if Sys.file_exists "large_test_dataset.sqlite3" then (
    let (contacts3, time3, schedules3, inserts3) = 
      run_scheduler_with_metrics "large_test_dataset.sqlite3" "Large Generated Dataset" in
    results := ("Large Generated", contacts3, time3, schedules3, inserts3) :: !results
  );
  
  (* Test 4: Massive dataset (500k contacts) - if exists *)
  if Sys.file_exists "massive_test_dataset.sqlite3" then (
    let (contacts4, time4, schedules4, inserts4) = 
      run_scheduler_with_metrics "massive_test_dataset.sqlite3" "Massive Dataset (500k)" in
    results := ("Massive Dataset", contacts4, time4, schedules4, inserts4) :: !results
  );
  
  (* Performance comparison report *)
  Printf.printf "\n\n🏆 PERFORMANCE COMPARISON REPORT\n";
  Printf.printf "=================================\n";
  Printf.printf "%-20s | %-10s | %-10s | %-12s | %-12s | %-15s\n" 
    "Dataset" "Contacts" "Time (s)" "Schedules" "Inserts" "Throughput (c/s)";
  Printf.printf "%s\n" (String.make 95 '-');
  
  List.rev !results |> List.iter (fun (name, contacts, time, schedules, inserts) ->
    let throughput = if time > 0.0 then float_of_int contacts /. time else 0.0 in
    Printf.printf "%-20s | %-10d | %-10.3f | %-12d | %-12d | %-15.0f\n" 
      name contacts time schedules inserts throughput
  );
  
  Printf.printf "\n✅ Performance testing complete!\n"

(* Scalability stress test *)
let run_scalability_test db_path =
  Printf.printf "\n🔥 SCALABILITY STRESS TEST\n";
  Printf.printf "==========================\n";
  
  set_db_path db_path;
  
  match initialize_database () with
  | Error err -> 
      Printf.printf "❌ Database initialization failed: %s\n" (string_of_db_error err)
  | Ok () ->
      (* Test with increasing window sizes *)
      let window_sizes = [30; 60; 90; 120; 180; 365] in
      
      Printf.printf "Testing scheduler with different lookahead windows:\n\n";
      
      List.iter (fun window_days ->
        Printf.printf "📊 Testing %d-day window...\n" window_days;
        
        let (contacts_result, time) = time_it (fun () ->
          get_contacts_in_scheduling_window window_days 14
        ) in
        
        match contacts_result with
        | Error err ->
            Printf.printf "   ❌ Error: %s\n" (string_of_db_error err)
        | Ok contacts ->
            let contact_count = List.length contacts in
            Printf.printf "   Found %d contacts in %.3f seconds (%.0f contacts/second)\n" 
              contact_count time (float_of_int contact_count /. time);
            
            (* Memory measurement *)
            let (major, minor, _heap) = measure_memory_usage () in
            Printf.printf "   Memory usage: %d words (%.1f MB)\n" 
              (major + minor) (float_of_int (major + minor) *. 8.0 /. 1024.0 /. 1024.0);
      ) window_sizes;
      
      Printf.printf "\n✅ Scalability test complete!\n"

let main () =
  let argc = Array.length Sys.argv in
  if argc < 2 then (
    Printf.printf "Usage: %s <command> [database_path]\n" Sys.argv.(0);
    Printf.printf "Commands:\n";
    Printf.printf "  suite               - Run full performance test suite\n";
    Printf.printf "  single <db_path>    - Test single database\n";
    Printf.printf "  scalability <db_path> - Run scalability stress test\n";
    exit 1
  );
  
  let command = Sys.argv.(1) in
  match command with
  | "suite" -> run_performance_suite ()
  | "single" when argc >= 3 -> 
      let db_path = Sys.argv.(2) in
      let _ = run_scheduler_with_metrics db_path "Single Database Test" in
      ()
  | "scalability" when argc >= 3 ->
      let db_path = Sys.argv.(2) in
      run_scalability_test db_path
  | _ ->
      Printf.printf "Invalid command or missing database path\n";
      exit 1

(* Entry point *)
let () = main ()

================
File: bin/pragma_performance_test.ml
================
open Scheduler.Db.Database

let test_pragma_and_chunk_combinations () =
  Printf.printf "🚀 PRAGMA & Chunk Size Performance Test\n";
  Printf.printf "========================================\n";
  
  set_db_path "golden_dataset.sqlite3";
  
  match initialize_database () with
  | Error err -> 
      Printf.printf "❌ Database initialization failed: %s\n" (string_of_db_error err)
  | Ok () ->
      let test_count = 15000 in
      
      let journal_modes = [
        ("DELETE", "PRAGMA journal_mode = DELETE");
        ("MEMORY", "PRAGMA journal_mode = MEMORY");
        ("WAL", "PRAGMA journal_mode = WAL");
      ] in
      
      let chunk_sizes = [500; 1000; 2000; 5000] in
      
      List.iter (fun (mode_name, journal_pragma) ->
        Printf.printf "\n🔧 Testing Journal Mode: %s\n" mode_name;
        Printf.printf "================================\n";
        
        (* Apply journal mode *)
        let _ = execute_sql_safe journal_pragma in
        let _ = execute_sql_safe "PRAGMA synchronous = OFF" in
        let _ = execute_sql_safe "PRAGMA cache_size = 50000" in
        
        List.iter (fun chunk_size ->
          Printf.printf "\n📊 Chunk size: %d\n" chunk_size;
          
          (* Clear test data *)
          let test_id = Printf.sprintf "%s_%d" mode_name chunk_size in
          let _ = execute_sql_safe (Printf.sprintf "DELETE FROM email_schedules WHERE batch_id = 'test_%s'" test_id) in
          
          let start_time = Unix.time () in
          
          (* Insert in chunks *)
          let total_chunks = (test_count + chunk_size - 1) / chunk_size in
          let inserted = ref 0 in
          
          for i = 0 to total_chunks - 1 do
            let start_idx = i * chunk_size in
            let end_idx = min (start_idx + chunk_size) test_count in
            let current_chunk_size = end_idx - start_idx in
            
            if current_chunk_size > 0 then (
              (* Build multi-VALUES statement *)
              let values_list = ref [] in
              for j = start_idx to end_idx - 1 do
                let value_tuple = Printf.sprintf "(%d, 'test_%s', 2025, 6, %d, '2025-12-25', '09:00:00', 'pre-scheduled', '', 'test_%s')"
                  (3000000 + j) test_id (1 + (j mod 30)) test_id in
                values_list := value_tuple :: !values_list
              done;
              
              let batch_sql = Printf.sprintf {|
                INSERT INTO email_schedules (
                  contact_id, email_type, event_year, event_month, event_day,
                  scheduled_send_date, scheduled_send_time, status, skip_reason, batch_id
                ) VALUES %s
              |} (String.concat ", " (List.rev !values_list)) in
              
              match execute_sql_safe batch_sql with
              | Ok _ -> inserted := !inserted + current_chunk_size
              | Error err -> 
                  Printf.printf "❌ Batch failed: %s\n" (string_of_db_error err);
            )
          done;
          
          let end_time = Unix.time () in
          let duration = end_time -. start_time in
          let throughput = float_of_int !inserted /. duration in
          
          Printf.printf "   Inserted: %d records\n" !inserted;
          Printf.printf "   Time: %.3f seconds\n" duration;
          Printf.printf "   Throughput: %.0f inserts/second\n" throughput;
          
        ) chunk_sizes;
        
      ) journal_modes;
      
      (* Restore defaults *)
      let _ = execute_sql_safe "PRAGMA synchronous = NORMAL" in
      let _ = execute_sql_safe "PRAGMA journal_mode = DELETE" in
      
      Printf.printf "\n✅ Performance comparison complete!\n"

let () = test_pragma_and_chunk_combinations ()

================
File: bin/scheduler_cli.ml
================
open Scheduler.Email_scheduler
open Scheduler.Db.Database

let run_scheduler db_path =
  Printf.printf "[%s] 🚀 Starting email scheduler...\n%!" 
    (Unix.time () |> Unix.localtime |> fun tm -> 
     Printf.sprintf "%02d:%02d:%02d" tm.tm_hour tm.tm_min tm.tm_sec);
  
  set_db_path db_path;
  
  match initialize_database () with
  | Error err -> 
      Printf.printf "[ERROR] Database initialization failed: %s\n%!" (string_of_db_error err);
      exit 1
  | Ok () ->
      (* Load contacts in scheduling window *)
      Printf.printf "[INFO] Loading contacts in scheduling window...\n%!";
      match get_contacts_in_scheduling_window 60 14 with
      | Error err ->
          Printf.printf "[ERROR] Failed to load contacts: %s\n%!" (string_of_db_error err);
          exit 1
      | Ok contacts ->
          let contact_count = List.length contacts in
          Printf.printf "[INFO] Loaded %d contacts for scheduling\n%!" contact_count;
          
          if contact_count = 0 then (
            Printf.printf "[INFO] No contacts need scheduling. Exiting.\n%!";
            exit 0
          );
          
          (* Generate scheduler run ID *)
          let run_id = Printf.sprintf "scheduler_run_%f" (Unix.time ()) in
          Printf.printf "[INFO] Starting scheduler run: %s\n%!" run_id;
          
          (* Create context and process schedules *)
          let config = Scheduler.Config.default in
          let context = create_context config contact_count in
          let context_with_run_id = { context with run_id } in
          
          let total_schedules = ref 0 in
          let processed_contacts = ref 0 in
          
          List.iter (fun contact ->
            match calculate_schedules_for_contact context_with_run_id contact with
            | Ok schedules ->
                incr processed_contacts;
                let count = List.length schedules in
                total_schedules := !total_schedules + count;
                
                (* Insert schedules immediately *)
                (match batch_insert_schedules_optimized schedules with
                 | Ok inserted -> 
                     if inserted <> count then
                       Printf.printf "[WARN] Contact %d: Generated %d schedules, inserted %d\n%!" 
                         contact.id count inserted
                 | Error err ->
                     Printf.printf "[ERROR] Failed to insert schedules for contact %d: %s\n%!" 
                       contact.id (string_of_db_error err))
            | Error err ->
                Printf.printf "[WARN] Failed to calculate schedules for contact %d: %s\n%!" 
                  contact.id (Scheduler.Types.string_of_error err)
          ) contacts;
          
          Printf.printf "[SUCCESS] Scheduler completed:\n%!";
          Printf.printf "  • Processed contacts: %d/%d\n%!" !processed_contacts contact_count;
          Printf.printf "  • Total schedules created: %d\n%!" !total_schedules;
          Printf.printf "  • Run ID: %s\n%!" run_id;
          
          exit 0

let main () =
  let argc = Array.length Sys.argv in
  if argc < 2 then (
    Printf.printf "Usage: %s <database_path>\n" Sys.argv.(0);
    Printf.printf "Example: %s /app/data/contacts.sqlite3\n" Sys.argv.(0);
    exit 1
  );
  
  let db_path = Sys.argv.(1) in
  run_scheduler db_path

let () = main ()

================
File: bin/visualizer_cli.ml
================
open Cmdliner
open Visualizer.Ast_analyzer
open Visualizer.Json_serializer

(** Take first n elements from a list *)
let rec take n = function
  | [] -> []
  | _ when n <= 0 -> []
  | x :: xs -> x :: take (n - 1) xs

(** Configuration for the visualizer *)
type config = {
  input_files : string list;
  output_dir : string;
  web_port : int option;
  serve : bool;
  verbose : bool;
  max_complexity : int option;
}

(** Default configuration *)
let default_config = {
  input_files = [];
  output_dir = "visualizer_output";
  web_port = None;
  serve = false;
  verbose = false;
  max_complexity = None;
}

(** Find OCaml files recursively in a directory *)
let rec find_ocaml_files dir =
  if Sys.is_directory dir then
    let files = Sys.readdir dir in
    Array.fold_left (fun acc file ->
      let full_path = Filename.concat dir file in
      if Sys.is_directory full_path then
        (find_ocaml_files full_path) @ acc
      else if Filename.check_suffix file ".ml" || Filename.check_suffix file ".mli" then
        full_path :: acc
      else
        acc
    ) [] files
  else
    [dir]

(** Collect all input files *)
let collect_input_files paths =
  List.concat_map (fun path ->
    if Sys.file_exists path then
      if Sys.is_directory path then
        find_ocaml_files path
      else
        [path]
    else begin
      Printf.eprintf "Warning: File or directory '%s' does not exist\n" path;
      []
    end
  ) paths

(** Copy web assets to output directory *)
let copy_web_assets output_dir =
  let web_files = [
    ("web/index.html", "index.html");
    ("web/visualizer.js", "visualizer.js");
  ] in
  
  List.iter (fun (src, dst) ->
    let dst_path = Filename.concat output_dir dst in
    if Sys.file_exists src then
      let content = 
        let ic = open_in src in
        let content = really_input_string ic (in_channel_length ic) in
        close_in ic;
        content
      in
      let oc = open_out dst_path in
      output_string oc content;
      close_out oc;
      Printf.printf "Copied %s -> %s\n" src dst_path
    else
      Printf.eprintf "Warning: Web asset '%s' not found\n" src
  ) web_files

(** Start a simple HTTP server *)
let start_server output_dir port =
  Printf.printf "Starting web server on port %d...\n" port;
  Printf.printf "Visit http://localhost:%d to view the visualization\n" port;
  
  (* Create a simple Python HTTP server command *)
  let server_cmd = Printf.sprintf "cd %s && python3 -m http.server %d" output_dir port in
  let exit_code = Sys.command server_cmd in
  if exit_code <> 0 then
    Printf.eprintf "Failed to start web server (exit code: %d)\n" exit_code

(** Print analysis summary *)
let print_summary analysis config =
  Printf.printf "\n=== OCaml Program Flow Analysis Summary ===\n";
  Printf.printf "Files analyzed: %d\n" (List.length config.input_files);
  Printf.printf "Functions found: %d\n" (List.length analysis.functions);
  Printf.printf "Modules found: %d\n" (List.length analysis.modules);
  
  if List.length analysis.errors > 0 then begin
    Printf.printf "\nErrors encountered:\n";
    List.iter (Printf.printf "  - %s\n") analysis.errors
  end;
  
  (* Print complexity statistics *)
  let complexities = List.map (fun f -> f.complexity_score) analysis.functions in
  if List.length complexities > 0 then begin
    let min_complexity = List.fold_left min (List.hd complexities) complexities in
    let max_complexity = List.fold_left max (List.hd complexities) complexities in
    let avg_complexity = 
      float_of_int (List.fold_left (+) 0 complexities) /. float_of_int (List.length complexities)
    in
    Printf.printf "\nComplexity Statistics:\n";
    Printf.printf "  Min: %d, Max: %d, Average: %.1f\n" min_complexity max_complexity avg_complexity;
  end;
  
  (* Print top-level functions by complexity *)
  let sorted_functions = 
    analysis.functions 
    |> List.sort (fun a b -> compare b.complexity_score a.complexity_score)
    |> (fun l -> match config.max_complexity with
        | Some max_c -> List.filter (fun f -> f.complexity_score <= max_c) l
        | None -> l)
    |> (fun l -> if List.length l > 10 then take 10 l else l)
  in
  if List.length sorted_functions > 0 then begin
    Printf.printf "\nMost Complex Functions:\n";
    List.iter (fun f ->
      Printf.printf "  %s (complexity: %d, calls: %d)\n" 
        f.name f.complexity_score (List.length f.calls)
    ) sorted_functions
  end;
  
  Printf.printf "\nVisualization generated in: %s/\n" config.output_dir

(** Main analysis and generation function *)
let run_analysis config =
  if config.verbose then
    Printf.printf "Analyzing %d OCaml files...\n" (List.length config.input_files);
  
  (* Ensure opam environment is loaded *)
  let _ = Sys.command "eval $(opam env) 2>/dev/null" in
  
  (* Run the analysis *)
  let analysis = analyze_files config.input_files in
  
  if config.verbose then begin
    Printf.printf "Analysis complete. Found %d functions.\n" (List.length analysis.functions);
    if List.length analysis.errors > 0 then
      Printf.printf "Encountered %d errors during analysis.\n" (List.length analysis.errors)
  end;
  
  (* Generate visualization data *)
  let result = export_complete_visualization config.input_files config.output_dir in
  
  (* Copy web assets *)
  copy_web_assets config.output_dir;
  
  (* Print summary *)
  print_summary result config;
  
  (* Start web server if requested *)
  if config.serve then begin
    let port = Option.value config.web_port ~default:8000 in
    start_server config.output_dir port
  end else begin
    let port = Option.value config.web_port ~default:8000 in
    Printf.printf "To view the visualization, run:\n";
    Printf.printf "  cd %s && python3 -m http.server %d\n" config.output_dir port;
    Printf.printf "Then visit http://localhost:%d\n" port
  end

(** Command line argument definitions *)
let input_files =
  let doc = "OCaml source files or directories to analyze" in
  Arg.(non_empty & pos_all string [] & info [] ~docv:"FILES" ~doc)

let output_dir =
  let doc = "Output directory for visualization files" in
  Arg.(value & opt string default_config.output_dir & info ["o"; "output"] ~docv:"DIR" ~doc)

let web_port =
  let doc = "Port for the web server (default: 8000)" in
  Arg.(value & opt (some int) None & info ["p"; "port"] ~docv:"PORT" ~doc)

let serve =
  let doc = "Start a web server after generating the visualization" in
  Arg.(value & flag & info ["s"; "serve"] ~doc)

let verbose =
  let doc = "Enable verbose output" in
  Arg.(value & flag & info ["v"; "verbose"] ~doc)

let max_complexity =
  let doc = "Filter functions by maximum complexity" in
  Arg.(value & opt (some int) None & info ["c"; "max-complexity"] ~docv:"N" ~doc)

(** Build configuration from command line arguments *)
let build_config input_files output_dir web_port serve verbose max_complexity =
  let collected_files = collect_input_files input_files in
  if List.length collected_files = 0 then begin
    Printf.eprintf "Error: No OCaml files found to analyze\n";
    exit 1
  end;
  {
    input_files = collected_files;
    output_dir;
    web_port;
    serve;
    verbose;
    max_complexity;
  }

(** Main command definition *)
let main_cmd =
  let doc = "Generate interactive visualizations for OCaml program flow" in
  let man = [
    `S Manpage.s_description;
    `P "The OCaml Program Flow Visualizer analyzes OCaml source code to extract function definitions, call relationships, and documentation. It generates an interactive web-based visualization that allows users to explore the code structure dynamically.";
    `S Manpage.s_examples;
    `P "Analyze a single file:";
    `Pre "  $(tname) src/main.ml";
    `P "Analyze all files in a directory:";
    `Pre "  $(tname) src/";
    `P "Generate visualization and start web server:";
    `Pre "  $(tname) --serve --port 9000 src/";
    `P "Filter by complexity:";
    `Pre "  $(tname) --max-complexity 10 src/";
    `S Manpage.s_see_also;
    `P "For more information, see the project documentation.";
  ] in
  Term.(const run_analysis $ (const build_config $ input_files $ output_dir $ web_port $ serve $ verbose $ max_complexity)),
  Cmd.info "ocaml-visualizer" ~version:"1.0.0" ~doc ~man

(** Main entry point *)
let () =
  exit (Cmd.eval (Cmd.v (snd main_cmd) (fst main_cmd)))

================
File: lib/db/database.ml
================
open Types
open Date_time

(* Native high-performance database interface using proper SQLite bindings *)

let db_handle = ref None
let db_path = ref "org-206.sqlite3"

(** 
 * [set_db_path]: Sets the database file path for SQLite connections
 * 
 * Purpose:
 *   Configures the SQLite database file location for all subsequent database
 *   operations, enabling environment-specific database configuration.
 * 
 * Parameters:
 *   - path: String path to SQLite database file
 * 
 * Returns:
 *   Unit (side effect: updates global database path reference)
 * 
 * Business Logic:
 *   - Updates global database path configuration
 *   - Enables switching between development, test, and production databases
 *   - Must be called before database operations in different environments
 * 
 * Usage Example:
 *   Called during application initialization to set environment-specific database
 * 
 * Error Cases:
 *   - None expected (simple reference assignment)
 * 
 * @integration_point
 *)
let set_db_path path = db_path := path

(* Error handling with Result types *)
type db_error = 
  | SqliteError of string
  | ParseError of string
  | ConnectionError of string

(** 
 * [string_of_db_error]: Converts database error to human-readable string
 * 
 * Purpose:
 *   Provides standardized error message formatting for database errors
 *   to enable consistent error reporting and debugging.
 * 
 * Parameters:
 *   - db_error variant: Specific database error type
 * 
 * Returns:
 *   String with formatted error message including error type
 * 
 * Business Logic:
 *   - Categorizes errors for targeted debugging
 *   - Provides clear error context for troubleshooting
 *   - Enables consistent error handling across application
 * 
 * Usage Example:
 *   Used in error reporting and logging throughout database operations
 * 
 * Error Cases:
 *   - None expected (pure string formatting)
 * 
 * @integration_point
 *)
let string_of_db_error = function
  | SqliteError msg -> "SQLite error: " ^ msg
  | ParseError msg -> "Parse error: " ^ msg
  | ConnectionError msg -> "Connection error: " ^ msg

(* Get or create database connection *)
let get_db_connection () =
  match !db_handle with
  | Some db -> Ok db
  | None ->
      try
        let db = Sqlite3.db_open !db_path in
        db_handle := Some db;
        Ok db
      with Sqlite3.Error msg ->
        Error (ConnectionError msg)

(* Parse datetime from SQLite timestamp string *)
let parse_datetime datetime_str =
  if datetime_str = "" || datetime_str = "NULL" then
    current_datetime ()
  else
    try
      (* Handle common SQLite datetime formats: "YYYY-MM-DD HH:MM:SS" *)
      match String.split_on_char ' ' datetime_str with
      | [date_part; time_part] ->
          let date = parse_date date_part in
          let time_components = String.split_on_char ':' time_part in
          (match time_components with
           | [hour_str; minute_str; second_str] ->
               let hour = int_of_string hour_str in
               let minute = int_of_string minute_str in
               (* Handle fractional seconds and short second strings safely *)
               let second = 
                 if String.length second_str >= 2 then
                   int_of_string (String.sub second_str 0 2)
                 else
                   int_of_string second_str
               in
               let time_tuple = (hour, minute, second) in
               make_datetime date time_tuple
           | _ -> current_datetime ())
      | [date_part] ->
          (* Date only, assume midnight *)
          let date = parse_date date_part in
          make_datetime date (0, 0, 0)
      | _ -> current_datetime ()
    with _ -> current_datetime ()

(* Execute SQL with proper error handling *)
let execute_sql_safe sql =
  match get_db_connection () with
  | Error err -> Error err
  | Ok db ->
      try
        let rows = ref [] in
        let callback row _headers =
          let row_data = Array.to_list (Array.map (function Some s -> s | None -> "") row) in
          rows := row_data :: !rows
        in
        match Sqlite3.exec db ~cb:callback sql with
        | Sqlite3.Rc.OK -> Ok (List.rev !rows)
        | rc -> Error (SqliteError (Sqlite3.Rc.to_string rc))
      with Sqlite3.Error msg ->
        Error (SqliteError msg)

(* Execute SQL without result data (INSERT, UPDATE, DELETE) *)
let execute_sql_no_result sql =
  match get_db_connection () with
  | Error err -> Error err
  | Ok db ->
      try
        match Sqlite3.exec db sql with
        | Sqlite3.Rc.OK -> Ok ()
        | rc -> Error (SqliteError (Sqlite3.Rc.to_string rc))
      with Sqlite3.Error msg ->
        Error (SqliteError msg)

(* High-performance prepared statement batch insertion *)
let batch_insert_with_prepared_statement table_sql values_list =
  match get_db_connection () with
  | Error err -> Error err
  | Ok db ->
      try
        (* Prepare the statement once *)
        let stmt = Sqlite3.prepare db table_sql in
        let total_inserted = ref 0 in
        
        (* Begin transaction for batch *)
        (match Sqlite3.exec db "BEGIN TRANSACTION" with
         | Sqlite3.Rc.OK -> ()
         | rc -> failwith ("Transaction begin failed: " ^ Sqlite3.Rc.to_string rc));
        
        (* Execute for each set of values *)
        List.iter (fun values ->
          (* Reset and bind parameters *)
          ignore (Sqlite3.reset stmt);
          Array.iteri (fun i value ->
            match Sqlite3.bind stmt (i + 1) (Sqlite3.Data.TEXT value) with
            | Sqlite3.Rc.OK -> ()
            | rc -> failwith ("Bind failed: " ^ Sqlite3.Rc.to_string rc)
          ) values;
          
          (* Execute the statement *)
          match Sqlite3.step stmt with
          | Sqlite3.Rc.DONE -> incr total_inserted
          | rc -> failwith ("Step failed: " ^ Sqlite3.Rc.to_string rc)
        ) values_list;
        
        (* Commit transaction *)
        (match Sqlite3.exec db "COMMIT" with
         | Sqlite3.Rc.OK -> Ok !total_inserted
         | rc -> 
             let _ = Sqlite3.exec db "ROLLBACK" in
             Error (SqliteError ("Commit failed: " ^ Sqlite3.Rc.to_string rc)))
        
      with 
      | Sqlite3.Error msg -> 
          let _ = Sqlite3.exec db "ROLLBACK" in
          Error (SqliteError msg)
      | Failure msg ->
          let _ = Sqlite3.exec db "ROLLBACK" in
          Error (SqliteError msg)

(* Parse contact data from SQLite row with new fields *)
let parse_contact_row = function
  | [id_str; email; zip_code; state; birth_date; effective_date; carrier; failed_underwriting_str] ->
      (try
        let id = int_of_string id_str in
        let birthday = 
          if birth_date = "" || birth_date = "NULL" then None
          else Some (parse_date birth_date)
        in
        let effective_date_opt = 
          if effective_date = "" || effective_date = "NULL" then None
          else Some (parse_date effective_date)
        in
        let state_opt = if state = "" || state = "NULL" then None else Some (state_of_string state) in
        let zip_code_opt = if zip_code = "" || zip_code = "NULL" then None else Some zip_code in
        let carrier_opt = if carrier = "" || carrier = "NULL" then None else Some carrier in
        let failed_underwriting = (failed_underwriting_str = "1" || failed_underwriting_str = "true") in
        Some {
          id;
          email;
          zip_code = zip_code_opt;
          state = state_opt;
          birthday;
          effective_date = effective_date_opt;
          carrier = carrier_opt;
          failed_underwriting;
        }
      with _ -> None)
  | [id_str; email; zip_code; state; birth_date; effective_date] ->
      (* Backward compatibility for old schema without carrier/underwriting fields *)
      (try
        let id = int_of_string id_str in
        let birthday = 
          if birth_date = "" || birth_date = "NULL" then None
          else Some (parse_date birth_date)
        in
        let effective_date_opt = 
          if effective_date = "" || effective_date = "NULL" then None
          else Some (parse_date effective_date)
        in
        let state_opt = if state = "" || state = "NULL" then None else Some (state_of_string state) in
        let zip_code_opt = if zip_code = "" || zip_code = "NULL" then None else Some zip_code in
        Some {
          id;
          email;
          zip_code = zip_code_opt;
          state = state_opt;
          birthday;
          effective_date = effective_date_opt;
          carrier = None;
          failed_underwriting = false;
        }
      with _ -> None)
  | _ -> None

(* Query-driven contact fetching with native SQLite - updated for new fields *)
let get_contacts_in_scheduling_window lookahead_days lookback_days =
  let today = current_date () in
  let active_window_end = add_days today lookahead_days in
  let lookback_window_start = add_days today (-lookback_days) in
  
  (* Format dates for SQL pattern matching *)
  let (_, start_month, start_day) = lookback_window_start in
  let (_, end_month, end_day) = active_window_end in
  let start_str = Printf.sprintf "%02d-%02d" start_month start_day in
  let end_str = Printf.sprintf "%02d-%02d" end_month end_day in
  
  (* Updated query to include new fields with fallback for old schema *)
  let query = 
    if start_month <= end_month then
      (* Window doesn't cross year boundary - simple case *)
      Printf.sprintf {|
        SELECT id, email, 
               COALESCE(zip_code, '') as zip_code, 
               COALESCE(state, '') as state, 
               COALESCE(birth_date, '') as birth_date, 
               COALESCE(effective_date, '') as effective_date,
               COALESCE(carrier, '') as carrier,
               COALESCE(failed_underwriting, 0) as failed_underwriting
        FROM contacts
        WHERE email IS NOT NULL AND email != '' 
        AND (
          (strftime('%%m-%%d', birth_date) BETWEEN '%s' AND '%s') OR
          (strftime('%%m-%%d', effective_date) BETWEEN '%s' AND '%s')
        )
      |} start_str end_str start_str end_str
    else
      (* Window crosses year boundary - need to handle two ranges *)
      Printf.sprintf {|
        SELECT id, email, 
               COALESCE(zip_code, '') as zip_code, 
               COALESCE(state, '') as state, 
               COALESCE(birth_date, '') as birth_date, 
               COALESCE(effective_date, '') as effective_date,
               COALESCE(carrier, '') as carrier,
               COALESCE(failed_underwriting, 0) as failed_underwriting
        FROM contacts
        WHERE email IS NOT NULL AND email != '' 
        AND (
          (strftime('%%m-%%d', birth_date) >= '%s' OR strftime('%%m-%%d', birth_date) <= '%s') OR
          (strftime('%%m-%%d', effective_date) >= '%s' OR strftime('%%m-%%d', effective_date) <= '%s')
        )
      |} start_str end_str start_str end_str
  in
  
  match execute_sql_safe query with
  | Error err -> Error err
  | Ok rows ->
      let contacts = List.filter_map parse_contact_row rows in
      Ok contacts

(* Get all contacts with native SQLite - updated for new fields *)
let get_all_contacts () =
  let query = {|
    SELECT id, email, 
           COALESCE(zip_code, '') as zip_code, 
           COALESCE(state, '') as state, 
           COALESCE(birth_date, '') as birth_date, 
           COALESCE(effective_date, '') as effective_date,
           COALESCE(carrier, '') as carrier,
           COALESCE(failed_underwriting, 0) as failed_underwriting
    FROM contacts
    WHERE email IS NOT NULL AND email != '' 
    ORDER BY id
  |} in
  
  match execute_sql_safe query with
  | Error err -> Error err
  | Ok rows ->
      let contacts = List.filter_map parse_contact_row rows in
      Ok contacts

(* Get total contact count with native SQLite *)
let get_total_contact_count () =
  let query = "SELECT COUNT(*) FROM contacts WHERE email IS NOT NULL AND email != ''" in
  match execute_sql_safe query with
  | Ok [[count_str]] -> 
      (try Ok (int_of_string count_str) 
       with _ -> Error (ParseError "Invalid count"))
  | Ok _ -> Error (ParseError "Invalid count result")
  | Error err -> Error err

(* Clear pre-scheduled emails *)
let clear_pre_scheduled_emails () =
  match execute_sql_no_result "DELETE FROM email_schedules WHERE status IN ('pre-scheduled', 'scheduled')" with
  | Ok () -> Ok 1  (* Success indicator *)
  | Error err -> Error err

(* Helper type for existing schedule comparison *)
type existing_schedule_record = {
  contact_id: int;
  email_type: string;
  scheduled_date: string;
  scheduled_time: string;
  status: string;
  skip_reason: string;
  scheduler_run_id: string;
  created_at: string;
}

(** 
 * [schedule_content_changed]: Intelligently compares schedule content to detect real changes
 * 
 * Purpose:
 *   Core smart update logic that determines if email schedule content has actually
 *   changed, ignoring metadata to preserve audit trails and prevent unnecessary updates.
 * 
 * Parameters:
 *   - existing_record: Existing schedule record from database
 *   - new_schedule: New schedule to compare against existing
 * 
 * Returns:
 *   Boolean indicating if content has meaningfully changed
 * 
 * Business Logic:
 *   - Compares essential schedule fields: type, date, time, status, skip reason
 *   - Ignores metadata fields like run_id and timestamps for audit preservation
 *   - Logs preservation decisions for audit trail transparency
 *   - Enables smart database updates that preserve history when appropriate
 *   - Critical for maintaining scheduler run tracking across multiple executions
 * 
 * Usage Example:
 *   Called by smart_batch_insert_schedules to determine update necessity
 * 
 * Error Cases:
 *   - None expected (pure comparison logic)
 * 
 * @business_rule @performance
 *)
let schedule_content_changed existing_record (new_schedule : email_schedule) =
  let new_scheduled_date_str = string_of_date new_schedule.scheduled_date in
  let new_scheduled_time_str = string_of_time new_schedule.scheduled_time in
  let new_status_str = match new_schedule.status with
    | PreScheduled -> "pre-scheduled"
    | Skipped _reason -> "skipped"
    | _ -> "unknown"
  in
  let new_skip_reason = match new_schedule.status with 
    | Skipped reason -> reason 
    | _ -> ""
  in
  let new_email_type_str = string_of_email_type new_schedule.email_type in
  
  let content_changed = 
    existing_record.email_type <> new_email_type_str ||
    existing_record.scheduled_date <> new_scheduled_date_str ||
    existing_record.scheduled_time <> new_scheduled_time_str ||
    existing_record.status <> new_status_str ||
    existing_record.skip_reason <> new_skip_reason
  in
  
  (* Use audit fields for business logic - log preservation of original scheduler_run_id *)
  if not content_changed then
    Printf.printf "📝 Content unchanged for contact %d - preserving original scheduler_run_id: %s (created: %s)\n%!" 
      new_schedule.contact_id existing_record.scheduler_run_id existing_record.created_at;
  
  content_changed

(* Find existing schedule for a new schedule *)
let find_existing_schedule existing_schedules (new_schedule : email_schedule) =
  let new_email_type_str = string_of_email_type new_schedule.email_type in
  let new_scheduled_date_str = string_of_date new_schedule.scheduled_date in
  
  List.find_opt (fun existing ->
    existing.contact_id = new_schedule.contact_id &&
    existing.email_type = new_email_type_str &&
    existing.scheduled_date = new_scheduled_date_str
  ) existing_schedules

(** 
 * [get_existing_schedules_for_comparison]: Retrieves all existing schedules for intelligent comparison
 * 
 * Purpose:
 *   Fetches existing email schedules from database to enable smart update logic
 *   that can detect unchanged content and preserve audit trails.
 * 
 * Returns:
 *   Result containing list of existing_schedule_record or database error
 * 
 * Business Logic:
 *   - Retrieves all pre-scheduled and scheduled email records
 *   - Excludes already sent/delivered emails to focus on updatable schedules
 *   - Provides data for smart comparison and audit trail preservation
 * 
 * @performance @integration_point
 *)
let get_existing_schedules_for_comparison () =
  let query = {|
    SELECT contact_id, email_type, scheduled_send_date, scheduled_send_time, 
           status, COALESCE(skip_reason, '') as skip_reason, 
           COALESCE(batch_id, '') as scheduler_run_id,
           COALESCE(created_at, '') as created_at
    FROM email_schedules 
    WHERE status IN ('pre-scheduled', 'scheduled', 'skipped')
    ORDER BY contact_id, email_type, scheduled_send_date
  |} in
  
  match execute_sql_safe query with
  | Error err -> Error err
  | Ok rows ->
      let records = List.map (fun row ->
        match row with
        | [contact_id_str; email_type; scheduled_date; scheduled_time; status; skip_reason; scheduler_run_id; created_at] ->
            (try
              {
                contact_id = int_of_string contact_id_str;
                email_type;
                scheduled_date;
                scheduled_time;
                status;
                skip_reason;
                scheduler_run_id;
                created_at;
              }
            with _ -> 
              (* Default record for parsing errors - will be filtered out by comparison logic *)
              {
                contact_id = 0;
                email_type = "";
                scheduled_date = "";
                scheduled_time = "";
                status = "";
                skip_reason = "";
                scheduler_run_id = "";
                created_at = "";
              })
        | _ -> 
            (* Default record for malformed rows *)
            {
              contact_id = 0;
              email_type = "";
              scheduled_date = "";
              scheduled_time = "";
              status = "";
              skip_reason = "";
              scheduler_run_id = "";
              created_at = "";
            }
      ) rows in
      Ok records

(** 
 * [smart_batch_insert_schedules]: Intelligent bulk schedule update with audit preservation
 * 
 * Purpose:
 *   Flagship smart update function that minimizes database operations by detecting
 *   unchanged schedules and preserving their audit trails while updating only changed content.
 * 
 * Parameters:
 *   - schedules: List of new email schedules to process
 *   - current_run_id: Run identifier for new schedules
 * 
 * Returns:
 *   Result containing number of processed records or database error
 * 
 * Business Logic:
 *   - Retrieves all existing schedules for intelligent comparison
 *   - Categorizes each schedule as new, changed, or unchanged
 *   - INSERT for new schedules with current run_id
 *   - UPDATE for changed schedules with current run_id and audit logging
 *   - PRESERVE unchanged schedules with original run_id for audit continuity
 *   - Uses single transaction for atomicity and performance
 *   - Provides detailed metrics for monitoring and optimization
 * 
 * Usage Example:
 *   Primary database update function called by scheduling orchestration
 * 
 * Error Cases:
 *   - Database errors with automatic rollback for data consistency
 *   - Comprehensive error logging for troubleshooting
 * 
 * @business_rule @performance @integration_point
 *)
let smart_batch_insert_schedules schedules current_run_id =
  if schedules = [] then Ok 0 else (
  
  Printf.printf "🔍 Getting existing schedules for comparison...\n%!";
  match get_existing_schedules_for_comparison () with
  | Error err -> Error err
  | Ok existing_schedules ->
      Printf.printf "📊 Found %d existing schedules to compare against\n%!" (List.length existing_schedules);
      
      match get_db_connection () with
      | Error err -> Error err
      | Ok db ->
          try
            (* Begin transaction *)
            (match Sqlite3.exec db "BEGIN TRANSACTION" with
             | Sqlite3.Rc.OK -> ()
             | rc -> failwith ("Transaction begin failed: " ^ Sqlite3.Rc.to_string rc));
            
            let total_processed = ref 0 in
            let unchanged_count = ref 0 in
            let changed_count = ref 0 in
            let new_count = ref 0 in
            
            (* Process each schedule with truly smart logic *)
            List.iter (fun (schedule : email_schedule) ->
              let scheduled_date_str = string_of_date schedule.scheduled_date in
              let scheduled_time_str = string_of_time schedule.scheduled_time in
              let status_str = match schedule.status with
                | PreScheduled -> "pre-scheduled"
                | Skipped _reason -> "skipped"
                | _ -> "unknown"
              in
              let skip_reason = match schedule.status with 
                | Skipped reason -> reason 
                | _ -> ""
              in
              
              let (current_year, _, _) = current_date () in
              let (event_year, event_month, event_day) = match schedule.email_type with
                | Anniversary Birthday -> (current_year, 1, 1)
                | Anniversary EffectiveDate -> (current_year, 1, 2)
                | _ -> (current_year, 1, 1)
              in
              
              (* Determine what action to take *)
              (match find_existing_schedule existing_schedules schedule with
                | None -> 
                    (* New schedule - INSERT *)
                    incr new_count;
                    let insert_sql = Printf.sprintf {|
                      INSERT INTO email_schedules (
                        contact_id, email_type, event_year, event_month, event_day,
                        scheduled_send_date, scheduled_send_time, status, skip_reason,
                        batch_id
                      ) VALUES (%d, '%s', %d, %d, %d, '%s', '%s', '%s', '%s', '%s')
                    |} 
                      schedule.contact_id
                      (string_of_email_type schedule.email_type)
                      event_year event_month event_day
                      scheduled_date_str
                      scheduled_time_str
                      status_str
                      skip_reason
                      current_run_id
                    in
                    (match Sqlite3.exec db insert_sql with
                     | Sqlite3.Rc.OK -> incr total_processed
                     | rc -> failwith ("Insert failed: " ^ Sqlite3.Rc.to_string rc))
                     
                | Some existing ->
                    if schedule_content_changed existing schedule then (
                      (* Content changed - UPDATE with new run_id and log audit trail *)
                      incr changed_count;
                      Printf.printf "🔄 Updating schedule for contact %d: %s → %s (original run: %s, created: %s)\n%!" 
                        schedule.contact_id existing.status status_str existing.scheduler_run_id existing.created_at;
                      
                      let update_sql = Printf.sprintf {|
                        UPDATE email_schedules SET
                          email_type = '%s', event_year = %d, event_month = %d, event_day = %d,
                          scheduled_send_date = '%s', scheduled_send_time = '%s', 
                          status = '%s', skip_reason = '%s', batch_id = '%s',
                          updated_at = CURRENT_TIMESTAMP
                        WHERE contact_id = %d AND email_type = '%s' AND scheduled_send_date = '%s'
                      |} 
                        (string_of_email_type schedule.email_type)
                        event_year event_month event_day
                        scheduled_date_str
                        scheduled_time_str
                        status_str
                        skip_reason
                        current_run_id
                        schedule.contact_id
                        existing.email_type
                        existing.scheduled_date
                      in
                      (match Sqlite3.exec db update_sql with
                       | Sqlite3.Rc.OK -> incr total_processed
                       | rc -> failwith ("Update failed: " ^ Sqlite3.Rc.to_string rc))
                    ) else (
                      (* Content unchanged - preserve existing record with full audit info *)
                      incr unchanged_count;
                      incr total_processed;
                      Printf.printf "✅ Preserving unchanged record for contact %d (run: %s, age: %s)\n%!" 
                        schedule.contact_id existing.scheduler_run_id existing.created_at;
                      (* No database operation needed - smart preservation! *)
                    )
              )
            ) schedules;
            
            (* Commit transaction *)
            (match Sqlite3.exec db "COMMIT" with
             | Sqlite3.Rc.OK -> 
                 Printf.printf "✅ Truly smart update complete: %d total, %d new, %d changed, %d unchanged (skipped)\n%!" 
                   !total_processed !new_count !changed_count !unchanged_count;
                 Ok !total_processed
             | rc -> 
                 let _ = Sqlite3.exec db "ROLLBACK" in
                 Error (SqliteError ("Commit failed: " ^ Sqlite3.Rc.to_string rc)))
            
          with 
          | Sqlite3.Error msg -> 
              let _ = Sqlite3.exec db "ROLLBACK" in
              Error (SqliteError msg)
          | Failure msg ->
              let _ = Sqlite3.exec db "ROLLBACK" in
              Error (SqliteError msg)
  )

(* Modified clear function that doesn't delete everything *)
let smart_clear_outdated_schedules new_schedules =
  if new_schedules = [] then Ok 0 else
  
  (* Build list of (contact_id, email_type, scheduled_date) for schedules we're keeping *)
  let keeping_schedules = List.map (fun (schedule : email_schedule) ->
    let email_type_str = string_of_email_type schedule.email_type in
    let scheduled_date_str = string_of_date schedule.scheduled_date in
    Printf.sprintf "(%d, '%s', '%s')" 
      schedule.contact_id email_type_str scheduled_date_str
  ) new_schedules in
  
  let keeping_list = String.concat ", " keeping_schedules in
  
  (* Delete only schedules not in our new list *)
  let delete_query = Printf.sprintf {|
    DELETE FROM email_schedules 
    WHERE status IN ('pre-scheduled', 'scheduled', 'skipped')
    AND (contact_id, email_type, scheduled_send_date) NOT IN (%s)
  |} keeping_list in
  
  match execute_sql_no_result delete_query with
  | Ok () -> 
      Printf.printf "🗑️  Cleaned up outdated schedules\n%!";
      Ok 1
  | Error err -> Error err

(* Apply high-performance SQLite PRAGMA settings *)
let optimize_sqlite_for_bulk_inserts () =
  let optimizations = [
    "PRAGMA synchronous = OFF";           (* Don't wait for OS write confirmation - major speedup *)
    "PRAGMA journal_mode = WAL";          (* WAL mode - test for real workload performance *)
    "PRAGMA cache_size = 500000";          (* Much larger cache - 200MB+ *)
    "PRAGMA page_size = 8192";            (* Larger page size for bulk operations *)
    "PRAGMA temp_store = MEMORY";         (* Store temporary tables in memory *)
    "PRAGMA count_changes = OFF";         (* Don't count changes - slight speedup *)
    "PRAGMA auto_vacuum = 0";             (* Disable auto-vacuum during bulk inserts *)
    "PRAGMA secure_delete = OFF";         (* Don't securely delete - faster *)
    "PRAGMA locking_mode = EXCLUSIVE";    (* Exclusive access for bulk operations *)
  ] in
  
  let rec apply_pragmas remaining =
    match remaining with
    | [] -> Ok ()
    | pragma :: rest ->
        match execute_sql_no_result pragma with
        | Ok () -> apply_pragmas rest
        | Error err -> Error err
  in
  apply_pragmas optimizations

(* Restore safe SQLite settings after bulk operations *)
let restore_sqlite_safety () =
  let safety_settings = [
    "PRAGMA synchronous = NORMAL";        (* Restore safe synchronous mode *)
    "PRAGMA journal_mode = WAL";          (* Keep WAL mode - it's safe and fast *)
    "PRAGMA auto_vacuum = 1";             (* Re-enable auto-vacuum *)
    "PRAGMA secure_delete = ON";          (* Re-enable secure delete *)
    "PRAGMA locking_mode = NORMAL";       (* Restore normal locking *)
  ] in
  
  let rec apply_pragmas remaining =
    match remaining with
    | [] -> Ok ()
    | pragma :: rest ->
        match execute_sql_no_result pragma with
        | Ok () -> apply_pragmas rest
        | Error err -> Error err
  in
  apply_pragmas safety_settings

(** 
 * [batch_insert_schedules_native]: Ultra high-performance batch insertion using prepared statements
 * 
 * Purpose:
 *   Provides maximum performance bulk insertion using SQLite prepared statements
 *   with aggressive optimizations for large-scale email schedule operations.
 * 
 * Parameters:
 *   - schedules: List of email schedules to insert
 * 
 * Returns:
 *   Result containing number of inserted records or database error
 * 
 * Business Logic:
 *   - Applies performance optimizations before insertion
 *   - Uses prepared statements for optimal SQL execution
 *   - Processes schedules in single transaction for atomicity
 *   - Converts schedule records to parameter arrays efficiently
 *   - Handles event date calculations for database storage
 *   - Restores safety settings after completion
 * 
 * Usage Example:
 *   Used for large-scale schedule insertions during batch processing
 * 
 * Error Cases:
 *   - Database errors with automatic safety restoration
 *   - Transaction rollback on any failure
 * 
 * @performance @integration_point
 *)
let batch_insert_schedules_native schedules =
  if schedules = [] then Ok 0 else
  
  (* Apply performance optimizations *)
  match optimize_sqlite_for_bulk_inserts () with
  | Error err -> Error err
  | Ok _ ->
      (* Prepare statement template *)
      let insert_sql = {|
        INSERT OR REPLACE INTO email_schedules (
          contact_id, email_type, event_year, event_month, event_day,
          scheduled_send_date, scheduled_send_time, status, skip_reason,
          batch_id
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
      |} in
      
      (* Convert schedules to parameter arrays *)
      let values_list = List.map (fun (schedule : email_schedule) ->
        let scheduled_date_str = string_of_date schedule.scheduled_date in
        let scheduled_time_str = string_of_time schedule.scheduled_time in
        let status_str = match schedule.status with
          | PreScheduled -> "pre-scheduled"
          | Skipped _reason -> "skipped"
          | _ -> "unknown"
        in
        let skip_reason = match schedule.status with 
          | Skipped reason -> reason 
          | _ -> ""
        in
        
        let (current_year, _, _) = current_date () in
        let (event_year, event_month, event_day) = match schedule.email_type with
          | Anniversary Birthday -> (current_year, 1, 1)
          | Anniversary EffectiveDate -> (current_year, 1, 2)
          | _ -> (current_year, 1, 1)
        in
        
        [|
          string_of_int schedule.contact_id;
          string_of_email_type schedule.email_type;
          string_of_int event_year;
          string_of_int event_month;
          string_of_int event_day;
          scheduled_date_str;
          scheduled_time_str;
          status_str;
          skip_reason;
          schedule.scheduler_run_id;
        |]
      ) schedules in
      
      (* Use prepared statement batch insertion *)
      match batch_insert_with_prepared_statement insert_sql values_list with
      | Ok total ->
          (* Restore safety settings *)
          let _ = restore_sqlite_safety () in
          Ok total
      | Error err -> 
          let _ = restore_sqlite_safety () in
          Error err

(* Simple but highly effective batch insert using native SQLite *)
let batch_insert_schedules_optimized schedules =
  batch_insert_schedules_native schedules

(* Batch insert with improved transaction handling - for smaller datasets *)
let batch_insert_schedules_transactional schedules =
  if schedules = [] then Ok 0 else
  
  match get_db_connection () with
  | Error err -> Error err
  | Ok db ->
      try
        (* Begin transaction *)
        (match Sqlite3.exec db "BEGIN TRANSACTION" with
         | Sqlite3.Rc.OK -> ()
         | rc -> failwith ("Transaction begin failed: " ^ Sqlite3.Rc.to_string rc));
        
        let total_inserted = ref 0 in
        
        (* Process each schedule individually within the transaction *)
        List.iter (fun (schedule : email_schedule) ->
          let scheduled_date_str = string_of_date schedule.scheduled_date in
          let scheduled_time_str = string_of_time schedule.scheduled_time in
          let status_str = match schedule.status with
            | PreScheduled -> "pre-scheduled"
            | Skipped _reason -> "skipped"
            | _ -> "unknown"
          in
          let skip_reason = match schedule.status with 
            | Skipped reason -> reason 
            | _ -> ""
          in
          
          let (current_year, _, _) = current_date () in
          let (event_year, event_month, event_day) = match schedule.email_type with
            | Anniversary Birthday -> (current_year, 1, 1)
            | Anniversary EffectiveDate -> (current_year, 1, 2)
            | _ -> (current_year, 1, 1)
          in
          
          let insert_sql = Printf.sprintf {|
            INSERT OR REPLACE INTO email_schedules (
              contact_id, email_type, event_year, event_month, event_day,
              scheduled_send_date, scheduled_send_time, status, skip_reason,
              batch_id
            ) VALUES (%d, '%s', %d, %d, %d, '%s', '%s', '%s', '%s', '%s')
          |} 
            schedule.contact_id
            (string_of_email_type schedule.email_type)
            event_year event_month event_day
            scheduled_date_str
            scheduled_time_str
            status_str
            skip_reason
            schedule.scheduler_run_id
          in
          
          match Sqlite3.exec db insert_sql with
          | Sqlite3.Rc.OK -> incr total_inserted
          | rc -> failwith ("Insert failed: " ^ Sqlite3.Rc.to_string rc)
        ) schedules;
        
        (* Commit transaction *)
        (match Sqlite3.exec db "COMMIT" with
         | Sqlite3.Rc.OK -> Ok !total_inserted
         | rc -> 
             let _ = Sqlite3.exec db "ROLLBACK" in
             Error (SqliteError ("Commit failed: " ^ Sqlite3.Rc.to_string rc)))
        
      with 
      | Sqlite3.Error msg -> 
          let _ = Sqlite3.exec db "ROLLBACK" in
          Error (SqliteError msg)
      | Failure msg ->
          let _ = Sqlite3.exec db "ROLLBACK" in
          Error (SqliteError msg)

(* Chunked batch insert with automatic chunk size optimization *)
let batch_insert_schedules_chunked schedules chunk_size =
  (* For large datasets, use the optimized prepared statement approach *)
  if List.length schedules > 1000 then
    batch_insert_schedules_native schedules
  else
    (* For smaller datasets, use the transactional approach *)
    if schedules = [] then Ok 0 else
    
    let rec chunk_list lst size =
      match lst with
      | [] -> []
      | _ ->
          let (chunk, rest) = 
            let rec take n lst acc =
              match lst, n with
              | [], _ -> (List.rev acc, [])
              | _, 0 -> (List.rev acc, lst)
              | x :: xs, n -> take (n-1) xs (x :: acc)
            in
            take size lst []
          in
          chunk :: chunk_list rest size
    in
    
    let chunks = chunk_list schedules chunk_size in
    let total_inserted = ref 0 in
    
    let rec process_chunks remaining_chunks =
      match remaining_chunks with
      | [] -> Ok !total_inserted
      | chunk :: rest ->
          match batch_insert_schedules_transactional chunk with
          | Ok count -> 
              total_inserted := !total_inserted + count;
              process_chunks rest
          | Error err -> Error err
    in
    
    process_chunks chunks

(* NEW: Smart update workflow - replaces clear_pre_scheduled_emails + batch_insert *)
let smart_update_schedules schedules current_run_id =
  if schedules = [] then Ok 0 else (
  
  Printf.printf "🚀 Starting smart schedule update with %d schedules...\n%!" (List.length schedules);
  
  (* Step 1: Smart insert/update with scheduler_run_id preservation *)
  match smart_batch_insert_schedules schedules current_run_id with
  | Error err -> Error err
  | Ok inserted_count ->
      (* Step 2: Clean up schedules that are no longer needed *)
      match smart_clear_outdated_schedules schedules with
      | Error err -> Error err
      | Ok _ ->
          Printf.printf "🎉 Smart update complete! Processed %d schedules\n%!" inserted_count;
          Ok inserted_count
  )

(* Legacy function for backward compatibility *)
let update_schedules_legacy schedules _current_run_id =
  Printf.printf "⚠️  Using legacy update method (clear all + insert all)\n%!";
  match clear_pre_scheduled_emails () with
  | Error err -> Error err
  | Ok _ ->
      match batch_insert_schedules_chunked schedules 1000 with
      | Error err -> Error err
      | Ok count -> Ok count

(* Main entry point - uses smart update by default *)
let update_email_schedules ?(use_smart_update=true) schedules current_run_id =
  if use_smart_update then
    smart_update_schedules schedules current_run_id
  else
    update_schedules_legacy schedules current_run_id

(* Get sent emails for followup *)
let get_sent_emails_for_followup lookback_days =
  let lookback_date = add_days (current_date ()) (-lookback_days) in
  let query = Printf.sprintf {|
    SELECT contact_id, email_type, 
           COALESCE(actual_send_datetime, scheduled_send_date) as sent_time,
           id
    FROM email_schedules 
    WHERE status IN ('sent', 'delivered')
    AND scheduled_send_date >= '%s'
    AND (email_type IN ('birthday', 'effective_date', 'post_window')
         OR email_type LIKE 'campaign_%%')
    ORDER BY contact_id, sent_time DESC
  |} (string_of_date lookback_date) in
  
  match execute_sql_safe query with
  | Error err -> Error err
  | Ok rows ->
      let sent_emails = List.filter_map (fun row ->
        match row with
        | [contact_id_str; email_type; sent_time; id_str] ->
            (try
              let contact_id = int_of_string contact_id_str in
              let id = int_of_string id_str in
              Some (contact_id, email_type, sent_time, id)
            with _ -> None)
        | _ -> None
      ) rows in
      Ok sent_emails

(* Check contact interaction data for followup classification *)
let get_contact_interactions contact_id since_date =
  let clicks_query = Printf.sprintf {|
    SELECT COUNT(*) FROM tracking_clicks 
    WHERE contact_id = %d AND clicked_at >= '%s'
  |} contact_id since_date in
  
  let events_query = Printf.sprintf {|
    SELECT COUNT(*) FROM contact_events
    WHERE contact_id = %d AND created_at >= '%s' AND event_type = 'eligibility_answered'
  |} contact_id since_date in
  
  match execute_sql_safe clicks_query with
  | Error err -> Error err
  | Ok [[click_count_str]] ->
      (match execute_sql_safe events_query with
       | Error err -> Error err
       | Ok [[event_count_str]] ->
           (try
             let has_clicks = int_of_string click_count_str > 0 in
             let has_health_answers = int_of_string event_count_str > 0 in
             Ok (has_clicks, has_health_answers)
           with _ -> Error (ParseError "Invalid interaction count"))
       | Ok _ -> Error (ParseError "Invalid event result"))
  | Ok _ -> Error (ParseError "Invalid click result")

(* Create performance indexes *)
let ensure_performance_indexes () =
  let indexes = [
    "CREATE INDEX IF NOT EXISTS idx_contacts_state_birthday ON contacts(state, birth_date)";
    "CREATE INDEX IF NOT EXISTS idx_contacts_state_effective ON contacts(state, effective_date)";
    "CREATE INDEX IF NOT EXISTS idx_schedules_lookup ON email_schedules(contact_id, email_type, scheduled_send_date)";
    "CREATE INDEX IF NOT EXISTS idx_schedules_status_date ON email_schedules(status, scheduled_send_date)";
  ] in
  
  let rec create_indexes remaining =
    match remaining with
    | [] -> Ok ()
    | index_sql :: rest ->
        match execute_sql_no_result index_sql with
        | Ok () -> create_indexes rest
        | Error err -> Error err
  in
  create_indexes indexes

(* Initialize database and ensure schema *)
let initialize_database () =
  (* Ensure AEP campaign type exists *)
  let ensure_aep_campaign () =
    let check_aep_query = "SELECT COUNT(*) FROM campaign_types WHERE name = 'aep'" in
    match execute_sql_safe check_aep_query with
    | Ok [["0"]] ->
        (* AEP campaign doesn't exist, create it *)
        let insert_aep_sql = {|
          INSERT INTO campaign_types (
            name, respect_exclusion_windows, enable_followups, days_before_event,
            target_all_contacts, priority, active, spread_evenly, skip_failed_underwriting
          ) VALUES (
            'aep', 1, 1, 30, 1, 30, 1, 0, 0
          )
        |} in
        execute_sql_no_result insert_aep_sql
    | Ok _ -> Ok () (* AEP already exists *)
    | Error err -> Error err
  in

  (* Ensure default AEP campaign instance exists *)
  let ensure_aep_instance () =
    let check_instance_query = "SELECT COUNT(*) FROM campaign_instances WHERE campaign_type = 'aep'" in
    match execute_sql_safe check_instance_query with
    | Ok [["0"]] ->
        (* No AEP instance exists, create default one *)
        let insert_instance_sql = {|
          INSERT INTO campaign_instances (
            campaign_type, instance_name, email_template, sms_template,
            active_start_date, active_end_date, spread_start_date, spread_end_date,
            target_states, target_carriers, metadata, created_at, updated_at
          ) VALUES (
            'aep', 'aep_default', 'aep_template', 'aep_sms_template',
            NULL, NULL, NULL, NULL, 'ALL', 'ALL', '{}',
            CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
          )
        |} in
        execute_sql_no_result insert_instance_sql
    | Ok _ -> Ok () (* AEP instance already exists *)
    | Error err -> Error err
  in

  match ensure_performance_indexes () with
  | Ok () -> 
      (match ensure_aep_campaign () with
       | Ok () -> ensure_aep_instance ()
       | Error err -> Error err)
  | Error err -> Error err

(* Close database connection *)
let close_database () =
  match !db_handle with
  | None -> ()
  | Some db ->
      ignore (Sqlite3.db_close db);
      db_handle := None 

(* Campaign database functions *)

(* Parse campaign_type_config from database row with new fields *)
let parse_campaign_type_config_row = function
  | [name; respect_exclusion_windows; enable_followups; days_before_event; target_all_contacts; priority; active; spread_evenly; skip_failed_underwriting] ->
      (try
        Some {
          name;
          respect_exclusion_windows = (respect_exclusion_windows = "1");
          enable_followups = (enable_followups = "1");
          days_before_event = int_of_string days_before_event;
          target_all_contacts = (target_all_contacts = "1");
          priority = int_of_string priority;
          active = (active = "1");
          spread_evenly = (spread_evenly = "1");
          skip_failed_underwriting = (skip_failed_underwriting = "1");
        }
      with _ -> None)
  | [name; respect_exclusion_windows; enable_followups; days_before_event; target_all_contacts; priority; active; spread_evenly] ->
      (* Backward compatibility for old schema without skip_failed_underwriting *)
      (try
        Some {
          name;
          respect_exclusion_windows = (respect_exclusion_windows = "1");
          enable_followups = (enable_followups = "1");
          days_before_event = int_of_string days_before_event;
          target_all_contacts = (target_all_contacts = "1");
          priority = int_of_string priority;
          active = (active = "1");
          spread_evenly = (spread_evenly = "1");
          skip_failed_underwriting = false;
        }
      with _ -> None)
  | _ -> None

(* Parse campaign_instance from database row with new fields *)
let parse_campaign_instance_row = function
  | [id_str; campaign_type; instance_name; email_template; sms_template; active_start_date; active_end_date; spread_start_date; spread_end_date; target_states; target_carriers; metadata; created_at; updated_at] ->
      (try
        let id = int_of_string id_str in
        let active_start_date_opt = 
          if active_start_date = "" || active_start_date = "NULL" then None
          else Some (parse_date active_start_date)
        in
        let active_end_date_opt = 
          if active_end_date = "" || active_end_date = "NULL" then None
          else Some (parse_date active_end_date)
        in
        let spread_start_date_opt = 
          if spread_start_date = "" || spread_start_date = "NULL" then None
          else Some (parse_date spread_start_date)
        in
        let spread_end_date_opt = 
          if spread_end_date = "" || spread_end_date = "NULL" then None
          else Some (parse_date spread_end_date)
        in
        let email_template_opt = if email_template = "" || email_template = "NULL" then None else Some email_template in
        let sms_template_opt = if sms_template = "" || sms_template = "NULL" then None else Some sms_template in
        let target_states_opt = if target_states = "" || target_states = "NULL" then None else Some target_states in
        let target_carriers_opt = if target_carriers = "" || target_carriers = "NULL" then None else Some target_carriers in
        let metadata_opt = if metadata = "" || metadata = "NULL" then None else Some metadata in
        Some {
          id;
          campaign_type;
          instance_name;
          email_template = email_template_opt;
          sms_template = sms_template_opt;
          active_start_date = active_start_date_opt;
          active_end_date = active_end_date_opt;
          spread_start_date = spread_start_date_opt;
          spread_end_date = spread_end_date_opt;
          target_states = target_states_opt;
          target_carriers = target_carriers_opt;
          metadata = metadata_opt;
          created_at = parse_datetime created_at;
          updated_at = parse_datetime updated_at;
        }
      with _ -> None)
  | [id_str; campaign_type; instance_name; email_template; sms_template; active_start_date; active_end_date; spread_start_date; spread_end_date; metadata; created_at; updated_at] ->
      (* Backward compatibility for old schema without targeting fields *)
      (try
        let id = int_of_string id_str in
        let active_start_date_opt = 
          if active_start_date = "" || active_start_date = "NULL" then None
          else Some (parse_date active_start_date)
        in
        let active_end_date_opt = 
          if active_end_date = "" || active_end_date = "NULL" then None
          else Some (parse_date active_end_date)
        in
        let spread_start_date_opt = 
          if spread_start_date = "" || spread_start_date = "NULL" then None
          else Some (parse_date spread_start_date)
        in
        let spread_end_date_opt = 
          if spread_end_date = "" || spread_end_date = "NULL" then None
          else Some (parse_date spread_end_date)
        in
        let email_template_opt = if email_template = "" || email_template = "NULL" then None else Some email_template in
        let sms_template_opt = if sms_template = "" || sms_template = "NULL" then None else Some sms_template in
        let metadata_opt = if metadata = "" || metadata = "NULL" then None else Some metadata in
        Some {
          id;
          campaign_type;
          instance_name;
          email_template = email_template_opt;
          sms_template = sms_template_opt;
          active_start_date = active_start_date_opt;
          active_end_date = active_end_date_opt;
          spread_start_date = spread_start_date_opt;
          spread_end_date = spread_end_date_opt;
          target_states = None;
          target_carriers = None;
          metadata = metadata_opt;
          created_at = parse_datetime created_at;
          updated_at = parse_datetime updated_at;
        }
      with _ -> None)
  | _ -> None

(* Parse contact_campaign from database row *)
let parse_contact_campaign_row = function
  | [id_str; contact_id_str; campaign_instance_id_str; trigger_date; status; metadata; created_at; updated_at] ->
      (try
        let id = int_of_string id_str in
        let contact_id = int_of_string contact_id_str in
        let campaign_instance_id = int_of_string campaign_instance_id_str in
        let trigger_date_opt = 
          if trigger_date = "" || trigger_date = "NULL" then None
          else Some (parse_date trigger_date)
        in
        let metadata_opt = if metadata = "" || metadata = "NULL" then None else Some metadata in
        Some {
          id;
          contact_id;
          campaign_instance_id;
          trigger_date = trigger_date_opt;
          status;
          metadata = metadata_opt;
          created_at = parse_datetime created_at;
          updated_at = parse_datetime updated_at;
        }
      with _ -> None)
  | _ -> None

(* Get active campaign instances for current date - updated for new fields *)
let get_active_campaign_instances () =
  let today = current_date () in
  let today_str = string_of_date today in
  
  let query = Printf.sprintf {|
    SELECT id, campaign_type, instance_name, 
           COALESCE(email_template, '') as email_template, 
           COALESCE(sms_template, '') as sms_template,
           COALESCE(active_start_date, '') as active_start_date, 
           COALESCE(active_end_date, '') as active_end_date, 
           COALESCE(spread_start_date, '') as spread_start_date, 
           COALESCE(spread_end_date, '') as spread_end_date,
           COALESCE(target_states, '') as target_states,
           COALESCE(target_carriers, '') as target_carriers,
           COALESCE(metadata, '') as metadata, 
           created_at, updated_at
    FROM campaign_instances
    WHERE (active_start_date IS NULL OR active_start_date <= '%s')
    AND (active_end_date IS NULL OR active_end_date >= '%s')
    ORDER BY id
  |} today_str today_str in
  
  match execute_sql_safe query with
  | Error err -> Error err
  | Ok rows ->
      let instances = List.filter_map parse_campaign_instance_row rows in
      Ok instances

(* Get campaign type configuration - updated for new fields *)
let get_campaign_type_config campaign_type_name =
  let query = Printf.sprintf {|
    SELECT name, 
           COALESCE(respect_exclusion_windows, 1) as respect_exclusion_windows, 
           COALESCE(enable_followups, 1) as enable_followups, 
           COALESCE(days_before_event, 0) as days_before_event,
           COALESCE(target_all_contacts, 0) as target_all_contacts, 
           COALESCE(priority, 10) as priority, 
           COALESCE(active, 1) as active, 
           COALESCE(spread_evenly, 0) as spread_evenly,
           COALESCE(skip_failed_underwriting, 0) as skip_failed_underwriting
    FROM campaign_types
    WHERE name = '%s' AND COALESCE(active, 1) = 1
  |} campaign_type_name in
  
  match execute_sql_safe query with
  | Error err -> Error err
  | Ok [row] ->
      (match parse_campaign_type_config_row row with
       | Some config -> Ok config
       | None -> Error (ParseError "Invalid campaign type config"))
  | Ok [] -> Error (ParseError "Campaign type not found")
  | Ok _ -> Error (ParseError "Multiple campaign types found")

(* Get contact campaigns for a specific campaign instance *)
let get_contact_campaigns_for_instance campaign_instance_id =
  let query = Printf.sprintf {|
    SELECT id, contact_id, campaign_instance_id, trigger_date, status, metadata, created_at, updated_at
    FROM contact_campaigns
    WHERE campaign_instance_id = %d
    AND status = 'pending'
    ORDER BY contact_id
  |} campaign_instance_id in
  
  match execute_sql_safe query with
  | Error err -> Error err
  | Ok rows ->
      let contact_campaigns = List.filter_map parse_contact_campaign_row rows in
      Ok contact_campaigns

(* Get all contacts for "target_all_contacts" campaigns *)
let get_all_contacts_for_campaign () =
  let query = {|
    SELECT id, email, zip_code, state, birth_date, effective_date
    FROM contacts
    WHERE email IS NOT NULL AND email != '' 
    AND zip_code IS NOT NULL AND zip_code != ''
    ORDER BY id
  |} in
  
  match execute_sql_safe query with
  | Error err -> Error err
  | Ok rows ->
      let contacts = List.filter_map parse_contact_row rows in
      Ok contacts 

(* Helper function to parse state/carrier targeting strings *)
let parse_targeting_list targeting_str =
  if targeting_str = "" || targeting_str = "NULL" || targeting_str = "ALL" then
    `All
  else
    let items = String.split_on_char ',' targeting_str |> List.map String.trim in
    `Specific items

(* Check if contact matches campaign targeting criteria *)
let contact_matches_targeting contact campaign_instance =
  let state_matches = match campaign_instance.target_states with
    | None -> true
    | Some target_states ->
        (match parse_targeting_list target_states with
         | `All -> true
         | `Specific states ->
             (match contact.state with
              | None -> false
              | Some contact_state -> List.mem (string_of_state contact_state) states))
  in
  
  let carrier_matches = match campaign_instance.target_carriers with
    | None -> true
    | Some target_carriers ->
        (match parse_targeting_list target_carriers with
         | `All -> true
         | `Specific carriers ->
             (match contact.carrier with
              | None -> false
              | Some contact_carrier -> List.mem contact_carrier carriers))
  in
  
  state_matches && carrier_matches

(* Get all contacts for campaign with targeting filters *)
let get_contacts_for_campaign campaign_instance =
  match get_all_contacts () with
  | Error err -> Error err
  | Ok all_contacts ->
      let filtered_contacts = List.filter (fun contact -> contact_matches_targeting contact campaign_instance) all_contacts in
      Ok filtered_contacts

================
File: lib/db/database.mli
================
(* Database interface for the email scheduler *)

(* Error handling *)
type db_error = 
  | SqliteError of string
  | ParseError of string
  | ConnectionError of string

val string_of_db_error : db_error -> string

(* Database initialization and management *)
val set_db_path : string -> unit
val initialize_database : unit -> (unit, db_error) result
val close_database : unit -> unit

(* Contact queries *)
val get_contacts_in_scheduling_window : int -> int -> (Types.contact list, db_error) result
val get_all_contacts : unit -> (Types.contact list, db_error) result
val get_total_contact_count : unit -> (int, db_error) result

(* Schedule management - smart update functions *)
val smart_update_schedules : Types.email_schedule list -> string -> (int, db_error) result
val update_email_schedules : ?use_smart_update:bool -> Types.email_schedule list -> string -> (int, db_error) result

(* Legacy schedule management functions *)
val clear_pre_scheduled_emails : unit -> (int, db_error) result
val batch_insert_schedules_optimized : Types.email_schedule list -> (int, db_error) result
val batch_insert_schedules_chunked : Types.email_schedule list -> int -> (int, db_error) result

(* Follow-up and interaction tracking *)
val get_sent_emails_for_followup : int -> ((int * string * string * int) list, db_error) result
val get_contact_interactions : int -> string -> (bool * bool, db_error) result

(* Performance optimization *)
val optimize_sqlite_for_bulk_inserts : unit -> (unit, db_error) result
val restore_sqlite_safety : unit -> (unit, db_error) result
val ensure_performance_indexes : unit -> (unit, db_error) result

(* Low-level database access for testing *)
val execute_sql_safe : string -> (string list list, db_error) result
val execute_sql_no_result : string -> (unit, db_error) result
val batch_insert_with_prepared_statement : string -> string array list -> (int, db_error) result

(* Campaign system functions *)
val get_active_campaign_instances : unit -> (Types.campaign_instance list, db_error) result
val get_campaign_type_config : string -> (Types.campaign_type_config, db_error) result
val get_contact_campaigns_for_instance : int -> (Types.contact_campaign list, db_error) result
val get_all_contacts_for_campaign : unit -> (Types.contact list, db_error) result
val get_contacts_for_campaign : Types.campaign_instance -> (Types.contact list, db_error) result

================
File: lib/domain/contact.ml
================
open Types

let validate_email email =
  let email_regex = Str.regexp "^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z][a-zA-Z]+$" in
  Str.string_match email_regex email 0

let validate_zip_code zip =
  let zip_regex = Str.regexp "^[0-9][0-9][0-9][0-9][0-9]\\(-[0-9][0-9][0-9][0-9]\\)?$" in
  Str.string_match zip_regex zip 0

let state_from_zip_code zip_code =
  Zip_data.ensure_loaded ();
  Zip_data.state_from_zip_code zip_code

let validate_contact contact =
  let errors = ref [] in
  
  if not (validate_email contact.email) then
    errors := "Invalid email format" :: !errors;
  
  begin match contact.zip_code with
  | Some zip when not (validate_zip_code zip) ->
      errors := "Invalid ZIP code format" :: !errors
  | Some zip when contact.state = None ->
      begin match state_from_zip_code zip with
      | None -> errors := "Cannot determine state from ZIP code" :: !errors
      | _ -> ()
      end
  | None -> errors := "Missing ZIP code" :: !errors
  | _ -> ()
  end;
  
  match !errors with
  | [] -> Ok contact
  | errs -> Error (String.concat "; " errs)

let update_contact_state contact =
  match contact.zip_code with
  | Some zip -> { contact with state = state_from_zip_code zip }
  | None -> contact

let is_valid_for_scheduling contact =
  match validate_contact contact with
  | Ok c -> c.state <> None
  | Error _ -> false

(* Enhanced validation for anniversary emails that considers organization config *)
let is_valid_for_anniversary_scheduling org_config contact =
  (* Basic email validation *)
  if not (validate_email contact.email) then
    false
  else
    (* For anniversary emails, we need location data unless org allows universal sending *)
    match contact.zip_code, contact.state with
    | None, None -> org_config.send_without_zipcode_for_universal
    | Some zip, None -> 
        (* Try to get state from zip *)
        (match state_from_zip_code zip with
         | Some _ -> true
         | None -> org_config.send_without_zipcode_for_universal)
    | _, Some _ -> true (* Has state, so valid *)

(* Enhanced validation for campaigns that considers targeting and organization config *)
let is_valid_for_campaign_scheduling org_config campaign_instance contact =
  (* Basic email validation *)
  if not (validate_email contact.email) then
    false
  else
    (* Check if we need location data for this campaign *)
    let requires_location = match (campaign_instance.target_states, campaign_instance.target_carriers) with
      | (None, None) -> false (* Universal campaign *)
      | (Some states, _) when states = "ALL" -> false (* Explicitly universal *)
      | (_, Some carriers) when carriers = "ALL" -> false (* Explicitly universal *)
      | _ -> true (* Has targeting constraints *)
    in
    
    if requires_location then
      (* Campaign has targeting - need valid location data *)
      contact.zip_code <> None || contact.state <> None
    else
      (* Universal campaign - send even without zip code if org allows *)
      org_config.send_without_zipcode_for_universal

let is_zip_code_valid zip =
  Zip_data.ensure_loaded ();
  Zip_data.is_valid_zip_code zip

================
File: lib/domain/types.ml
================
type state = 
  | CA | CT | ID | KY | MA | MD | MO | NV 
  | NY | OK | OR | VA | WA 
  | Other of string

type anniversary_email = 
  | Birthday
  | EffectiveDate
  | PostWindow

type campaign_email = {
  campaign_type: string;
  instance_id: int;
  respect_exclusions: bool;
  days_before_event: int;
  priority: int;
}

type followup_type =
  | Cold
  | ClickedNoHQ
  | HQNoYes
  | HQWithYes

type email_type =
  | Anniversary of anniversary_email
  | Campaign of campaign_email
  | Followup of followup_type

type schedule_status =
  | PreScheduled
  | Skipped of string
  | Scheduled
  | Processing
  | Sent

type contact = {
  id: int;
  email: string;
  zip_code: string option;
  state: state option;
  birthday: Date_time.date option;
  effective_date: Date_time.date option;
  carrier: string option; (* Insurance carrier code *)
  failed_underwriting: bool; (* Whether contact failed health questions *)
}

type email_schedule = {
  contact_id: int;
  email_type: email_type;
  scheduled_date: Date_time.date;
  scheduled_time: Date_time.time;
  status: schedule_status;
  priority: int;
  template_id: string option;
  campaign_instance_id: int option;
  scheduler_run_id: string;
}

let state_of_string = function
  | "CA" -> CA | "CT" -> CT | "ID" -> ID | "KY" -> KY
  | "MA" -> MA | "MD" -> MD | "MO" -> MO | "NV" -> NV
  | "NY" -> NY | "OK" -> OK | "OR" -> OR | "VA" -> VA
  | "WA" -> WA | s -> Other s

let string_of_state = function
  | CA -> "CA" | CT -> "CT" | ID -> "ID" | KY -> "KY"
  | MA -> "MA" | MD -> "MD" | MO -> "MO" | NV -> "NV"
  | NY -> "NY" | OK -> "OK" | OR -> "OR" | VA -> "VA"
  | WA -> "WA" | Other s -> s

let string_of_anniversary_email = function
  | Birthday -> "birthday"
  | EffectiveDate -> "effective_date"
  | PostWindow -> "post_window"

let anniversary_email_of_string = function
  | "birthday" -> Birthday
  | "effective_date" -> EffectiveDate
  | "post_window" -> PostWindow
  | s -> failwith ("Unknown anniversary email type: " ^ s)

let string_of_followup_type = function
  | Cold -> "cold"
  | ClickedNoHQ -> "clicked_no_hq"
  | HQNoYes -> "hq_no_yes"
  | HQWithYes -> "hq_with_yes"

let followup_type_of_string = function
  | "cold" -> Cold
  | "clicked_no_hq" -> ClickedNoHQ
  | "hq_no_yes" -> HQNoYes
  | "hq_with_yes" -> HQWithYes
  | s -> failwith ("Unknown followup type: " ^ s)

let string_of_email_type = function
  | Anniversary a -> string_of_anniversary_email a
  | Campaign c -> Printf.sprintf "campaign_%s_%d" c.campaign_type c.instance_id
  | Followup f -> Printf.sprintf "followup_%s" (string_of_followup_type f)

let email_type_of_string str =
  if String.length str >= 8 && String.sub str 0 8 = "campaign" then
    (* Parse campaign emails: "campaign_type_instanceid" *)
    let parts = String.split_on_char '_' str in
    match parts with
    | "campaign" :: campaign_type :: instance_id_str :: _ ->
        let instance_id = int_of_string instance_id_str in
        (* Default campaign values - in a real implementation these would be retrieved from DB *)
        Campaign {
          campaign_type;
          instance_id;
          respect_exclusions = true;
          days_before_event = 30;
          priority = 10;
        }
    | _ -> failwith ("Invalid campaign email type format: " ^ str)
  else if String.length str >= 8 && String.sub str 0 8 = "followup" then
    (* Parse followup emails: "followup_type" *)
    let parts = String.split_on_char '_' str in
    match parts with
    | "followup" :: followup_parts ->
        let followup_type_str = String.concat "_" followup_parts in
        Followup (followup_type_of_string followup_type_str)
    | _ -> failwith ("Invalid followup email type format: " ^ str)
  else
    (* Parse anniversary emails *)
    Anniversary (anniversary_email_of_string str)

let string_of_schedule_status = function
  | PreScheduled -> "pre-scheduled"
  | Skipped reason -> Printf.sprintf "skipped:%s" reason
  | Scheduled -> "scheduled"
  | Processing -> "processing"
  | Sent -> "sent"

let priority_of_email_type = function
  | Anniversary Birthday -> 10
  | Anniversary EffectiveDate -> 20
  | Anniversary PostWindow -> 40
  | Campaign c -> c.priority
  | Followup _ -> 50

(* Error types for comprehensive error handling *)
type scheduler_error =
  | DatabaseError of string
  | InvalidContactData of { contact_id: int; reason: string }
  | ConfigurationError of string
  | ValidationError of string
  | DateCalculationError of string
  | LoadBalancingError of string
  | UnexpectedError of exn

type 'a scheduler_result = ('a, scheduler_error) result

let string_of_error = function
  | DatabaseError msg -> Printf.sprintf "Database error: %s" msg
  | InvalidContactData { contact_id; reason } -> 
      Printf.sprintf "Invalid contact data (ID %d): %s" contact_id reason
  | ConfigurationError msg -> Printf.sprintf "Configuration error: %s" msg
  | ValidationError msg -> Printf.sprintf "Validation error: %s" msg
  | DateCalculationError msg -> Printf.sprintf "Date calculation error: %s" msg
  | LoadBalancingError msg -> Printf.sprintf "Load balancing error: %s" msg
  | UnexpectedError exn -> Printf.sprintf "Unexpected error: %s" (Printexc.to_string exn)

(* Campaign system types *)
type campaign_type_config = {
  name: string;
  respect_exclusion_windows: bool;
  enable_followups: bool;
  days_before_event: int;
  target_all_contacts: bool;
  priority: int;
  active: bool;
  spread_evenly: bool;
  skip_failed_underwriting: bool;
}

type campaign_instance = {
  id: int;
  campaign_type: string;
  instance_name: string;
  email_template: string option;
  sms_template: string option;
  active_start_date: Date_time.date option;
  active_end_date: Date_time.date option;
  spread_start_date: Date_time.date option;
  spread_end_date: Date_time.date option;
  target_states: string option;
  target_carriers: string option;
  metadata: string option;
  created_at: Date_time.datetime;
  updated_at: Date_time.datetime;
}

type contact_campaign = {
  id: int;
  contact_id: int;
  campaign_instance_id: int;
  trigger_date: Date_time.date option;
  status: string;
  metadata: string option;
  created_at: Date_time.datetime;
  updated_at: Date_time.datetime;
}

(* Audit trail types *)
type scheduler_checkpoint = {
  id: int;
  run_timestamp: Date_time.datetime;
  scheduler_run_id: string;
  contacts_checksum: string;
  schedules_before_checksum: string option;
  schedules_after_checksum: string option;
  contacts_processed: int option;
  emails_scheduled: int option;
  emails_skipped: int option;
  status: string;
  error_message: string option;
  completed_at: Date_time.datetime option;
}

(* Load balancing types *)
type daily_stats = {
  date: Date_time.date;
  total_count: int;
  ed_count: int;
  campaign_count: int;
  anniversary_count: int;
  over_threshold: bool;
}

type load_balancing_config = {
  daily_send_percentage_cap: float;
  ed_daily_soft_limit: int;
  ed_smoothing_window_days: int;
  catch_up_spread_days: int;
  overage_threshold: float;
  total_contacts: int;
}

type distribution_analysis = {
  total_emails: int;
  total_days: int;
  avg_per_day: float;
  max_day: int;
  min_day: int;
  distribution_variance: int;
}

(* Organization-level configuration for scheduling flexibility *)
type organization_config = {
  enable_post_window_emails: bool;
  effective_date_first_email_months: int;
  exclude_failed_underwriting_global: bool;
  send_without_zipcode_for_universal: bool;
}

================
File: lib/rules/dsl.ml
================
open Types

type window = {
  before_days: int;
  after_days: int;
  use_month_start: bool;
}

type rule =
  | BirthdayWindow of window
  | EffectiveDateWindow of window
  | YearRoundExclusion
  | NoExclusion

let birthday_window ~before ~after ?(use_month_start=false) () =
  BirthdayWindow { before_days = before; after_days = after; use_month_start }

let effective_date_window ~before ~after () =
  EffectiveDateWindow { before_days = before; after_days = after; use_month_start = false }

let year_round = YearRoundExclusion
let no_exclusion = NoExclusion

let rules_for_state = function
  | CA -> birthday_window ~before:30 ~after:60 ()
  | ID -> birthday_window ~before:0 ~after:63 ()
  | KY -> birthday_window ~before:0 ~after:60 ()
  | MD -> birthday_window ~before:0 ~after:30 ()
  | NV -> birthday_window ~before:0 ~after:60 ~use_month_start:true ()
  | OK -> birthday_window ~before:0 ~after:60 ()
  | OR -> birthday_window ~before:0 ~after:31 ()
  | VA -> birthday_window ~before:0 ~after:30 ()
  | MO -> effective_date_window ~before:30 ~after:33 ()
  | CT | MA | NY | WA -> year_round
  | Other _ -> no_exclusion

let has_exclusion_window state =
  match rules_for_state state with
  | NoExclusion -> false
  | _ -> true

let is_year_round_exclusion state =
  match rules_for_state state with
  | YearRoundExclusion -> true
  | _ -> false

let get_window_for_email_type state email_type =
  match rules_for_state state, email_type with
  | BirthdayWindow w, Anniversary Birthday -> Some w
  | EffectiveDateWindow w, Anniversary EffectiveDate -> Some w
  | YearRoundExclusion, Anniversary _ -> None
  | _, _ -> None

================
File: lib/rules/exclusion_window.ml
================
open Dsl
open Date_time
open Types
open Date_calc

type exclusion_result = 
  | NotExcluded
  | Excluded of { reason: string; window_end: Date_time.date option }

(** 
 * [check_birthday_exclusion]: Checks if a date falls within birthday exclusion window
 * 
 * Purpose:
 *   Determines if email should be excluded due to state-specific birthday exclusion
 *   rules that prevent sending emails during sensitive periods around birthdays.
 * 
 * Parameters:
 *   - contact: Contact record containing state and birthday information
 *   - check_date: Date to evaluate against exclusion window
 * 
 * Returns:
 *   exclusion_result indicating exclusion status with reason and window end date
 * 
 * Business Logic:
 *   - Requires both state and birthday data to apply exclusion
 *   - Looks up state-specific window configuration for birthday emails
 *   - Calculates next birthday anniversary relative to check date
 *   - Determines if check date falls within configured exclusion window
 *   - Provides specific exclusion reason including state information
 * 
 * Usage Example:
 *   Called by check_exclusion_window as part of comprehensive exclusion evaluation
 * 
 * Error Cases:
 *   - Returns NotExcluded if state or birthday data missing
 *   - Returns NotExcluded if no exclusion window configured for state
 * 
 * @business_rule @state_machine
 *)
let check_birthday_exclusion contact check_date =
  match contact.state, contact.birthday with
  | Some state, Some birthday ->
      begin match get_window_for_email_type state (Anniversary Birthday) with
      | Some window ->
          let next_bday = next_anniversary check_date birthday in
          if in_exclusion_window check_date window next_bday then
            let window_end = add_days next_bday window.after_days in
            Excluded { 
              reason = Printf.sprintf "Birthday exclusion window for %s" (string_of_state state);
              window_end = Some window_end 
            }
          else
            NotExcluded
      | None -> NotExcluded
      end
  | _ -> NotExcluded

(** 
 * [check_effective_date_exclusion]: Checks if date falls within effective date exclusion window
 * 
 * Purpose:
 *   Determines if email should be excluded due to state-specific effective date exclusion
 *   rules that prevent sending emails during sensitive periods around policy anniversaries.
 * 
 * Parameters:
 *   - contact: Contact record containing state and effective_date information
 *   - check_date: Date to evaluate against exclusion window
 * 
 * Returns:
 *   exclusion_result indicating exclusion status with reason and window end date
 * 
 * Business Logic:
 *   - Requires both state and effective date data to apply exclusion
 *   - Looks up state-specific window configuration for effective date emails
 *   - Calculates next effective date anniversary relative to check date
 *   - Determines if check date falls within configured exclusion window
 *   - Provides specific exclusion reason including state information
 * 
 * Usage Example:
 *   Called by check_exclusion_window as part of comprehensive exclusion evaluation
 * 
 * Error Cases:
 *   - Returns NotExcluded if state or effective_date data missing
 *   - Returns NotExcluded if no exclusion window configured for state
 * 
 * @business_rule @state_machine
 *)
let check_effective_date_exclusion contact check_date =
  match contact.state, contact.effective_date with
  | Some state, Some ed ->
      begin match get_window_for_email_type state (Anniversary EffectiveDate) with
      | Some window ->
          let next_ed = next_anniversary check_date ed in
          if in_exclusion_window check_date window next_ed then
            let window_end = add_days next_ed window.after_days in
            Excluded { 
              reason = Printf.sprintf "Effective date exclusion window for %s" (string_of_state state);
              window_end = Some window_end 
            }
          else
            NotExcluded
      | None -> NotExcluded
      end
  | _ -> NotExcluded

(** 
 * [check_year_round_exclusion]: Checks if contact's state has year-round email exclusion
 * 
 * Purpose:
 *   Identifies states with permanent exclusion policies that prevent all anniversary
 *   emails regardless of date, typically due to regulatory restrictions.
 * 
 * Parameters:
 *   - contact: Contact record containing state information
 * 
 * Returns:
 *   exclusion_result indicating if state has year-round exclusion policy
 * 
 * Business Logic:
 *   - Checks if contact's state is configured for year-round exclusion
 *   - Returns permanent exclusion with no end date for applicable states
 *   - Provides state-specific exclusion reason for audit purposes
 *   - Takes precedence over date-based exclusion windows
 * 
 * Usage Example:
 *   Called first by check_exclusion_window to check for permanent exclusions
 * 
 * Error Cases:
 *   - Returns NotExcluded if contact has no state information
 *   - Returns NotExcluded if state not configured for year-round exclusion
 * 
 * @business_rule @state_machine
 *)
let check_year_round_exclusion contact =
  match contact.state with
  | Some state when is_year_round_exclusion state ->
      Excluded { 
        reason = Printf.sprintf "Year-round exclusion for %s" (string_of_state state);
        window_end = None 
      }
  | _ -> NotExcluded

(** 
 * [check_exclusion_window]: Main exclusion evaluation function for comprehensive rule checking
 * 
 * Purpose:
 *   Orchestrates all exclusion rule evaluations in priority order to determine if an
 *   email should be excluded for a contact on a specific date.
 * 
 * Parameters:
 *   - contact: Contact record with state, birthday, and effective_date information
 *   - check_date: Date to evaluate against all applicable exclusion rules
 * 
 * Returns:
 *   exclusion_result with first applicable exclusion or NotExcluded if none apply
 * 
 * Business Logic:
 *   - Evaluates exclusions in priority order (year-round, birthday, effective date)
 *   - Returns first exclusion match without checking subsequent rules
 *   - Provides comprehensive state-based compliance checking
 *   - Ensures regulatory compliance across all anniversary email types
 * 
 * Usage Example:
 *   Called by should_skip_email and email scheduling functions for exclusion decisions
 * 
 * Error Cases:
 *   - Returns NotExcluded if contact lacks required data for any rule evaluation
 *   - Handles missing state/date information gracefully
 * 
 * @business_rule @integration_point
 *)
let check_exclusion_window contact check_date =
  match check_year_round_exclusion contact with
  | Excluded _ as result -> result
  | NotExcluded ->
      match check_birthday_exclusion contact check_date with
      | Excluded _ as result -> result
      | NotExcluded -> check_effective_date_exclusion contact check_date

(** 
 * [should_skip_email]: Determines if specific email type should be skipped for contact
 * 
 * Purpose:
 *   Makes final decision on email exclusion considering both exclusion rules and
 *   email type-specific policies like campaign respect_exclusions settings.
 * 
 * Parameters:
 *   - contact: Contact record for exclusion rule evaluation
 *   - email_type: Type of email being considered (Campaign, Anniversary, etc.)
 *   - check_date: Scheduled date for the email
 * 
 * Returns:
 *   Boolean indicating if email should be skipped (true) or sent (false)
 * 
 * Business Logic:
 *   - Campaign emails with respect_exclusions=false bypass all exclusion rules
 *   - PostWindow anniversary emails always bypass exclusion rules
 *   - All other emails subject to standard exclusion window evaluation
 *   - Provides final gatekeeper for email sending decisions
 * 
 * Usage Example:
 *   Called by email scheduling functions before creating email schedules
 * 
 * Error Cases:
 *   - Defaults to exclusion rule evaluation for unknown email types
 *   - Returns false (don't skip) if exclusion evaluation returns NotExcluded
 * 
 * @business_rule @integration_point
 *)
let should_skip_email contact email_type check_date =
  match email_type with
  | Campaign c when not c.respect_exclusions -> false
  | Anniversary PostWindow -> false
  | _ ->
      match check_exclusion_window contact check_date with
      | NotExcluded -> false
      | Excluded _ -> true

(** 
 * [get_post_window_date]: Calculates when post-exclusion window email can be sent
 * 
 * Purpose:
 *   Determines the earliest date when a make-up email can be sent after exclusion
 *   windows end, enabling recovery of missed anniversary communications.
 * 
 * Parameters:
 *   - contact: Contact record for exclusion window evaluation
 * 
 * Returns:
 *   Option date representing earliest post-window send date, or None if no exclusions
 * 
 * Business Logic:
 *   - Evaluates all current exclusion windows (birthday and effective date)
 *   - Finds the latest ending exclusion window to avoid conflicts
 *   - Adds one day buffer after window end for post-window email
 *   - Enables recovery communication after exclusion periods
 * 
 * Usage Example:
 *   Called by calculate_post_window_emails to schedule make-up communications
 * 
 * Error Cases:
 *   - Returns None if no active exclusion windows found
 *   - Handles missing exclusion window end dates gracefully
 * 
 * @business_rule @data_flow
 *)
let get_post_window_date contact =
  let today = current_date () in
  let exclusions = [
    check_birthday_exclusion contact today;
    check_effective_date_exclusion contact today
  ] in
  
  let latest_window_end = 
    List.fold_left (fun acc exc ->
      match exc, acc with
      | Excluded { window_end = Some end_date; _ }, None -> Some end_date
      | Excluded { window_end = Some end_date; _ }, Some acc_date ->
          if compare_date end_date acc_date > 0 then Some end_date else Some acc_date
      | _ -> acc
    ) None exclusions
  in
  
  match latest_window_end with
  | Some end_date -> Some (add_days end_date 1)
  | None -> None

================
File: lib/scheduling/date_calc.ml
================
open Date_time
open Dsl

let pre_window_buffer_days = 60

let in_exclusion_window check_date window anchor_date =
  let window_start_offset = -(window.before_days + pre_window_buffer_days) in
  let window_end_offset = window.after_days in
  
  let check_year anchor =
    let base_date = 
      if window.use_month_start then
        let (year, month, _) = anchor in
        (year, month, 1)  (* Use first day of month *)
      else
        anchor
    in
    let window_start = add_days base_date window_start_offset in
    let window_end = add_days base_date window_end_offset in
    compare_date check_date window_start >= 0 &&
    compare_date check_date window_end <= 0
  in
  
  check_year anchor_date ||
  let (year, month, day) = anchor_date in
  let prev_year_anchor = (year - 1, month, day) in
  let next_year_anchor = (year + 1, month, day) in
  check_year prev_year_anchor || check_year next_year_anchor

let calculate_jitter ~contact_id ~event_type ~year ~window_days =
  let hash_input = Printf.sprintf "%d-%s-%d" contact_id event_type year in
  (Hashtbl.hash hash_input) mod window_days - (window_days / 2)

let schedule_time_ct hour minute =
  ((hour, minute, 0), 0)  (* ((hour, minute, second), tz_offset) - CT is 0 offset from our system time *)

================
File: lib/scheduling/email_scheduler.ml
================
open Types
open Date_time
open Date_calc
open Exclusion_window
open Load_balancer
open Config
open Database

type scheduling_context = {
  config: Config.t;
  run_id: string;
  start_time: datetime;
  load_balancing_config: load_balancing_config;
}

(** 
 * [generate_run_id]: Generates a unique run identifier for the current scheduling execution
 * 
 * Purpose:
 *   Creates a timestamp-based unique identifier for tracking a specific scheduler run.
 *   This ID is used to group all email schedules created during a single execution.
 * 
 * Parameters:
 *   - None
 * 
 * Returns:
 *   String in format "run_YYYYMMDD_HHMMSS" representing the current timestamp
 * 
 * Business Logic:
 *   - Uses current datetime to ensure uniqueness across runs
 *   - Provides audit trail for scheduled emails
 *   - Enables tracking and debugging of specific scheduler executions
 * 
 * Usage Example:
 *   Called by create_context when initializing scheduling context
 * 
 * Error Cases:
 *   - None expected (system time should always be available)
 * 
 * @integration_point
 *)
let generate_run_id () =
  let now = current_datetime () in
  let (date, ((hour, minute, second), _)) = Ptime.to_date_time now in
  let (year, month, day) = date in
  Printf.sprintf "run_%04d%02d%02d_%02d%02d%02d" 
    year month day hour minute second

(** 
 * [create_context]: Creates a complete scheduling context for the current run
 * 
 * Purpose:
 *   Initializes all necessary components for email scheduling including configuration,
 *   unique run ID, timing, and load balancing settings based on total contact count.
 * 
 * Parameters:
 *   - config: Configuration object containing organization settings and email timing
 *   - total_contacts: Total number of contacts to be processed for load balancing calculations
 * 
 * Returns:
 *   scheduling_context record with all initialized components
 * 
 * Business Logic:
 *   - Generates unique run ID for audit trail
 *   - Captures start time for performance tracking
 *   - Configures load balancing based on expected volume
 *   - Ensures consistent context across all scheduling operations
 * 
 * Usage Example:
 *   Called at the beginning of schedule_emails_streaming to initialize the session
 * 
 * Error Cases:
 *   - None expected (all dependencies should be available)
 * 
 * @integration_point @state_machine
 *)
let create_context config total_contacts =
  let run_id = generate_run_id () in
  let start_time = current_datetime () in
  let load_balancing_config = default_config total_contacts in
  { config; run_id; start_time; load_balancing_config }

(** 
 * [calculate_spread_date]: Calculates deterministic spread date for campaign emails
 * 
 * Purpose:
 *   Distributes campaign emails evenly across a date range using contact ID as seed
 *   to ensure consistent but scattered scheduling for campaigns with spread_evenly=true.
 * 
 * Parameters:
 *   - contact_id: Unique contact identifier used as distribution seed
 *   - spread_start_date: Start date of the spread period
 *   - spread_end_date: End date of the spread period
 * 
 * Returns:
 *   Date within the spread range, deterministically calculated for the contact
 * 
 * Business Logic:
 *   - Uses modulo operation on contact_id for deterministic distribution
 *   - Ensures each contact gets the same date on subsequent runs
 *   - Spreads load evenly across the available date range
 *   - Prevents clustering of campaign emails on specific dates
 * 
 * Usage Example:
 *   Called by calculate_campaign_emails when campaign_config.spread_evenly is true
 * 
 * Error Cases:
 *   - None expected (valid date range assumed to be provided)
 * 
 * @business_rule @performance
 *)
let calculate_spread_date contact_id spread_start_date spread_end_date =
  let start_date = spread_start_date in
  let end_date = spread_end_date in
  let total_days = diff_days end_date start_date + 1 in
  
  (* Use contact_id as seed for deterministic distribution *)
  let hash_value = contact_id mod total_days in
  add_days start_date hash_value

(** 
 * [should_exclude_contact]: Determines if contact should be excluded from campaign
 * 
 * Purpose:
 *   Evaluates organization-level and campaign-specific exclusion rules for failed
 *   underwriting contacts to ensure compliance with business policies.
 * 
 * Parameters:
 *   - config: Configuration containing organization exclusion settings
 *   - campaign_config: Campaign-specific configuration including exclusion rules
 *   - contact: Contact record with failed_underwriting flag
 * 
 * Returns:
 *   Option string - Some exclusion_reason if excluded, None if allowed
 * 
 * Business Logic:
 *   - Checks global organization policy for failed underwriting exclusion
 *   - Allows AEP campaigns even for failed underwriting when globally excluded
 *   - Respects campaign-specific failed underwriting skip settings
 *   - Provides specific exclusion reasons for audit purposes
 * 
 * Usage Example:
 *   Called by calculate_campaign_emails to filter contacts before scheduling
 * 
 * Error Cases:
 *   - None expected (all inputs should be valid)
 * 
 * @business_rule
 *)
let should_exclude_contact config campaign_config contact =
  (* Check global underwriting exclusion *)
  if config.organization.exclude_failed_underwriting_global && contact.failed_underwriting then
    (* Only allow AEP campaigns for failed underwriting contacts *)
    if campaign_config.name <> "aep" then
      Some "Failed underwriting - global exclusion"
    else
      None
  else if campaign_config.skip_failed_underwriting && contact.failed_underwriting then
    Some "Failed underwriting - campaign exclusion"
  else
    None

(** 
 * [is_contact_valid_for_scheduling]: Validates contact eligibility for campaign scheduling
 * 
 * Purpose:
 *   Determines if a contact has sufficient data for campaign scheduling based on
 *   email validity and location targeting requirements.
 * 
 * Parameters:
 *   - config: Configuration containing organization policies
 *   - campaign_instance: Campaign instance with targeting constraints
 *   - contact: Contact record with email, zip_code, and state information
 * 
 * Returns:
 *   Boolean indicating if contact is valid for this campaign
 * 
 * Business Logic:
 *   - Requires valid email address for all campaigns
 *   - Checks if campaign has targeting constraints (states/carriers)
 *   - For targeted campaigns, requires location data (zip or state)
 *   - For universal campaigns, respects organization policy on missing location data
 *   - Handles "ALL" targeting as universal campaigns
 * 
 * Usage Example:
 *   Called by calculate_campaign_emails to validate each contact
 * 
 * Error Cases:
 *   - Returns false for contacts with missing required data
 * 
 * @business_rule @data_flow
 *)
let is_contact_valid_for_scheduling config campaign_instance contact =
  (* Basic email validation *)
  if contact.email = "" then
    false
  else
    (* Check if we need zip code/state for this campaign *)
    let requires_location = match (campaign_instance.target_states, campaign_instance.target_carriers) with
      | (None, None) -> false (* Universal campaign *)
      | (Some states, _) when states = "ALL" -> false (* Explicitly universal *)
      | (_, Some carriers) when carriers = "ALL" -> false (* Explicitly universal *)
      | _ -> true (* Has targeting constraints *)
    in
    
    if requires_location then
      (* Campaign has targeting - need valid location data *)
      contact.zip_code <> None || contact.state <> None
    else
      (* Universal campaign - send even without zip code if org allows *)
      config.organization.send_without_zipcode_for_universal

(** 
 * [should_send_effective_date_email]: Determines if effective date email should be sent
 * 
 * Purpose:
 *   Evaluates whether sufficient time has passed since a contact's effective date
 *   to warrant sending anniversary emails based on organization configuration.
 * 
 * Parameters:
 *   - config: Configuration containing effective_date_first_email_months setting
 *   - _contact: Contact record (currently unused but preserved for future use)
 *   - effective_date: The contact's insurance effective date
 * 
 * Returns:
 *   Boolean indicating if effective date email should be sent
 * 
 * Business Logic:
 *   - Calculates months elapsed since effective date
 *   - Compares against organization minimum threshold
 *   - Prevents emails too soon after policy inception
 *   - Ensures regulatory compliance with timing requirements
 * 
 * Usage Example:
 *   Called by calculate_anniversary_emails before scheduling effective date anniversaries
 * 
 * Error Cases:
 *   - None expected (date calculations should be valid)
 * 
 * @business_rule
 *)
let should_send_effective_date_email config _contact effective_date =
  let today = current_date () in
  let (today_year, today_month, _) = today in
  let (ed_year, ed_month, _) = effective_date in
  let months_since_effective = 
    let years_diff = today_year - ed_year in
    let months_diff = today_month - ed_month in
    years_diff * 12 + months_diff
  in
  
  (* Only send if we've passed the minimum months threshold *)
  months_since_effective >= config.organization.effective_date_first_email_months

(** 
 * [calculate_campaign_emails]: Generates email schedules for a specific campaign instance
 * 
 * Purpose:
 *   Core campaign scheduling logic that processes all eligible contacts for a campaign,
 *   applies business rules, handles exclusions, and creates email schedule records.
 * 
 * Parameters:
 *   - context: Scheduling context with configuration and load balancing settings
 *   - campaign_instance: Specific campaign instance with targeting and timing data
 *   - campaign_config: Campaign type configuration with rules and settings
 * 
 * Returns:
 *   List of email_schedule records for all processed contacts in this campaign
 * 
 * Business Logic:
 *   - Retrieves contacts based on campaign targeting (all contacts vs specific list)
 *   - Validates each contact for campaign eligibility
 *   - Applies organization and campaign exclusion rules
 *   - Calculates schedule dates (spread evenly vs regular timing)
 *   - Handles exclusion windows if campaign respects them
 *   - Creates appropriate schedule status (PreScheduled vs Skipped)
 * 
 * Usage Example:
 *   Called by calculate_all_campaign_schedules for each active campaign instance
 * 
 * Error Cases:
 *   - Database errors when retrieving contacts return empty lists
 *   - Invalid contacts are skipped with Skipped status
 * 
 * @business_rule @data_flow @performance
 *)
let calculate_campaign_emails context campaign_instance campaign_config =
  let send_time = schedule_time_ct context.config.send_time_hour context.config.send_time_minute in
  let schedules = ref [] in
  
  (* Get contacts for this campaign with targeting *)
  let contacts = 
    if campaign_config.target_all_contacts then
      match get_contacts_for_campaign campaign_instance with
      | Ok contacts -> contacts
      | Error _ -> []
    else
      match get_contact_campaigns_for_instance campaign_instance.id with
      | Ok contact_campaigns ->
          (* Get the actual contact records for the contact_campaigns *)
          List.filter_map (fun (cc : contact_campaign) ->
            try
              match get_all_contacts () with
              | Ok (contacts_from_db : contact list) -> 
                  List.find_opt (fun (c : contact) -> c.id = cc.contact_id) contacts_from_db
              | Error _ -> None
            with _ -> None
          ) contact_campaigns
      | Error _ -> []
  in
  
  List.iter (fun contact ->
    (* Check if contact is valid for this campaign *)
    if Contact.is_valid_for_campaign_scheduling context.config.organization campaign_instance contact then
      (* Check organization-level exclusions *)
      match should_exclude_contact context.config campaign_config contact with
      | Some exclusion_reason ->
          (* Contact is excluded - create skipped schedule *)
          let scheduled_date = current_date () in (* Placeholder date *)
          let campaign_email = {
            campaign_type = campaign_config.name;
            instance_id = campaign_instance.id;
            respect_exclusions = campaign_config.respect_exclusion_windows;
            days_before_event = campaign_config.days_before_event;
            priority = campaign_config.priority;
          } in
          let schedule = {
            contact_id = contact.id;
            email_type = Campaign campaign_email;
            scheduled_date;
            scheduled_time = send_time;
            status = Skipped exclusion_reason;
            priority = campaign_config.priority;
            template_id = campaign_instance.email_template;
            campaign_instance_id = Some campaign_instance.id;
            scheduler_run_id = context.run_id;
          } in
          schedules := schedule :: !schedules
      | None ->
          (* Contact is eligible - calculate schedule date *)
          let scheduled_date = 
            if campaign_config.spread_evenly then
              match (campaign_instance.spread_start_date, campaign_instance.spread_end_date) with
              | (Some start_date, Some end_date) ->
                  calculate_spread_date contact.id start_date end_date
              | _ ->
                  (* Fallback to regular calculation if spread dates not set *)
                  let today = current_date () in
                  add_days today campaign_config.days_before_event
            else
              (* Regular campaign scheduling *)
              let trigger_date = 
                if campaign_config.target_all_contacts then
                  current_date () (* Use today as trigger for "all contacts" campaigns *)
                else
                  (* Get trigger date from contact_campaigns table *)
                  match get_contact_campaigns_for_instance campaign_instance.id with
                  | Ok contact_campaigns ->
                      (match List.find_opt (fun cc -> cc.contact_id = contact.id) contact_campaigns with
                       | Some cc -> 
                           (match cc.trigger_date with
                            | Some date -> date
                            | None -> current_date ())
                       | None -> current_date ())
                  | Error _ -> current_date ()
              in
              add_days trigger_date campaign_config.days_before_event
          in
          
          (* Create campaign email type *)
          let campaign_email = {
            campaign_type = campaign_config.name;
            instance_id = campaign_instance.id;
            respect_exclusions = campaign_config.respect_exclusion_windows;
            days_before_event = campaign_config.days_before_event;
            priority = campaign_config.priority;
          } in
          
          let email_type = Campaign campaign_email in
          
          (* Check exclusion windows if required *)
          let should_skip = 
            if campaign_config.respect_exclusion_windows then
              should_skip_email contact email_type scheduled_date
            else
              false
          in
          
          let (status, _skip_reason) = 
            if should_skip then
              let reason = match check_exclusion_window contact scheduled_date with
                | Excluded { reason; _ } -> reason
                | NotExcluded -> "Unknown exclusion"
              in
              (Skipped reason, reason)
            else
              (PreScheduled, "")
          in
          
          let schedule = {
            contact_id = contact.id;
            email_type;
            scheduled_date;
            scheduled_time = send_time;
            status;
            priority = campaign_config.priority;
            template_id = campaign_instance.email_template;
            campaign_instance_id = Some campaign_instance.id;
            scheduler_run_id = context.run_id;
          } in
          schedules := schedule :: !schedules
  ) contacts;
  
  !schedules

(** 
 * [calculate_anniversary_emails]: Generates anniversary email schedules for a contact
 * 
 * Purpose:
 *   Creates email schedules for birthday and effective date anniversaries based on
 *   contact data and organization configuration, applying exclusion rules.
 * 
 * Parameters:
 *   - context: Scheduling context with configuration and timing settings
 *   - contact: Contact record with birthday, effective_date, and other data
 * 
 * Returns:
 *   List of email_schedule records for anniversary emails (birthday and effective date)
 * 
 * Business Logic:
 *   - Checks organization-level failed underwriting exclusion policy
 *   - Calculates next anniversary dates for birthday and effective date
 *   - Applies days_before configuration for email timing
 *   - Evaluates exclusion windows and creates appropriate status
 *   - Handles minimum time threshold for effective date emails
 *   - Creates audit trail with skip reasons when applicable
 * 
 * Usage Example:
 *   Called by calculate_schedules_for_contact for each valid contact
 * 
 * Error Cases:
 *   - Missing birthday/effective_date are handled gracefully (no emails created)
 *   - Exclusion window checks may result in Skipped status
 * 
 * @business_rule @data_flow
 *)
let calculate_anniversary_emails context contact =
  let today = current_date () in
  let schedules = ref [] in
  
  let send_time = schedule_time_ct context.config.send_time_hour context.config.send_time_minute in
  
  (* Check organization-level underwriting exclusion for anniversary emails *)
  if context.config.organization.exclude_failed_underwriting_global && contact.failed_underwriting then
    (* Skip all anniversary emails for failed underwriting *)
    !schedules
  else (
    begin match contact.birthday with
    | Some birthday ->
        let next_bday = next_anniversary today birthday in
        let birthday_send_date = add_days next_bday (-context.config.birthday_days_before) in
        
        if not (should_skip_email contact (Anniversary Birthday) birthday_send_date) then
          let schedule = {
            contact_id = contact.id;
            email_type = Anniversary Birthday;
            scheduled_date = birthday_send_date;
            scheduled_time = send_time;
            status = PreScheduled;
            priority = priority_of_email_type (Anniversary Birthday);
            template_id = Some "birthday_template";
            campaign_instance_id = None;
            scheduler_run_id = context.run_id;
          } in
          schedules := schedule :: !schedules
        else
          let skip_reason = match check_exclusion_window contact birthday_send_date with
            | Excluded { reason; _ } -> reason
            | NotExcluded -> "Unknown exclusion"
          in
          let schedule = {
            contact_id = contact.id;
            email_type = Anniversary Birthday;
            scheduled_date = birthday_send_date;
            scheduled_time = send_time;
            status = Skipped skip_reason;
            priority = priority_of_email_type (Anniversary Birthday);
            template_id = Some "birthday_template";
            campaign_instance_id = None;
            scheduler_run_id = context.run_id;
          } in
          schedules := schedule :: !schedules
    | None -> ()
    end;
    
    begin match contact.effective_date with
    | Some ed ->
        (* Check if enough time has passed since effective date *)
        if should_send_effective_date_email context.config contact ed then
          let next_ed = next_anniversary today ed in
          let ed_send_date = add_days next_ed (-context.config.effective_date_days_before) in
          
          if not (should_skip_email contact (Anniversary EffectiveDate) ed_send_date) then
            let schedule = {
              contact_id = contact.id;
              email_type = Anniversary EffectiveDate;
              scheduled_date = ed_send_date;
              scheduled_time = send_time;
              status = PreScheduled;
              priority = priority_of_email_type (Anniversary EffectiveDate);
              template_id = Some "effective_date_template";
              campaign_instance_id = None;
              scheduler_run_id = context.run_id;
            } in
            schedules := schedule :: !schedules
          else
            let skip_reason = match check_exclusion_window contact ed_send_date with
              | Excluded { reason; _ } -> reason
              | NotExcluded -> "Unknown exclusion"
            in
            let schedule = {
              contact_id = contact.id;
              email_type = Anniversary EffectiveDate;
              scheduled_date = ed_send_date;
              scheduled_time = send_time;
              status = Skipped skip_reason;
              priority = priority_of_email_type (Anniversary EffectiveDate);
              template_id = Some "effective_date_template";
              campaign_instance_id = None;
              scheduler_run_id = context.run_id;
            } in
            schedules := schedule :: !schedules
    | None -> ()
    end;
    
    !schedules
  )

(** 
 * [calculate_post_window_emails]: Generates post-exclusion window email schedules
 * 
 * Purpose:
 *   Creates email schedules for contacts who had emails skipped during exclusion
 *   windows, to be sent after the window period ends.
 * 
 * Parameters:
 *   - context: Scheduling context with configuration settings
 *   - contact: Contact record that may need post-window emails
 * 
 * Returns:
 *   List containing single post-window email schedule or empty list
 * 
 * Business Logic:
 *   - Checks if organization enables post-window email feature
 *   - Retrieves calculated post-window date from exclusion logic
 *   - Creates single email schedule with PostWindow anniversary type
 *   - Uses standard send time and priority settings
 * 
 * Usage Example:
 *   Called by calculate_schedules_for_contact for contacts with exclusion history
 * 
 * Error Cases:
 *   - Returns empty list if organization disables feature
 *   - Returns empty list if no post-window date calculated
 * 
 * @business_rule
 *)
let calculate_post_window_emails context contact =
  (* Check if organization enables post-window emails *)
  if not context.config.organization.enable_post_window_emails then
    []
  else
    match get_post_window_date contact with
    | Some post_date ->
        let send_time = schedule_time_ct context.config.send_time_hour context.config.send_time_minute in
        let schedule = {
          contact_id = contact.id;
          email_type = Anniversary PostWindow;
          scheduled_date = post_date;
          scheduled_time = send_time;
          status = PreScheduled;
          priority = priority_of_email_type (Anniversary PostWindow);
          template_id = Some "post_window_template";
          campaign_instance_id = None;
          scheduler_run_id = context.run_id;
        } in
        [schedule]
    | None -> []

(** 
 * [generate_post_window_for_skipped]: Generates post-window emails for schedules skipped due to exclusions
 * 
 * Purpose:
 *   Automatically creates post-window makeup emails for any schedules that were
 *   skipped due to exclusion windows during the current scheduling run.
 * 
 * Parameters:
 *   - context: Scheduling context with configuration and timing settings  
 *   - skipped_schedules: List of schedules that were skipped due to exclusions
 * 
 * Returns:
 *   List of post-window email schedules for skipped emails
 * 
 * Business Logic:
 *   - Filters skipped schedules for exclusion-related skip reasons
 *   - Calculates appropriate post-window dates for each skipped email
 *   - Creates makeup emails to be sent after exclusion window ends
 *   - Respects organization enable_post_window_emails setting
 * 
 * @business_rule @data_flow
 *)
let generate_post_window_for_skipped context skipped_schedules =
  if not context.config.organization.enable_post_window_emails then
    []
  else
    let post_window_schedules = ref [] in
    let send_time = schedule_time_ct context.config.send_time_hour context.config.send_time_minute in
    
    List.iter (fun (schedule : email_schedule) ->
      match schedule.status with
      | Skipped reason when (try Str.search_forward (Str.regexp "exclusion\\|window") reason 0 >= 0 with Not_found -> false) ->
          (* Calculate post-window date for this skipped email *)
          (match get_all_contacts () with
           | Ok (contacts : contact list) ->
               (match List.find_opt (fun (c : contact) -> c.id = schedule.contact_id) contacts with
                | Some contact ->
                    (match get_post_window_date contact with
                     | Some post_date ->
                         let post_window_schedule = {
                           contact_id = schedule.contact_id;
                           email_type = Anniversary PostWindow;
                           scheduled_date = post_date;
                           scheduled_time = send_time;
                           status = PreScheduled;
                           priority = priority_of_email_type (Anniversary PostWindow);
                           template_id = Some "post_window_template";
                           campaign_instance_id = None;
                           scheduler_run_id = context.run_id;
                         } in
                         post_window_schedules := post_window_schedule :: !post_window_schedules
                     | None -> ())
                | None -> ())
           | Error _ -> ())
      | _ -> ()
    ) skipped_schedules;
    
    !post_window_schedules

(** 
 * [calculate_schedules_for_contact]: Generates all email schedules for a single contact
 * 
 * Purpose:
 *   Core scheduling function that determines which emails should be sent to a contact
 *   and when, based on their anniversaries, state rules, and organization policies.
 * 
 * Parameters:
 *   - context: Scheduling context containing config, run_id, and load balancing settings
 *   - contact: The contact record with birthday, effective_date, state, etc.
 * 
 * Returns:
 *   Result containing list of email_schedule records or scheduler_error
 * 
 * Business Logic:
 *   - Validates contact has required data for anniversary scheduling
 *   - Calculates anniversary-based emails (birthday, effective_date)
 *   - Applies state exclusion windows based on contact.state
 *   - Adds post-window emails if any were skipped
 *   - Respects organization configuration for timing and exclusions
 * 
 * Usage Example:
 *   Called by process_contact_batch for each contact in batch processing
 * 
 * Error Cases:
 *   - InvalidContactData: Missing required fields or validation failure
 *   - UnexpectedError: Unhandled exceptions during processing
 * 
 * @business_rule @data_flow
 *)
let calculate_schedules_for_contact context contact =
  try
    if not (Contact.is_valid_for_anniversary_scheduling context.config.organization contact) then
      Error (InvalidContactData { 
        contact_id = contact.id; 
        reason = "Contact failed anniversary scheduling validation" 
      })
    else
      let anniversary_schedules = calculate_anniversary_emails context contact in
      let post_window_schedules = calculate_post_window_emails context contact in
      let all_schedules = anniversary_schedules @ post_window_schedules in
      Ok all_schedules
  with e ->
    Error (UnexpectedError e)

(** 
 * [calculate_all_campaign_schedules]: Generates schedules for all active campaigns
 * 
 * Purpose:
 *   Orchestrates campaign email scheduling across all active campaign instances,
 *   retrieving configurations and handling errors at the campaign level.
 * 
 * Parameters:
 *   - context: Scheduling context with configuration and settings
 * 
 * Returns:
 *   Tuple of (schedule_list, error_list) containing all campaign schedules and any errors
 * 
 * Business Logic:
 *   - Retrieves all active campaign instances from database
 *   - For each instance, gets campaign type configuration
 *   - Calls calculate_campaign_emails for schedule generation
 *   - Accumulates all schedules and errors for return
 *   - Continues processing even if individual campaigns fail
 * 
 * Usage Example:
 *   Called by schedule_emails_streaming to handle all campaign scheduling
 * 
 * Error Cases:
 *   - Database errors accessing campaigns are collected and returned
 *   - Individual campaign failures don't stop overall processing
 * 
 * @integration_point @data_flow
 *)
let calculate_all_campaign_schedules context =
  let all_schedules = ref [] in
  let errors = ref [] in
  
  match get_active_campaign_instances () with
  | Error err -> 
      errors := (DatabaseError (string_of_db_error err)) :: !errors;
      (!all_schedules, !errors)
  | Ok campaign_instances ->
      List.iter (fun campaign_instance ->
        match get_campaign_type_config campaign_instance.campaign_type with
        | Error err ->
            errors := (DatabaseError (string_of_db_error err)) :: !errors
        | Ok campaign_config ->
            let campaign_schedules = calculate_campaign_emails context campaign_instance campaign_config in
            all_schedules := campaign_schedules @ !all_schedules
      ) campaign_instances;
      (!all_schedules, !errors)

type batch_result = {
  schedules: email_schedule list;
  contacts_processed: int;
  emails_scheduled: int;
  emails_skipped: int;
  errors: scheduler_error list;
}

(** 
 * [process_contact_batch]: Processes a batch of contacts for anniversary email scheduling
 * 
 * Purpose:
 *   Efficiently processes a subset of contacts in parallel, calculating schedules
 *   and collecting metrics for batch processing performance optimization.
 * 
 * Parameters:
 *   - context: Scheduling context with configuration and run information
 *   - contacts: List of contacts to process in this batch
 * 
 * Returns:
 *   batch_result record containing schedules, metrics, and any errors encountered
 * 
 * Business Logic:
 *   - Processes each contact individually for anniversary scheduling
 *   - Accumulates all generated schedules from the batch
 *   - Tracks processing metrics (scheduled, skipped, errors)
 *   - Continues processing even if individual contacts fail
 *   - Provides detailed statistics for monitoring and debugging
 * 
 * Usage Example:
 *   Called by schedule_emails_streaming for each chunk of contacts
 * 
 * Error Cases:
 *   - Individual contact errors are collected but don't stop batch processing
 *   - Returns comprehensive metrics even when some contacts fail
 * 
 * @performance @data_flow
 *)
let process_contact_batch context contacts =
  let all_schedules = ref [] in
  let contacts_processed = ref 0 in
  let emails_scheduled = ref 0 in
  let emails_skipped = ref 0 in
  let errors = ref [] in
  
  List.iter (fun contact ->
    incr contacts_processed;
    match calculate_schedules_for_contact context contact with
    | Ok schedules ->
        all_schedules := schedules @ !all_schedules;
        List.iter (fun (schedule : email_schedule) ->
          match schedule.status with
          | PreScheduled -> incr emails_scheduled
          | Skipped _ -> incr emails_skipped
          | _ -> ()
        ) schedules
    | Error err ->
        errors := err :: !errors
  ) contacts;
  
  {
    schedules = !all_schedules;
    contacts_processed = !contacts_processed;
    emails_scheduled = !emails_scheduled;
    emails_skipped = !emails_skipped;
    errors = !errors;
  }

(** 
 * [manage_campaign_lifecycle]: Manages campaign instance activation/deactivation based on dates
 * 
 * Purpose:
 *   Automatically activates and deactivates campaign instances based on their
 *   active_start_date and active_end_date fields to ensure only current campaigns run.
 * 
 * Parameters:
 *   - context: Scheduling context (unused but kept for consistency)
 * 
 * Returns:
 *   Result indicating success or database error
 * 
 * Business Logic:
 *   - Checks all campaign instances against current date
 *   - Activates instances whose start date has arrived
 *   - Deactivates instances whose end date has passed
 *   - Provides audit trail of lifecycle changes
 * 
 * @business_rule @state_machine
 *)
let manage_campaign_lifecycle _context =
  let today = current_date () in
  let today_str = string_of_date today in
  
  (* Get all campaign instances with date ranges *)
  let query = Printf.sprintf {|
    SELECT id, campaign_type, instance_name,
           COALESCE(active_start_date, '') as active_start_date,
           COALESCE(active_end_date, '') as active_end_date,
           COALESCE(metadata, '{}') as metadata
    FROM campaign_instances
    WHERE (active_start_date IS NOT NULL OR active_end_date IS NOT NULL)
  |} in
  
  match execute_sql_safe query with
  | Error err -> Error (DatabaseError (string_of_db_error err))
  | Ok rows ->
      let process_instance row =
        match row with
        | [id_str; _campaign_type; _instance_name; active_start_date; active_end_date; _metadata] ->
            (try
              let id = int_of_string id_str in
              let should_be_active = 
                let after_start = 
                  if active_start_date = "" || active_start_date = "NULL" then true
                  else (parse_date active_start_date) <= today
                in
                let before_end = 
                  if active_end_date = "" || active_end_date = "NULL" then true
                  else today <= (parse_date active_end_date)
                in
                after_start && before_end
              in
              
              (* Update metadata to track lifecycle changes *)
              let updated_metadata = 
                if should_be_active then
                  Printf.sprintf "{\"lifecycle_status\": \"active\", \"last_checked\": \"%s\"}" today_str
                else
                  Printf.sprintf "{\"lifecycle_status\": \"inactive\", \"last_checked\": \"%s\"}" today_str
              in
              
              let update_sql = Printf.sprintf {|
                UPDATE campaign_instances 
                SET metadata = '%s', updated_at = CURRENT_TIMESTAMP
                WHERE id = %d
              |} updated_metadata id in
              
              execute_sql_no_result update_sql
            with _ -> Ok ())
        | _ -> Ok ()
      in
      
             (* Process all instances *)
       let rec process_all rows =
         match rows with
         | [] -> Ok ()
         | row :: rest ->
             (match process_instance row with
              | Ok () -> process_all rest
              | Error err -> Error (DatabaseError (string_of_db_error err)))
       in
       
       process_all rows

(** 
 * [extract_date_from_datetime_string]: Safely extracts date from either date or datetime string
 * 
 * Purpose:
 *   Handles database values that could be either date strings (YYYY-MM-DD) or 
 *   datetime strings (YYYY-MM-DD HH:MM:SS) by extracting just the date portion.
 * 
 * Parameters:
 *   - datetime_or_date_str: String that could be date or datetime format
 * 
 * Returns:
 *   Date extracted from the string
 * 
 * Business Logic:
 *   - If string contains space (datetime format), takes only the date part
 *   - If string has no space (date format), uses as-is
 *   - Handles COALESCE(actual_send_datetime, scheduled_send_date) safely
 * 
 * @utility
 *)
let extract_date_from_datetime_string datetime_or_date_str =
  (* Check if the string contains time information (has a space) *)
  match String.index_opt datetime_or_date_str ' ' with
  | Some space_index ->
      (* Extract just the date part (before the space) *)
      let date_part = String.sub datetime_or_date_str 0 space_index in
      parse_date date_part
  | None ->
      (* No space found, treat as date string *)
      parse_date datetime_or_date_str

(** 
 * [determine_followup_type]: Determines the appropriate follow-up email type based on contact interactions
 * 
 * Purpose:
 *   Analyzes contact engagement behavior to select the most appropriate follow-up email
 *   template based on clicks, health question answers, and medical conditions.
 * 
 * Parameters:
 *   - contact_id: The contact ID to analyze
 *   - since_date: Date from which to analyze interactions (typically when initial email was sent)
 * 
 * Returns:
 *   Result containing followup_type or scheduler_error
 * 
 * Business Logic:
 *   - Checks for clicks and health question responses
 *   - Prioritizes follow-ups based on engagement level
 *   - Uses highest applicable follow-up type for contact behavior
 * 
 * @business_rule
 *)
let determine_followup_type contact_id since_date =
  match get_contact_interactions contact_id since_date with
  | Error err -> Error (DatabaseError (string_of_db_error err))
  | Ok (has_clicks, has_health_answers) ->
      if has_health_answers then
        (* For now, assume no medical conditions check - would need additional logic *)
        Ok HQNoYes
      else if has_clicks then
        Ok ClickedNoHQ
      else
        Ok Cold

(** 
 * [calculate_followup_emails]: Generates follow-up email schedules for eligible contacts
 * 
 * Purpose:
 *   Identifies contacts who need follow-up emails based on their sent emails and
 *   creates appropriate follow-up schedules based on engagement behavior.
 * 
 * Parameters:
 *   - context: Scheduling context with configuration and timing settings
 * 
 * Returns:
 *   List of email_schedule records for follow-up emails
 * 
 * Business Logic:
 *   - Looks back for sent emails that need follow-ups
 *   - Analyzes contact engagement behavior for each email
 *   - Schedules follow-ups based on configured delay
 *   - Excludes contacts with existing follow-ups
 *   - Respects exclusion windows for follow-up scheduling
 * 
 * @business_rule @data_flow
 *)
let calculate_followup_emails context =
  let schedules = ref [] in
  let send_time = schedule_time_ct context.config.send_time_hour context.config.send_time_minute in
  let lookback_days = 35 in (* Look back 35 days for eligible emails *)
  
  match get_sent_emails_for_followup lookback_days with
  | Error _ -> !schedules (* Return empty list on error *)
  | Ok sent_emails ->
      List.iter (fun (contact_id, email_type, sent_time, _email_id) ->
        (* Check if this email type is eligible for follow-ups *)
        let is_eligible_for_followup = match email_type with
          | "birthday" | "effective_date" | "post_window" -> true
          | email_type_str when String.length email_type_str >= 9 && String.sub email_type_str 0 9 = "campaign_" ->
              (* For campaign emails, check if the campaign has enable_followups=true *)
              let after_prefix = String.sub email_type_str 9 (String.length email_type_str - 9) in
              let campaign_type = 
                (* Extract just the campaign type (before first underscore after "campaign_") *)
                match String.index_opt after_prefix '_' with
                | Some underscore_pos -> String.sub after_prefix 0 underscore_pos
                | None -> after_prefix (* No underscore found, use whole string *)
              in
              (match get_campaign_type_config campaign_type with
               | Ok campaign_config -> campaign_config.enable_followups
               | Error _ -> false)
          | _ -> false
        in
        
        if is_eligible_for_followup then (
          (* Check if contact already has follow-ups scheduled *)
          let has_existing_followup = 
            match execute_sql_safe (Printf.sprintf {|
              SELECT COUNT(*) FROM email_schedules 
              WHERE contact_id = %d 
              AND email_type LIKE 'followup%%' 
              AND status IN ('pre-scheduled', 'scheduled', 'sent')
            |} contact_id) with
            | Ok [["0"]] -> false
            | _ -> true
          in
          
          if not has_existing_followup then (
          (* Determine follow-up type based on behavior *)
          let sent_date = extract_date_from_datetime_string sent_time in
          let since_date_str = string_of_date sent_date in
          
          match determine_followup_type contact_id since_date_str with
          | Error _ -> () (* Skip on error *)
          | Ok followup_type ->
              (* Schedule follow-up for configured delay after sent date *)
              let followup_date = add_days sent_date context.config.followup_delay_days in
              let today = current_date () in
              
              (* If follow-up is overdue, schedule for tomorrow *)
              let scheduled_date = 
                if followup_date < today then
                  add_days today 1
                else
                  followup_date
              in
              
                             (* Get contact for exclusion window check *)
               (match get_all_contacts () with
                | Ok (contacts : contact list) ->
                    (match List.find_opt (fun (c : contact) -> c.id = contact_id) contacts with
                    | Some contact ->
                        let email_type = Followup followup_type in
                        
                        (* Check exclusion windows *)
                        let should_skip = should_skip_email contact email_type scheduled_date in
                        
                        let (status, _skip_reason) = 
                          if should_skip then
                            let reason = match check_exclusion_window contact scheduled_date with
                              | Excluded { reason; _ } -> reason
                              | NotExcluded -> "Unknown exclusion"
                            in
                            (Skipped reason, reason)
                          else
                            (PreScheduled, "")
                        in
                        
                        let schedule = {
                          contact_id;
                          email_type;
                          scheduled_date;
                          scheduled_time = send_time;
                          status;
                          priority = priority_of_email_type email_type;
                          template_id = Some (Printf.sprintf "%s_template" (string_of_followup_type followup_type));
                          campaign_instance_id = None;
                          scheduler_run_id = context.run_id;
                        } in
                        schedules := schedule :: !schedules
                    | None -> ())
               | Error _ -> ())
          )
        )
      ) sent_emails;
      
             !schedules



(** 
 * [apply_frequency_limits]: Filters email schedules based on frequency limits
 * 
 * Purpose:
 *   Applies frequency limit enforcement to a list of proposed email schedules,
 *   prioritizing higher priority emails when limits are exceeded.
 * 
 * Parameters:
 *   - context: Scheduling context with frequency limit configuration
 *   - schedules: List of proposed email schedules to filter
 * 
 * Returns:
 *   Tuple of (allowed_schedules, frequency_limited_schedules)
 * 
 * Business Logic:
 *   - Groups schedules by contact_id for frequency checking
 *   - Sorts schedules by priority (lower number = higher priority)
 *   - For each email, counts both database emails AND current batch emails within period
 *   - Tracks previously-allowed emails from current batch to prevent batch-level limit violations
 *   - Allows highest priority emails within frequency limits
 *   - Marks excess emails as skipped due to frequency limits
 * 
 * @business_rule @performance
 *)
let apply_frequency_limits context schedules =
  let allowed_schedules = ref [] in
  let limited_schedules = ref [] in
  
  (* Group schedules by contact_id *)
  let contact_groups = 
    List.fold_left (fun acc (schedule : email_schedule) ->
      let contact_id = schedule.contact_id in
      let existing = try List.assoc contact_id acc with Not_found -> [] in
      (contact_id, schedule :: existing) :: (List.remove_assoc contact_id acc)
    ) [] schedules
  in
  
  (* Process each contact's schedules *)
  List.iter (fun (contact_id, contact_schedules) ->
    (* Sort by priority (lower number = higher priority) *)
    let sorted_schedules : email_schedule list = List.sort (fun (a : email_schedule) (b : email_schedule) -> compare a.priority b.priority) contact_schedules in
    
    (* Track emails we've already allowed for this contact in current batch *)
    let allowed_in_batch = ref [] in
    
    List.iter (fun (schedule : email_schedule) ->
      (* Calculate period for this email *)
      let period_start = add_days schedule.scheduled_date (-context.config.period_days) in
      let period_start_str = string_of_date period_start in
      let proposed_date_str = string_of_date schedule.scheduled_date in
      
      (* Count emails from database *)
      let count_query = Printf.sprintf {|
        SELECT COUNT(*) 
        FROM email_schedules 
        WHERE contact_id = %d 
        AND scheduled_send_date BETWEEN '%s' AND '%s'
        AND status IN ('pre-scheduled', 'scheduled', 'sent', 'delivered')
      |} contact_id period_start_str proposed_date_str in
      
      match execute_sql_safe count_query with
      | Error _ -> 
          (* On error, allow the email (conservative approach) *)
          allowed_schedules := schedule :: !allowed_schedules;
          allowed_in_batch := schedule :: !allowed_in_batch
      | Ok [[ count_str ]] ->
          (try
            let db_count = int_of_string count_str in
            
            (* Count emails from current batch that fall within this period *)
            let batch_count = List.fold_left (fun acc (batch_schedule : email_schedule) ->
              if batch_schedule.scheduled_date >= period_start && 
                 batch_schedule.scheduled_date <= schedule.scheduled_date then
                acc + 1
              else
                acc
            ) 0 !allowed_in_batch in
            
            let total_count = db_count + batch_count in
            
            if total_count >= context.config.max_emails_per_period then
              (* Create skipped version due to frequency limits *)
              let limited_schedule = {
                schedule with 
                status = Skipped "Frequency limit exceeded";
              } in
              limited_schedules := limited_schedule :: !limited_schedules
            else
              allowed_schedules := schedule :: !allowed_schedules;
              allowed_in_batch := schedule :: !allowed_in_batch
          with _ -> 
            (* On parse error, allow the email (conservative approach) *)
            allowed_schedules := schedule :: !allowed_schedules;
            allowed_in_batch := schedule :: !allowed_in_batch)
      | Ok _ -> 
          (* On unexpected result, allow the email (conservative approach) *)
          allowed_schedules := schedule :: !allowed_schedules;
          allowed_in_batch := schedule :: !allowed_in_batch
    ) sorted_schedules
  ) contact_groups;
  
  (!allowed_schedules, !limited_schedules)

(** 
 * [resolve_campaign_conflicts]: Resolves conflicts when multiple campaigns target same contact on same date
 * 
 * Purpose:
 *   Handles priority conflicts when multiple campaign emails are scheduled for the
 *   same contact on the same date, keeping highest priority and skipping others.
 * 
 * Parameters:
 *   - schedules: List of email schedules potentially containing conflicts
 * 
 * Returns:
 *   Tuple of (resolved_schedules, conflicted_schedules)
 * 
 * Business Logic:
 *   - Groups schedules by (contact_id, scheduled_date)
 *   - For each group, selects highest priority email (lowest number)
 *   - Marks other emails as skipped due to campaign conflicts
 *   - Preserves non-campaign emails (anniversary, follow-up) alongside campaigns
 * 
 * @business_rule
 *)
let resolve_campaign_conflicts schedules =
  let resolved_schedules = ref [] in
  let conflicted_schedules = ref [] in
  
  (* Group schedules by contact_id and scheduled_date *)
  let date_groups = 
    List.fold_left (fun acc (schedule : email_schedule) ->
      let key = (schedule.contact_id, schedule.scheduled_date) in
      let existing = try List.assoc key acc with Not_found -> [] in
      (key, schedule :: existing) :: (List.remove_assoc key acc)
    ) [] schedules
  in
  
  (* Process each date group *)
  List.iter (fun ((contact_id, date), group_schedules) ->
    (* Validate that all schedules in group actually match the key *)
    List.iter (fun (s : email_schedule) ->
      if s.contact_id <> contact_id || s.scheduled_date <> date then
        failwith (Printf.sprintf "Grouping error: schedule contact_id=%d date=%s doesn't match group key contact_id=%d date=%s"
                   s.contact_id (string_of_date s.scheduled_date) contact_id (string_of_date date))
    ) group_schedules;
    
    (* Separate campaign emails from other types *)
    let (campaign_emails, other_emails) = 
      List.partition (fun (s : email_schedule) ->
        match s.email_type with
        | Campaign _ -> true
        | _ -> false
      ) group_schedules
    in
    
    (* Always keep non-campaign emails *)
    resolved_schedules := other_emails @ !resolved_schedules;
    
    (* Handle campaign conflicts for contact_id on date *)
    match campaign_emails with
    | [] -> () (* No campaigns for this contact on this date *)
    | [single_campaign] -> 
        (* Single campaign, no conflict for contact_id on date *)
        resolved_schedules := single_campaign :: !resolved_schedules
    | multiple_campaigns ->
        (* Multiple campaigns for contact_id on date - resolve by priority *)
        let sorted_campaigns : email_schedule list = List.sort (fun (a : email_schedule) (b : email_schedule) -> compare a.priority b.priority) multiple_campaigns in
        match sorted_campaigns with
        | highest_priority :: conflicts ->
            (* Keep highest priority campaign for contact_id on date *)
            resolved_schedules := highest_priority :: !resolved_schedules;
            (* Skip conflicting campaigns for contact_id on date *)
            List.iter (fun (conflict : email_schedule) ->
              let skipped_conflict = {
                conflict with 
                status = Skipped (Printf.sprintf "Campaign priority conflict on %s for contact %d" 
                                   (string_of_date date) contact_id);
              } in
              conflicted_schedules := skipped_conflict :: !conflicted_schedules
            ) conflicts
        | [] -> () (* Should not happen *)
  ) date_groups;
  
  (!resolved_schedules, !conflicted_schedules)

(** 
 * [schedule_emails_streaming]: Main orchestration function for email scheduling
 * 
 * Purpose:
 *   Top-level function that coordinates all email scheduling including anniversary
 *   emails, campaigns, load balancing, and provides comprehensive execution results.
 * 
 * Parameters:
 *   - contacts: List of all contacts to process for anniversary emails
 *   - config: Configuration containing organization settings and timing
 *   - total_contacts: Total contact count for load balancing calculations
 * 
 * Returns:
 *   Result containing batch_result with all schedules and metrics, or scheduler_error
 * 
 * Business Logic:
 *   - Creates scheduling context with run ID and load balancing config
 *   - Processes campaign schedules first (independent of contact batching)
 *   - Processes anniversary contacts in configurable batch sizes
 *   - Combines anniversary and campaign schedules
 *   - Applies load balancing distribution to final schedules
 *   - Provides comprehensive metrics and error reporting
 * 
 * Usage Example:
 *   Main entry point called by external scheduler with full contact list
 * 
 * Error Cases:
 *   - Database errors, validation failures, unexpected exceptions
 *   - Returns detailed error information for debugging
 * 
 * @integration_point @state_machine @performance
 *)
let schedule_emails_streaming ~contacts ~config ~total_contacts =
  try
    let context = create_context config total_contacts in
    let chunk_size = config.batch_size in
    
    (* Manage campaign lifecycle before scheduling *)
    let _ = manage_campaign_lifecycle context in
    
    (* First, calculate all campaign schedules *)
    let (campaign_schedules, campaign_errors) = calculate_all_campaign_schedules context in
    
    (* Calculate follow-up email schedules *)
    let followup_schedules = calculate_followup_emails context in
    
    let rec process_chunks remaining_contacts acc_result =
      match remaining_contacts with
      | [] -> Ok acc_result
      | _ ->
          let (chunk, rest) = 
            let rec take n lst acc =
              if n = 0 || lst = [] then (List.rev acc, lst)
              else match lst with
                | h :: t -> take (n - 1) t (h :: acc)
                | [] -> (List.rev acc, [])
            in
            take chunk_size remaining_contacts []
          in
          
          let batch_result = process_contact_batch context chunk in
          
          let new_acc = {
            schedules = batch_result.schedules @ acc_result.schedules;
            contacts_processed = acc_result.contacts_processed + batch_result.contacts_processed;
            emails_scheduled = acc_result.emails_scheduled + batch_result.emails_scheduled;
            emails_skipped = acc_result.emails_skipped + batch_result.emails_skipped;
            errors = batch_result.errors @ acc_result.errors;
          } in
          
          process_chunks rest new_acc
    in
    
    let initial_result = {
      schedules = [];
      contacts_processed = 0;
      emails_scheduled = 0;
      emails_skipped = 0;
      errors = campaign_errors; (* Include campaign errors from the start *)
    } in
    
    match process_chunks contacts initial_result with
    | Ok raw_result ->
        (* Combine anniversary schedules with campaign schedules *)
        let all_schedules = raw_result.schedules @ campaign_schedules @ followup_schedules in
        
        (* Apply frequency limits before load balancing *)
        let (frequency_allowed_schedules, frequency_limited_schedules) = apply_frequency_limits context all_schedules in
        let frequency_filtered_schedules = frequency_allowed_schedules @ frequency_limited_schedules in
        
        (* Resolve campaign priority conflicts *)
        let (conflict_resolved_schedules, campaign_conflicts) = resolve_campaign_conflicts frequency_filtered_schedules in
        let conflict_resolved_all = conflict_resolved_schedules @ campaign_conflicts in
        
        (* Generate post-window emails for any skipped schedules *)
        let skipped_schedules = List.filter (fun (s : email_schedule) -> 
          match s.status with Skipped _ -> true | _ -> false) conflict_resolved_all in
        let auto_post_window_schedules = generate_post_window_for_skipped context skipped_schedules in
        
        (* Combine all schedules including auto-generated post-window emails *)
        let final_schedules = conflict_resolved_all @ auto_post_window_schedules in
        
        (* Count campaign schedules for metrics *)
        let campaign_scheduled = List.fold_left (fun acc (schedule : email_schedule) ->
          match schedule.status with
          | PreScheduled -> acc + 1
          | _ -> acc
        ) 0 campaign_schedules in
        
        let campaign_skipped = List.fold_left (fun acc (schedule : email_schedule) ->
          match schedule.status with
          | Skipped _ -> acc + 1
          | _ -> acc
        ) 0 campaign_schedules in
        
        (* Count follow-up schedules for metrics *)
        let followup_scheduled = List.fold_left (fun acc (schedule : email_schedule) ->
          match schedule.status with
          | PreScheduled -> acc + 1
          | _ -> acc
        ) 0 followup_schedules in
        
        let followup_skipped = List.fold_left (fun acc (schedule : email_schedule) ->
          match schedule.status with
          | Skipped _ -> acc + 1
          | _ -> acc
        ) 0 followup_schedules in
        
        (* Count frequency-limited schedules for metrics *)
        let frequency_limited_count = List.length frequency_limited_schedules in
        
        (* Count auto-generated post-window schedules for metrics *)
        let auto_post_window_count = List.length auto_post_window_schedules in
        
        (* Count campaign conflicts for metrics *)
        let campaign_conflict_count = List.length campaign_conflicts in
        
        let combined_result = {
          schedules = final_schedules;
          contacts_processed = raw_result.contacts_processed;
          emails_scheduled = raw_result.emails_scheduled + campaign_scheduled + followup_scheduled + auto_post_window_count;
          emails_skipped = raw_result.emails_skipped + campaign_skipped + followup_skipped + frequency_limited_count + campaign_conflict_count;
          errors = raw_result.errors;
        } in
        
        begin match distribute_schedules combined_result.schedules context.load_balancing_config with
        | Ok balanced_schedules ->
            Ok { combined_result with schedules = balanced_schedules }
        | Error err ->
            Error err
        end
    | Error err -> Error err
    
  with e ->
    Error (UnexpectedError e)

(** 
 * [get_scheduling_summary]: Generates human-readable summary of scheduling results
 * 
 * Purpose:
 *   Creates formatted summary text with key metrics and distribution analysis
 *   for monitoring, logging, and administrative reporting purposes.
 * 
 * Parameters:
 *   - result: batch_result containing schedules and processing metrics
 * 
 * Returns:
 *   Formatted string with comprehensive scheduling statistics
 * 
 * Business Logic:
 *   - Analyzes email distribution across dates for load balancing insights
 *   - Calculates averages, maximums, and variance for capacity planning
 *   - Provides contact processing metrics for performance monitoring
 *   - Formats data in human-readable format for reports and logs
 * 
 * Usage Example:
 *   Called after schedule_emails_streaming completes for logging and reporting
 * 
 * Error Cases:
 *   - None expected (operates on already validated result data)
 * 
 * @integration_point
 *)
let get_scheduling_summary result =
  let analysis = analyze_distribution result.schedules in
  Printf.sprintf 
    "Scheduling Summary:\n\
     - Contacts processed: %d\n\
     - Emails scheduled: %d\n\
     - Emails skipped: %d\n\
     - Total emails: %d\n\
     - Distribution over %d days\n\
     - Average per day: %.1f\n\
     - Max day: %d emails\n\
     - Distribution variance: %d"
    result.contacts_processed
    result.emails_scheduled
    result.emails_skipped
    analysis.total_emails
    analysis.total_days
    analysis.avg_per_day
    analysis.max_day
    analysis.distribution_variance

================
File: lib/scheduling/load_balancer.ml
================
open Date_time
open Types
open Date_calc

module DailyStats = struct
  (** 
   * [empty]: Creates empty daily statistics record for a specific date
   * 
   * Purpose:
   *   Initializes daily statistics tracking structure with zero counts for
   *   all email types to begin accumulating load metrics.
   * 
   * Parameters:
   *   - date: Date tuple for which to create empty statistics
   * 
   * Returns:
   *   daily_stats record with zero counts and specified date
   * 
   * Business Logic:
   *   - Provides clean starting point for daily email counting
   *   - Initializes all email type counters to zero
   *   - Sets over_threshold flag to false initially
   *   - Forms basis for load balancing calculations
   * 
   * Usage Example:
   *   Called by group_by_date when encountering new date
   * 
   * Error Cases:
   *   - None expected (pure data structure creation)
   * 
   * @performance
   *)
  let empty date = {
    date;
    total_count = 0;
    ed_count = 0;
    campaign_count = 0;
    anniversary_count = 0;
    over_threshold = false;
  }

  (** 
   * [add_email]: Updates daily statistics by adding one email schedule
   * 
   * Purpose:
   *   Increments appropriate counters in daily statistics based on email type
   *   to track load distribution and support capacity planning decisions.
   * 
   * Parameters:
   *   - stats: Current daily statistics record
   *   - email_schedule: Email schedule to add to statistics
   * 
   * Returns:
   *   Updated daily_stats record with incremented counters
   * 
   * Business Logic:
   *   - Increments total count for all email types
   *   - Increments specific counters based on email type classification
   *   - Distinguishes between anniversary, campaign, and effective date emails
   *   - Maintains detailed breakdown for targeted load balancing
   * 
   * Usage Example:
   *   Called by group_by_date for each schedule on a given date
   * 
   * Error Cases:
   *   - None expected (pure counter increment operations)
   * 
   * @performance
   *)
  let add_email stats email_schedule =
    let new_total = stats.total_count + 1 in
    let new_ed = match email_schedule.email_type with
      | Anniversary EffectiveDate -> stats.ed_count + 1
      | _ -> stats.ed_count
    in
    let new_campaign = match email_schedule.email_type with
      | Campaign _ -> stats.campaign_count + 1
      | _ -> stats.campaign_count
    in
    let new_anniversary = match email_schedule.email_type with
      | Anniversary _ -> stats.anniversary_count + 1
      | _ -> stats.anniversary_count
    in
    { stats with 
      total_count = new_total;
      ed_count = new_ed;
      campaign_count = new_campaign;
      anniversary_count = new_anniversary;
    }
end

(** 
 * [group_by_date]: Groups email schedules by date and computes daily statistics
 * 
 * Purpose:
 *   Aggregates email schedules by scheduled date to create daily load statistics
 *   for analysis and load balancing decision making.
 * 
 * Parameters:
 *   - schedules: List of email schedules to group and analyze
 * 
 * Returns:
 *   List of daily_stats records, one for each date with scheduled emails
 * 
 * Business Logic:
 *   - Uses hashtable for efficient date-based grouping
 *   - Accumulates email counts per date for load analysis
 *   - Creates detailed breakdown by email type for targeted balancing
 *   - Provides foundation for capacity planning and smoothing algorithms
 * 
 * Usage Example:
 *   Called by load balancing functions to analyze current distribution
 * 
 * Error Cases:
 *   - None expected (handles empty schedule lists gracefully)
 * 
 * @performance @data_flow
 *)
let group_by_date schedules =
  let date_map = Hashtbl.create 1000 in
  List.iter (fun schedule ->
    let date = schedule.scheduled_date in
    let current_stats = 
      match Hashtbl.find_opt date_map date with
      | Some stats -> stats
      | None -> DailyStats.empty date
    in
    let updated_stats = DailyStats.add_email current_stats schedule in
    Hashtbl.replace date_map date updated_stats
  ) schedules;
  Hashtbl.fold (fun _date stats acc -> stats :: acc) date_map []

(** 
 * [calculate_daily_cap]: Calculates daily email sending capacity limit
 * 
 * Purpose:
 *   Determines maximum emails per day based on total contact count and
 *   configured percentage cap to prevent overwhelming email volumes.
 * 
 * Parameters:
 *   - config: Load balancing configuration with percentage cap and contact count
 * 
 * Returns:
 *   Integer representing maximum emails allowed per day
 * 
 * Business Logic:
 *   - Applies percentage cap to total contact count
 *   - Ensures sustainable email sending volumes
 *   - Provides hard limit for daily email distribution
 *   - Supports capacity planning and resource management
 * 
 * Usage Example:
 *   Called by cap enforcement functions to determine redistribution thresholds
 * 
 * Error Cases:
 *   - None expected (arithmetic on validated configuration values)
 * 
 * @business_rule @performance
 *)
let calculate_daily_cap config =
  int_of_float (float_of_int config.total_contacts *. config.daily_send_percentage_cap)

(** 
 * [calculate_ed_soft_limit]: Calculates soft limit for effective date emails per day
 * 
 * Purpose:
 *   Determines target limit for effective date anniversary emails to prevent
 *   clustering and ensure balanced distribution across dates.
 * 
 * Parameters:
 *   - config: Load balancing configuration with ED limit and percentage cap
 * 
 * Returns:
 *   Integer representing soft limit for effective date emails per day
 * 
 * Business Logic:
 *   - Uses configured ED daily soft limit as baseline
 *   - Caps at 30% of overall daily capacity
 *   - Prevents effective date emails from dominating daily volume
 *   - Enables targeted smoothing of anniversary clusters
 * 
 * Usage Example:
 *   Called by effective date smoothing algorithms
 * 
 * Error Cases:
 *   - None expected (arithmetic on validated configuration values)
 * 
 * @business_rule @performance
 *)
let calculate_ed_soft_limit config =
  let org_cap = calculate_daily_cap config in
  min config.ed_daily_soft_limit (int_of_float (float_of_int org_cap *. 0.3))

(** 
 * [is_over_threshold]: Checks if daily statistics exceed overage threshold
 * 
 * Purpose:
 *   Determines if a day's email count exceeds the configured overage threshold
 *   requiring redistribution to maintain sustainable sending patterns.
 * 
 * Parameters:
 *   - config: Load balancing configuration with overage threshold
 *   - stats: Daily statistics to evaluate
 * 
 * Returns:
 *   Boolean indicating if day exceeds acceptable overage threshold
 * 
 * Business Logic:
 *   - Applies overage threshold multiplier to daily cap
 *   - Identifies days requiring load redistribution
 *   - Triggers redistribution algorithms when threshold exceeded
 *   - Maintains flexibility while preventing extreme clustering
 * 
 * Usage Example:
 *   Called by cap enforcement to identify redistribution candidates
 * 
 * Error Cases:
 *   - None expected (comparison operations on valid statistics)
 * 
 * @business_rule
 *)
let is_over_threshold config stats =
  let daily_cap = calculate_daily_cap config in
  let threshold = int_of_float (float_of_int daily_cap *. config.overage_threshold) in
  stats.total_count > threshold

(** 
 * [is_ed_over_soft_limit]: Checks if effective date emails exceed soft limit
 * 
 * Purpose:
 *   Determines if effective date anniversary emails on a day exceed the soft
 *   limit requiring targeted smoothing to prevent clustering.
 * 
 * Parameters:
 *   - config: Load balancing configuration with ED soft limit
 *   - stats: Daily statistics to evaluate
 * 
 * Returns:
 *   Boolean indicating if ED count exceeds soft limit threshold
 * 
 * Business Logic:
 *   - Compares ED count against calculated soft limit
 *   - Identifies days needing effective date smoothing
 *   - Triggers targeted redistribution for anniversary clusters
 *   - Maintains balanced distribution of anniversary emails
 * 
 * Usage Example:
 *   Called by smooth_effective_dates to identify smoothing candidates
 * 
 * Error Cases:
 *   - None expected (comparison operations on valid statistics)
 * 
 * @business_rule
 *)
let is_ed_over_soft_limit config stats =
  let ed_limit = calculate_ed_soft_limit config in
  stats.ed_count > ed_limit

(** 
 * [apply_jitter]: Applies deterministic jitter to redistribute email schedules
 * 
 * Purpose:
 *   Calculates jittered date for email schedule using contact ID and email type
 *   as seed to ensure consistent but distributed scheduling across window.
 * 
 * Parameters:
 *   - original_date: Original scheduled date for the email
 *   - contact_id: Contact identifier for deterministic jitter calculation
 *   - email_type: Email type for jitter algorithm differentiation
 *   - window_days: Size of redistribution window in days
 * 
 * Returns:
 *   Result containing new jittered date or load balancing error
 * 
 * Business Logic:
 *   - Uses deterministic algorithm for consistent redistribution
 *   - Leverages contact ID as seed for even distribution
 *   - Maintains email type context for algorithm tuning
 *   - Provides controlled randomization within specified window
 * 
 * Usage Example:
 *   Called by smoothing algorithms to redistribute clustered emails
 * 
 * Error Cases:
 *   - LoadBalancingError: Jitter calculation or date arithmetic failures
 * 
 * @performance @business_rule
 *)
let apply_jitter ~original_date ~contact_id ~email_type ~window_days =
  try
    let (year, _, _) = original_date in
    let jitter = calculate_jitter 
      ~contact_id 
      ~event_type:(string_of_email_type email_type)
      ~year 
      ~window_days in
    let new_date = add_days original_date jitter in
    Ok new_date
  with e ->
    Error (LoadBalancingError (Printf.sprintf "Jitter calculation failed: %s" (Printexc.to_string e)))

(** 
 * [smooth_effective_dates]: Redistributes clustered effective date anniversary emails
 * 
 * Purpose:
 *   Applies targeted smoothing algorithm to effective date emails that exceed
 *   soft limits, redistributing them across nearby dates to prevent clustering.
 * 
 * Parameters:
 *   - schedules: List of all email schedules to process
 *   - config: Load balancing configuration with smoothing parameters
 * 
 * Returns:
 *   List of schedules with effective date emails redistributed
 * 
 * Business Logic:
 *   - Separates effective date emails from other types for targeted processing
 *   - Identifies days exceeding ED soft limits requiring smoothing
 *   - Applies jitter within configured window to redistribute clusters
 *   - Ensures redistributed dates are not in the past
 *   - Recombines smoothed schedules with unmodified schedules
 * 
 * Usage Example:
 *   Called by distribute_schedules as first step in load balancing pipeline
 * 
 * Error Cases:
 *   - Jitter application failures handled gracefully by keeping original dates
 * 
 * @business_rule @performance
 *)
let smooth_effective_dates schedules config =
  let ed_schedules = List.filter (fun s ->
    match s.email_type with
    | Anniversary EffectiveDate -> true
    | _ -> false
  ) schedules in
  
  let other_schedules = List.filter (fun s ->
    match s.email_type with
    | Anniversary EffectiveDate -> false
    | _ -> true
  ) schedules in
  
  let daily_stats = group_by_date ed_schedules in
  let _dates_to_smooth = List.filter (is_ed_over_soft_limit config) daily_stats in
  
  let smoothed_schedules = List.fold_left (fun acc stats ->
    if is_ed_over_soft_limit config stats then
      let date_schedules = List.filter (fun s -> 
        compare_date s.scheduled_date stats.date = 0
      ) ed_schedules in
      
      let window_days = config.ed_smoothing_window_days in
      let redistributed = List.map (fun schedule ->
        match apply_jitter 
          ~original_date:schedule.scheduled_date
          ~contact_id:schedule.contact_id
          ~email_type:schedule.email_type
          ~window_days with
        | Ok new_date -> 
            let today = current_date () in
            if compare_date new_date today >= 0 then
              { schedule with scheduled_date = new_date }
            else
              schedule
        | Error _ -> schedule
      ) date_schedules in
      redistributed @ acc
    else
      let date_schedules = List.filter (fun s -> 
        compare_date s.scheduled_date stats.date = 0
      ) ed_schedules in
      date_schedules @ acc
  ) [] daily_stats in
  
  smoothed_schedules @ other_schedules

(** 
 * [enforce_daily_caps]: Enforces hard daily limits by redistributing excess emails
 * 
 * Purpose:
 *   Core cap enforcement algorithm that identifies overloaded days and redistributes
 *   emails to maintain daily sending limits while preserving priority ordering.
 * 
 * Parameters:
 *   - schedules: List of email schedules to process
 *   - config: Load balancing configuration with daily caps and thresholds
 * 
 * Returns:
 *   List of schedules with excess emails redistributed to maintain caps
 * 
 * Business Logic:
 *   - Groups schedules by date and sorts chronologically
 *   - Identifies days exceeding overage threshold
 *   - Sorts schedules by priority to preserve important emails
 *   - Moves excess schedules to next available day or catch-up distribution
 *   - Maintains email priority ordering during redistribution
 * 
 * Usage Example:
 *   Called by distribute_schedules after effective date smoothing
 * 
 * Error Cases:
 *   - None expected (uses deterministic redistribution algorithms)
 * 
 * @business_rule @performance
 *)
let rec enforce_daily_caps schedules config =
  let day_stats_list = group_by_date schedules in
  
  let sorted_stats = List.sort (fun (a : daily_stats) (b : daily_stats) -> 
    compare_date a.date b.date
  ) day_stats_list in
  
  let rec process_days acc remaining_stats =
    match remaining_stats with
    | [] -> acc
    | stats :: rest ->
        if is_over_threshold config stats then
          let daily_cap = calculate_daily_cap config in
          let date_schedules = List.filter (fun s ->
            compare_date s.scheduled_date stats.date = 0
          ) schedules in
          
          let sorted_schedules = List.sort (fun (a : email_schedule) (b : email_schedule) ->
            compare a.priority b.priority
          ) date_schedules in
          
          let (keep_schedules, move_schedules) = 
            let rec split kept moved remaining count =
              if count >= daily_cap || remaining = [] then
                (List.rev kept, List.rev moved @ remaining)
              else
                match remaining with
                | schedule :: rest ->
                    split (schedule :: kept) moved rest (count + 1)
                | [] -> (List.rev kept, List.rev moved)
            in
            split [] [] sorted_schedules 0
          in
          
          let moved_schedules = match rest with
            | next_stats :: _ ->
                List.map (fun schedule ->
                  { schedule with scheduled_date = next_stats.date }
                ) move_schedules
            | [] ->
                distribute_catch_up move_schedules config
          in
          
          process_days (keep_schedules @ moved_schedules @ acc) rest
        else
          let date_schedules = List.filter (fun s ->
            compare_date s.scheduled_date stats.date = 0
          ) schedules in
          process_days (date_schedules @ acc) rest
  in
  
  process_days [] sorted_stats

(** 
 * [distribute_catch_up]: Distributes overflow emails across catch-up period
 * 
 * Purpose:
 *   Handles emails that cannot be accommodated in normal scheduling by spreading
 *   them across a configured catch-up period to ensure delivery.
 * 
 * Parameters:
 *   - schedules: List of overflow email schedules to redistribute
 *   - config: Load balancing configuration with catch-up spread parameters
 * 
 * Returns:
 *   List of schedules with dates spread across catch-up period
 * 
 * Business Logic:
 *   - Uses modulo operation for even distribution across catch-up days
 *   - Starts from tomorrow to avoid same-day delivery issues
 *   - Ensures all overflow emails eventually get scheduled
 *   - Provides predictable distribution pattern for capacity planning
 * 
 * Usage Example:
 *   Called by enforce_daily_caps when no future capacity available
 * 
 * Error Cases:
 *   - None expected (deterministic date calculation)
 * 
 * @business_rule
 *)
and distribute_catch_up schedules config =
  let spread_days = config.catch_up_spread_days in
  let today = current_date () in
  
  List.mapi (fun index schedule ->
    let day_offset = (index mod spread_days) + 1 in
    let new_date = add_days today day_offset in
    { schedule with scheduled_date = new_date }
  ) schedules

(** 
 * [distribute_schedules]: Main load balancing orchestration function
 * 
 * Purpose:
 *   Coordinates complete load balancing pipeline applying smoothing algorithms
 *   and cap enforcement to create balanced email distribution.
 * 
 * Parameters:
 *   - schedules: List of all email schedules to balance
 *   - config: Load balancing configuration with all parameters
 * 
 * Returns:
 *   Result containing balanced schedules or load balancing error
 * 
 * Business Logic:
 *   - Applies effective date smoothing first for targeted redistribution
 *   - Follows with daily cap enforcement for hard limit compliance
 *   - Uses pipeline approach for layered load balancing
 *   - Provides comprehensive error handling for all balancing operations
 * 
 * Usage Example:
 *   Called by schedule_emails_streaming after all schedules generated
 * 
 * Error Cases:
 *   - LoadBalancingError: Any failures in smoothing or cap enforcement
 * 
 * @integration_point @performance @business_rule
 *)
let distribute_schedules schedules config =
  try
    let result = schedules
      |> (fun s -> smooth_effective_dates s config)
      |> (fun s -> enforce_daily_caps s config) in
    Ok result
  with e ->
    Error (LoadBalancingError (Printf.sprintf "Load balancing failed: %s" (Printexc.to_string e)))

(** 
 * [analyze_distribution]: Analyzes email distribution for reporting and monitoring
 * 
 * Purpose:
 *   Computes comprehensive statistics on email distribution across dates for
 *   capacity planning, performance monitoring, and load balancing assessment.
 * 
 * Parameters:
 *   - schedules: List of email schedules to analyze
 * 
 * Returns:
 *   distribution_analysis record with detailed statistics
 * 
 * Business Logic:
 *   - Groups schedules by date for daily analysis
 *   - Calculates total volume and time span metrics
 *   - Computes distribution statistics (average, min, max, variance)
 *   - Provides insights for capacity planning and system optimization
 * 
 * Usage Example:
 *   Called by get_scheduling_summary for comprehensive reporting
 * 
 * Error Cases:
 *   - Handles empty schedule lists gracefully with zero values
 * 
 * @integration_point @performance
 *)
let analyze_distribution schedules =
  let daily_stats = group_by_date schedules in
  let total_emails = List.length schedules in
  let total_days = List.length daily_stats in
  let avg_per_day = if total_days > 0 then 
    float_of_int total_emails /. float_of_int total_days 
  else 0.0 in
  
  let max_day = List.fold_left (fun acc stats ->
    max acc stats.total_count
  ) 0 daily_stats in
  
  let min_day = if daily_stats = [] then 0 else
    List.fold_left (fun acc stats ->
      min acc stats.total_count
    ) max_int daily_stats in
  
  {
    total_emails;
    total_days;
    avg_per_day;
    max_day;
    min_day;
    distribution_variance = max_day - min_day;
  }

(** 
 * [validate_config]: Validates load balancing configuration parameters
 * 
 * Purpose:
 *   Ensures all load balancing configuration values are within valid ranges
 *   and logically consistent to prevent runtime errors and invalid behavior.
 * 
 * Parameters:
 *   - config: Load balancing configuration to validate
 * 
 * Returns:
 *   Result indicating validation success or configuration errors
 * 
 * Business Logic:
 *   - Validates percentage cap is between 0 and 1
 *   - Ensures all day limits and windows are positive
 *   - Checks overage threshold is greater than 1.0
 *   - Accumulates all validation errors for comprehensive feedback
 * 
 * Usage Example:
 *   Called before using configuration in load balancing operations
 * 
 * Error Cases:
 *   - ConfigurationError: Invalid parameter values with detailed descriptions
 * 
 * @integration_point
 *)
let validate_config config =
  let errors = [] in
  let errors = if config.daily_send_percentage_cap <= 0.0 || config.daily_send_percentage_cap > 1.0 then
    "daily_send_percentage_cap must be between 0 and 1" :: errors
  else errors in
  let errors = if config.ed_daily_soft_limit <= 0 then
    "ed_daily_soft_limit must be positive" :: errors
  else errors in
  let errors = if config.ed_smoothing_window_days <= 0 then
    "ed_smoothing_window_days must be positive" :: errors
  else errors in
  let errors = if config.catch_up_spread_days <= 0 then
    "catch_up_spread_days must be positive" :: errors
  else errors in
  let errors = if config.overage_threshold <= 1.0 then
    "overage_threshold must be greater than 1.0" :: errors
  else errors in
  match errors with
  | [] -> Ok ()
  | _ -> Error (ConfigurationError (String.concat "; " errors))

(** 
 * [default_config]: Creates default load balancing configuration
 * 
 * Purpose:
 *   Provides sensible default configuration values for load balancing based on
 *   total contact count and proven operational parameters.
 * 
 * Parameters:
 *   - total_contacts: Total number of contacts for capacity calculations
 * 
 * Returns:
 *   load_balancing_config record with default values
 * 
 * Business Logic:
 *   - Sets 7% daily sending cap for sustainable volume
 *   - Limits effective date emails to 15 per day
 *   - Uses 5-day smoothing window for anniversary redistribution
 *   - Provides 7-day catch-up period for overflow emails
 *   - Sets 20% overage threshold before redistribution
 * 
 * Usage Example:
 *   Called by create_context to initialize load balancing configuration
 * 
 * Error Cases:
 *   - None expected (uses validated default values)
 * 
 * @integration_point
 *)
let default_config total_contacts = {
  daily_send_percentage_cap = 0.07;
  ed_daily_soft_limit = 15;
  ed_smoothing_window_days = 5;
  catch_up_spread_days = 7;
  overage_threshold = 1.2;
  total_contacts;
}

================
File: lib/utils/audit_simple.ml
================
open Types

let calculate_checksum data =
  let hash = Hashtbl.hash data in
  Printf.sprintf "%08x" hash

let calculate_contacts_checksum contacts =
  Printf.sprintf "checksum_%d" (List.length contacts)

let log_scheduling_event ~run_id ~event ~details =
  Printf.printf "[%s] %s - %s\n" run_id event details

let log_error ~run_id ~error =
  let error_message = string_of_error error in
  log_scheduling_event ~run_id ~event:"ERROR" ~details:error_message

================
File: lib/utils/config.ml
================
open Types

type t = {
  timezone: string;
  batch_size: int;
  max_memory_mb: int;
  
  send_time_hour: int;
  send_time_minute: int;
  
  birthday_days_before: int;
  effective_date_days_before: int;
  pre_window_buffer: int;
  followup_delay_days: int;
  
  max_emails_per_period: int;
  period_days: int;
  
  daily_cap_percentage: float;
  ed_soft_limit: int;
  smoothing_window: int;
  
  database_path: string;
  backup_dir: string;
  backup_retention_days: int;
  
  (* Organization-specific configuration *)
  organization: organization_config;
}

let default = {
  timezone = "America/Chicago";
  batch_size = 10_000;
  max_memory_mb = 1024;
  
  send_time_hour = 8;
  send_time_minute = 30;
  
  birthday_days_before = 14;
  effective_date_days_before = 30;
  pre_window_buffer = 60;
  followup_delay_days = 2;
  
  max_emails_per_period = 3;
  period_days = 30;
  
  daily_cap_percentage = 0.07;
  ed_soft_limit = 15;
  smoothing_window = 5;
  
  database_path = "org-206.sqlite3";
  backup_dir = "./backups";
  backup_retention_days = 7;
  
  (* Default organization configuration *)
  organization = {
    enable_post_window_emails = true; (* Default: enable post-window emails *)
    effective_date_first_email_months = 11; (* Default: 11 months before first anniversary *)
    exclude_failed_underwriting_global = false; (* Default: don't exclude failed underwriting globally *)
    send_without_zipcode_for_universal = true; (* Default: send to contacts without zip for universal campaigns *)
  };
}

(* Simplified config loading - just return default for now *)
let load_from_json _json_string =
  Ok default

let load_from_file _filename =
  Ok default

================
File: lib/utils/date_time.ml
================
(* Core types leveraging Ptime's robust date handling *)
type date = Ptime.date  (* This is (int * int * int) but we'll use Ptime.t internally *)
type time = (int * int * int) * int  (* ((hour, minute, second), tz_offset_s) *)
type datetime = Ptime.t

(** 
 * [date_to_ptime]: Internal helper to convert date tuple to Ptime.t for calculations
 * 
 * Purpose:
 *   Safely converts date tuple format to Ptime.t for robust date arithmetic
 *   operations while providing clear error messages for invalid dates.
 * 
 * Parameters:
 *   - (year, month, day): Date tuple with integer components
 * 
 * Returns:
 *   Ptime.t representation suitable for date calculations
 * 
 * Business Logic:
 *   - Validates date components during conversion
 *   - Leverages Ptime's robust calendar logic
 *   - Handles leap year validation automatically
 *   - Provides basis for all date arithmetic operations
 * 
 * Usage Example:
 *   Used internally by add_days, compare_date, and anniversary calculations
 * 
 * Error Cases:
 *   - Fails with descriptive message for invalid dates (e.g., Feb 30)
 * 
 * @performance
 *)
let date_to_ptime (year, month, day) =
  match Ptime.of_date (year, month, day) with
  | Some ptime -> ptime
  | None -> failwith (Printf.sprintf "Invalid date: %04d-%02d-%02d" year month day)

(** 
 * [ptime_to_date]: Internal helper to convert Ptime.t back to date tuple
 * 
 * Purpose:
 *   Converts Ptime.t representation back to date tuple format for external use
 *   while maintaining precision and avoiding calculation errors.
 * 
 * Parameters:
 *   - ptime: Ptime.t instance from date calculations
 * 
 * Returns:
 *   Date tuple (year, month, day) matching system date format
 * 
 * Business Logic:
 *   - Preserves exact date values from calculations
 *   - Maintains consistency with external date format
 *   - Ensures no precision loss during conversion
 * 
 * Usage Example:
 *   Used internally by add_days and next_anniversary for result conversion
 * 
 * Error Cases:
 *   - None expected (Ptime.t should always convert to valid date)
 * 
 * @performance
 *)
let ptime_to_date ptime = Ptime.to_date ptime

(** 
 * [make_date]: Smart constructor for validated date creation
 * 
 * Purpose:
 *   Creates date tuples with comprehensive validation to prevent invalid dates
 *   from entering the system and causing calculation errors.
 * 
 * Parameters:
 *   - year: Four-digit year value
 *   - month: Month value (1-12)
 *   - day: Day value (1-31, validated against month/year)
 * 
 * Returns:
 *   Valid date tuple after successful validation
 * 
 * Business Logic:
 *   - Validates date components against calendar rules
 *   - Handles leap year validation for February 29
 *   - Ensures month/day combinations are valid
 *   - Provides fail-fast validation for data integrity
 * 
 * Usage Example:
 *   Used when creating dates from user input or database values
 * 
 * Error Cases:
 *   - Fails with descriptive message for invalid date combinations
 * 
 * @data_flow
 *)
let make_date year month day =
  match Ptime.of_date (year, month, day) with
  | Some ptime -> Ptime.to_date ptime
  | None -> failwith (Printf.sprintf "Invalid date: %04d-%02d-%02d" year month day)

(** 
 * [make_time]: Smart constructor for validated time creation
 * 
 * Purpose:
 *   Creates time tuples with validation to ensure time components are within
 *   valid ranges for consistent time handling across the system.
 * 
 * Parameters:
 *   - hour: Hour value (0-23)
 *   - minute: Minute value (0-59)
 *   - second: Second value (0-59)
 * 
 * Returns:
 *   Valid time tuple with timezone offset after successful validation
 * 
 * Business Logic:
 *   - Validates time components against 24-hour clock rules
 *   - Uses UTC timezone offset for consistency
 *   - Provides foundation for scheduling time calculations
 * 
 * Usage Example:
 *   Used when creating scheduled send times for email delivery
 * 
 * Error Cases:
 *   - Fails with descriptive message for invalid time values
 * 
 * @data_flow
 *)
let make_time hour minute second =
  match Ptime.of_date_time ((1970, 1, 1), ((hour, minute, second), 0)) with
  | Some ptime -> 
      let (_, time) = Ptime.to_date_time ptime in
      time
  | None -> failwith (Printf.sprintf "Invalid time: %02d:%02d:%02d" hour minute second)

(** 
 * [make_datetime]: Combines date and time into datetime representation
 * 
 * Purpose:
 *   Creates complete datetime objects for precise scheduling and timestamp
 *   operations while validating the date/time combination.
 * 
 * Parameters:
 *   - date: Date tuple (year, month, day)
 *   - time: Time tuple ((hour, minute, second), timezone_offset)
 * 
 * Returns:
 *   Ptime.t datetime representation for scheduling operations
 * 
 * Business Logic:
 *   - Combines separate date and time components safely
 *   - Validates the complete datetime combination
 *   - Provides basis for precise scheduling calculations
 * 
 * Usage Example:
 *   Used when creating specific send timestamps for email schedules
 * 
 * Error Cases:
 *   - Fails for invalid date/time combinations
 * 
 * @data_flow
 *)
let make_datetime date time =
  match Ptime.of_date_time (date, (time, 0)) with
  | Some ptime -> ptime
  | None -> failwith "Invalid date/time combination"

(** 
 * [current_date]: Gets current system date for scheduling calculations
 * 
 * Purpose:
 *   Provides current date as baseline for anniversary calculations and
 *   scheduling operations, ensuring consistent "today" reference.
 * 
 * Parameters:
 *   - None
 * 
 * Returns:
 *   Current date tuple representing today's date
 * 
 * Business Logic:
 *   - Uses system clock for current date determination
 *   - Provides consistent baseline for all date calculations
 *   - Ensures scheduling operates relative to actual current date
 * 
 * Usage Example:
 *   Called by anniversary calculation and exclusion window functions
 * 
 * Error Cases:
 *   - None expected (system clock should always be available)
 * 
 * @integration_point
 *)
let current_date () =
  let now = Ptime_clock.now () in
  Ptime.to_date now

(** 
 * [current_datetime]: Gets current system datetime for run tracking
 * 
 * Purpose:
 *   Provides precise current timestamp for run identification, performance
 *   tracking, and audit trail creation in scheduling operations.
 * 
 * Parameters:
 *   - None
 * 
 * Returns:
 *   Current Ptime.t datetime with full precision
 * 
 * Business Logic:
 *   - Captures precise execution timestamp
 *   - Enables performance monitoring and run tracking
 *   - Provides audit trail for scheduling operations
 * 
 * Usage Example:
 *   Used by generate_run_id and performance monitoring functions
 * 
 * Error Cases:
 *   - None expected (system clock should always be available)
 * 
 * @integration_point
 *)
let current_datetime () =
  Ptime_clock.now ()

(** 
 * [add_days]: Adds specified number of days to a date with robust arithmetic
 * 
 * Purpose:
 *   Performs reliable date arithmetic that handles month boundaries, leap years,
 *   and year transitions correctly for scheduling calculations.
 * 
 * Parameters:
 *   - date: Starting date tuple
 *   - n: Number of days to add (positive or negative)
 * 
 * Returns:
 *   New date tuple after adding the specified days
 * 
 * Business Logic:
 *   - Handles month and year boundaries correctly
 *   - Accounts for leap years in February calculations
 *   - Supports both forward and backward date arithmetic
 *   - Uses Ptime's robust calendar arithmetic internally
 * 
 * Usage Example:
 *   Used for calculating send dates based on days_before settings
 * 
 * Error Cases:
 *   - Fails on arithmetic overflow (extremely large day values)
 * 
 * @performance @business_rule
 *)
let add_days date n =
  let ptime = date_to_ptime date in
  let span = Ptime.Span.of_int_s (n * 24 * 3600) in
  match Ptime.add_span ptime span with
  | Some new_ptime -> ptime_to_date new_ptime
  | None -> failwith "Date arithmetic overflow"

(** 
 * [compare_date]: Compares two dates with robust calendar logic
 * 
 * Purpose:
 *   Provides reliable date comparison that handles edge cases and provides
 *   consistent ordering for scheduling and exclusion window operations.
 * 
 * Parameters:
 *   - d1: First date tuple for comparison
 *   - d2: Second date tuple for comparison
 * 
 * Returns:
 *   Integer indicating comparison result (-1, 0, 1)
 * 
 * Business Logic:
 *   - Uses Ptime's robust comparison logic
 *   - Handles leap year and month boundary edge cases
 *   - Provides consistent ordering for date-based decisions
 * 
 * Usage Example:
 *   Used by exclusion window and anniversary calculation functions
 * 
 * Error Cases:
 *   - None expected for valid dates
 * 
 * @performance
 *)
let compare_date d1 d2 =
  let ptime1 = date_to_ptime d1 in
  let ptime2 = date_to_ptime d2 in
  Ptime.compare ptime1 ptime2

(** 
 * [diff_days]: Calculates difference between dates in days
 * 
 * Purpose:
 *   Computes exact day difference between dates for spread calculations,
 *   exclusion window timing, and scheduling distribution.
 * 
 * Parameters:
 *   - d1: First date tuple (subtracted from)
 *   - d2: Second date tuple (subtracted)
 * 
 * Returns:
 *   Integer number of days difference (d1 - d2)
 * 
 * Business Logic:
 *   - Calculates exact day difference using robust calendar arithmetic
 *   - Handles month boundaries and leap years correctly
 *   - Provides foundation for date range calculations
 * 
 * Usage Example:
 *   Used by calculate_spread_date for campaign distribution
 * 
 * Error Cases:
 *   - None expected for valid dates
 * 
 * @performance @business_rule
 *)
let diff_days d1 d2 =
  let ptime1 = date_to_ptime d1 in
  let ptime2 = date_to_ptime d2 in
  let span = Ptime.diff ptime1 ptime2 in
  let seconds = Ptime.Span.to_float_s span in
  int_of_float (seconds /. (24.0 *. 3600.0))

(** 
 * [is_leap_year]: Determines if year is a leap year using robust logic
 * 
 * Purpose:
 *   Accurately identifies leap years for February 29 handling in anniversary
 *   calculations and date validation operations.
 * 
 * Parameters:
 *   - year: Four-digit year value to check
 * 
 * Returns:
 *   Boolean indicating if year is a leap year
 * 
 * Business Logic:
 *   - Uses Ptime's calendar logic for accurate leap year determination
 *   - Handles century years and other edge cases correctly
 *   - Critical for February 29 anniversary handling
 * 
 * Usage Example:
 *   Used by next_anniversary for leap year date adjustments
 * 
 * Error Cases:
 *   - None expected for valid year values
 * 
 * @business_rule
 *)
let is_leap_year year =
  (* February 29th exists in leap years - let Ptime handle the logic *)
  match Ptime.of_date (year, 2, 29) with
  | Some _ -> true
  | None -> false

(** 
 * [days_in_month]: Calculates number of days in specified month/year
 * 
 * Purpose:
 *   Determines exact days in month accounting for leap years, providing
 *   foundation for date validation and calendar calculations.
 * 
 * Parameters:
 *   - year: Year value for leap year context
 *   - month: Month value (1-12)
 * 
 * Returns:
 *   Integer number of days in the specified month
 * 
 * Business Logic:
 *   - Accounts for leap years in February calculations
 *   - Uses Ptime validation to find last valid day
 *   - Provides accurate month length for date operations
 * 
 * Usage Example:
 *   Used internally for date validation and calendar operations
 * 
 * Error Cases:
 *   - Returns fallback value for invalid month values
 * 
 * @performance
 *)
let days_in_month year month =
  (* Find the last valid day of the month *)
  let rec find_last_day day =
    if day > 31 then 28 (* Fallback - should never happen *)
    else
      match Ptime.of_date (year, month, day) with
      | Some _ -> day
      | None -> find_last_day (day - 1)
  in
  find_last_day 31

(** 
 * [next_anniversary]: Calculates next occurrence of anniversary date
 * 
 * Purpose:
 *   Core anniversary logic that finds the next occurrence of a significant date
 *   relative to today, handling leap year edge cases for February 29 birthdays.
 * 
 * Parameters:
 *   - today: Current date for calculation reference
 *   - event_date: Original anniversary date (birthday, effective date)
 * 
 * Returns:
 *   Date tuple representing next anniversary occurrence
 * 
 * Business Logic:
 *   - Tries current year first, then next year if already passed
 *   - Handles February 29 leap year birthdays by adjusting to February 28
 *   - Uses robust date comparison to determine if anniversary has passed
 *   - Critical for accurate anniversary email scheduling
 * 
 * Usage Example:
 *   Used by calculate_anniversary_emails for birthday and effective date scheduling
 * 
 * Error Cases:
 *   - None expected (handles leap year edge cases gracefully)
 * 
 * @business_rule @data_flow
 *)
let next_anniversary today event_date =
  let today_ptime = date_to_ptime today in
  let (today_year, _, _) = today in
  let (_, event_month, event_day) = event_date in
  
  (* Try this year first - let Ptime handle leap year edge cases *)
  let this_year_candidate_tuple = 
    if event_month = 2 && event_day = 29 && not (is_leap_year today_year) then
      (today_year, 2, 28) (* Feb 29 -> Feb 28 in non-leap years *)
    else
      (today_year, event_month, event_day)
  in
  
  (* Use Ptime's robust comparison instead of manual tuple comparison *)
  let this_year_ptime = date_to_ptime this_year_candidate_tuple in
  if Ptime.compare this_year_ptime today_ptime >= 0 then
    this_year_candidate_tuple
  else
    (* Try next year *)
    let next_year = today_year + 1 in
    if event_month = 2 && event_day = 29 && not (is_leap_year next_year) then
      (next_year, 2, 28)
    else
      (next_year, event_month, event_day)

(** 
 * [string_of_date]: Converts date tuple to standardized string format
 * 
 * Purpose:
 *   Provides consistent string representation of dates for logging, database
 *   storage, and user interface display across the system.
 * 
 * Parameters:
 *   - (year, month, day): Date tuple to format
 * 
 * Returns:
 *   String in ISO 8601 format "YYYY-MM-DD"
 * 
 * Business Logic:
 *   - Uses zero-padded format for consistent string length
 *   - Follows ISO 8601 standard for international compatibility
 *   - Provides readable format for logs and debugging
 *   - Ensures consistent date representation across components
 * 
 * Usage Example:
 *   Used for logging, database queries, and debug output
 * 
 * Error Cases:
 *   - None expected (all valid date tuples should format correctly)
 * 
 * @integration_point
 *)
let string_of_date (year, month, day) = 
  Printf.sprintf "%04d-%02d-%02d" year month day

(** 
 * [string_of_time]: Converts time tuple to standardized string format
 * 
 * Purpose:
 *   Provides consistent string representation of times for logging and
 *   scheduling display, focusing on the time component only.
 * 
 * Parameters:
 *   - ((hour, minute, second), _): Time tuple with timezone offset (ignored)
 * 
 * Returns:
 *   String in 24-hour format "HH:MM:SS"
 * 
 * Business Logic:
 *   - Uses 24-hour format for clarity and consistency
 *   - Zero-pads all components for fixed-width display
 *   - Ignores timezone offset for local time display
 *   - Provides readable format for schedule times
 * 
 * Usage Example:
 *   Used for displaying scheduled send times in logs and interfaces
 * 
 * Error Cases:
 *   - None expected (all valid time tuples should format correctly)
 * 
 * @integration_point
 *)
let string_of_time ((hour, minute, second), _) =
  Printf.sprintf "%02d:%02d:%02d" hour minute second

(** 
 * [string_of_datetime]: Converts datetime to combined date/time string
 * 
 * Purpose:
 *   Provides comprehensive string representation of complete datetime for
 *   precise logging, run tracking, and timestamp display.
 * 
 * Parameters:
 *   - dt: Ptime.t datetime to format
 * 
 * Returns:
 *   String combining date and time "YYYY-MM-DD HH:MM:SS"
 * 
 * Business Logic:
 *   - Combines date and time formatting for complete timestamp
 *   - Uses space separator for readability
 *   - Provides precise timestamp for audit trails
 *   - Maintains consistency with component string formats
 * 
 * Usage Example:
 *   Used for run ID generation and detailed logging timestamps
 * 
 * Error Cases:
 *   - None expected (valid datetime should always format correctly)
 * 
 * @integration_point
 *)
let string_of_datetime dt =
  let (date, time) = Ptime.to_date_time dt in
  Printf.sprintf "%s %s" (string_of_date date) (string_of_time time)

(** 
 * [parse_date]: Parses ISO date string into date tuple with validation
 * 
 * Purpose:
 *   Safely converts string date representations from external sources into
 *   validated date tuples for internal processing.
 * 
 * Parameters:
 *   - date_str: String in "YYYY-MM-DD" format
 * 
 * Returns:
 *   Valid date tuple after parsing and validation
 * 
 * Business Logic:
 *   - Expects ISO 8601 format with dash separators
 *   - Validates parsed components using make_date validation
 *   - Provides safe conversion from external string data
 *   - Ensures invalid dates are rejected early
 * 
 * Usage Example:
 *   Used when parsing dates from configuration files or API inputs
 * 
 * Error Cases:
 *   - Fails with descriptive message for invalid format or invalid dates
 * 
 * @data_flow
 *)
let parse_date date_str =
  match String.split_on_char '-' date_str with
  | [year_str; month_str; day_str] ->
      let year = int_of_string year_str in
      let month = int_of_string month_str in
      let day = int_of_string day_str in
      make_date year month day
  | _ -> failwith ("Invalid date format: " ^ date_str)

(** 
 * [parse_time]: Parses time string into time tuple with validation
 * 
 * Purpose:
 *   Safely converts string time representations from external sources into
 *   validated time tuples for scheduling operations.
 * 
 * Parameters:
 *   - time_str: String in "HH:MM:SS" format
 * 
 * Returns:
 *   Valid time tuple after parsing and validation
 * 
 * Business Logic:
 *   - Expects 24-hour format with colon separators
 *   - Validates parsed components using make_time validation
 *   - Provides safe conversion from external string data
 *   - Ensures invalid times are rejected early
 * 
 * Usage Example:
 *   Used when parsing send times from configuration files
 * 
 * Error Cases:
 *   - Fails with descriptive message for invalid format or invalid times
 * 
 * @data_flow
 *)
let parse_time time_str =
  match String.split_on_char ':' time_str with
  | [hour_str; minute_str; second_str] ->
      let hour = int_of_string hour_str in
      let minute = int_of_string minute_str in
      let second = int_of_string second_str in
      make_time hour minute second
  | _ -> failwith ("Invalid time format: " ^ time_str)

(** 
 * [with_fixed_time]: Utility function for testing with controlled time
 * 
 * Purpose:
 *   Provides mechanism for testing time-dependent functionality with fixed
 *   time values, enabling deterministic test results.
 * 
 * Parameters:
 *   - fixed_time: Fixed time value for testing (currently acknowledged but not used)
 *   - f: Function to execute with controlled time context
 * 
 * Returns:
 *   Result of executing function f
 * 
 * Business Logic:
 *   - Acknowledges fixed time parameter for future implementation
 *   - Currently passes through to normal function execution
 *   - Provides foundation for comprehensive time mocking
 *   - Enables deterministic testing of scheduling logic
 * 
 * Usage Example:
 *   Used in test suites to control time-dependent behavior
 * 
 * Error Cases:
 *   - None expected (passes through underlying function errors)
 * 
 * @integration_point
 *)
let with_fixed_time fixed_time f =
  (* Note: Full time mocking would require overriding current_date/current_datetime globally *)
  (* For now, acknowledge the fixed_time parameter and call function normally *)
  let _ = fixed_time in (* Acknowledge parameter to avoid unused warning *)
  f ()

================
File: lib/utils/simple_date.ml
================
type date = {
  year: int;
  month: int;
  day: int;
}

type time = {
  hour: int;
  minute: int;
  second: int;
}

type datetime = {
  date: date;
  time: time;
}

let make_date year month day = { year; month; day }
let make_time hour minute second = { hour; minute; second }
let make_datetime date time = { date; time }

let current_date () =
  let tm = Unix.localtime (Unix.time ()) in
  { year = tm.tm_year + 1900; month = tm.tm_mon + 1; day = tm.tm_mday }

let current_datetime () =
  let tm = Unix.localtime (Unix.time ()) in
  {
    date = { year = tm.tm_year + 1900; month = tm.tm_mon + 1; day = tm.tm_mday };
    time = { hour = tm.tm_hour; minute = tm.tm_min; second = tm.tm_sec }
  }

let is_leap_year year =
  (year mod 4 = 0 && year mod 100 <> 0) || (year mod 400 = 0)

let days_in_month year month =
  match month with
  | 1 | 3 | 5 | 7 | 8 | 10 | 12 -> 31
  | 4 | 6 | 9 | 11 -> 30
  | 2 -> if is_leap_year year then 29 else 28
  | _ -> failwith "Invalid month"

let add_days date n =
  let rec add_days_rec d remaining =
    if remaining = 0 then d
    else if remaining > 0 then
      let days_in_current_month = days_in_month d.year d.month in
      if d.day + remaining <= days_in_current_month then
        { d with day = d.day + remaining }
      else
        let days_used = days_in_current_month - d.day + 1 in
        let new_date = 
          if d.month = 12 then
            { year = d.year + 1; month = 1; day = 1 }
          else
            { d with month = d.month + 1; day = 1 }
        in
        add_days_rec new_date (remaining - days_used)
    else
      let days_to_subtract = -remaining in
      if d.day > days_to_subtract then
        { d with day = d.day - days_to_subtract }
      else
        let new_date = 
          if d.month = 1 then
            let prev_year = d.year - 1 in
            let days_in_dec = days_in_month prev_year 12 in
            { year = prev_year; month = 12; day = days_in_dec }
          else
            let prev_month = d.month - 1 in
            let days_in_prev = days_in_month d.year prev_month in
            { d with month = prev_month; day = days_in_prev }
        in
        add_days_rec new_date (remaining + d.day)
  in
  add_days_rec date n

let compare_date d1 d2 =
  if d1.year <> d2.year then compare d1.year d2.year
  else if d1.month <> d2.month then compare d1.month d2.month
  else compare d1.day d2.day

let diff_days d1 d2 =
  let days_since_epoch date =
    let rec count_days acc year =
      if year >= date.year then acc
      else
        let days_in_year = if is_leap_year year then 366 else 365 in
        count_days (acc + days_in_year) (year + 1)
    in
    let year_days = count_days 0 1970 in
    let month_days = ref 0 in
    for m = 1 to date.month - 1 do
      month_days := !month_days + days_in_month date.year m
    done;
    year_days + !month_days + date.day
  in
  days_since_epoch d1 - days_since_epoch d2

let next_anniversary today event_date =
  let this_year_candidate = { event_date with year = today.year } in
  let this_year_candidate = 
    if event_date.month = 2 && event_date.day = 29 && not (is_leap_year today.year) then
      { this_year_candidate with day = 28 }
    else
      this_year_candidate
  in
  
  if compare_date this_year_candidate today >= 0 then
    this_year_candidate
  else
    let next_year = today.year + 1 in
    let next_year_candidate = { event_date with year = next_year } in
    if event_date.month = 2 && event_date.day = 29 && not (is_leap_year next_year) then
      { next_year_candidate with day = 28 }
    else
      next_year_candidate

let string_of_date d = Printf.sprintf "%04d-%02d-%02d" d.year d.month d.day
let string_of_time t = Printf.sprintf "%02d:%02d:%02d" t.hour t.minute t.second
let string_of_datetime dt = 
  Printf.sprintf "%s %s" (string_of_date dt.date) (string_of_time dt.time)

let parse_date date_str =
  match String.split_on_char '-' date_str with
  | [year_str; month_str; day_str] ->
      let year = int_of_string year_str in
      let month = int_of_string month_str in
      let day = int_of_string day_str in
      { year; month; day }
  | _ -> failwith ("Invalid date format: " ^ date_str)

================
File: lib/utils/zip_data.ml
================
open Types

type zip_info = {
  state: string;
  counties: string list;
  cities: string list option;
}

let zip_table = Hashtbl.create 50000

(* Hardcoded common ZIP codes for testing - in production this would load from database *)
let common_zip_mappings = [
  ("90210", "CA"); (* Beverly Hills, CA *)
  ("10001", "NY"); (* New York, NY *)
  ("06830", "CT"); (* Greenwich, CT *)
  ("89101", "NV"); (* Las Vegas, NV *)
  ("63101", "MO"); (* St. Louis, MO *)
  ("97201", "OR"); (* Portland, OR *)
  ("02101", "MA"); (* Boston, MA *)
  ("98101", "WA"); (* Seattle, WA *)
  ("20001", "WA"); (* Washington, DC - treat as WA for testing *)
  ("83301", "ID"); (* Twin Falls, ID *)
  ("40201", "KY"); (* Louisville, KY *)
  ("21201", "MD"); (* Baltimore, MD *)
  ("23220", "VA"); (* Richmond, VA *)
  ("73301", "OK"); (* Austin, TX - treat as OK for testing *)
]

let load_zip_data () =
  try
    (* Load hardcoded mappings *)
    List.iter (fun (zip, state_str) ->
      let zip_info = { 
        state = state_str; 
        counties = ["County"]; 
        cities = Some ["City"] 
      } in
      Hashtbl.add zip_table zip zip_info
    ) common_zip_mappings;
    
    Printf.printf "Loaded %d ZIP codes (simplified)\n" (Hashtbl.length zip_table);
    Ok ()
  with e ->
    Error (Printf.sprintf "Failed to load ZIP data: %s" (Printexc.to_string e))

let state_from_zip_code zip_code =
  let clean_zip = 
    if String.length zip_code >= 5 then
      String.sub zip_code 0 5
    else
      zip_code
  in
  
  match Hashtbl.find_opt zip_table clean_zip with
  | Some zip_info -> Some (state_of_string zip_info.state)
  | None -> None

let is_valid_zip_code zip_code =
  let clean_zip = 
    if String.length zip_code >= 5 then
      String.sub zip_code 0 5
    else
      zip_code
  in
  Hashtbl.mem zip_table clean_zip

let get_zip_info zip_code =
  let clean_zip = 
    if String.length zip_code >= 5 then
      String.sub zip_code 0 5
    else
      zip_code
  in
  Hashtbl.find_opt zip_table clean_zip

let ensure_loaded () =
  if Hashtbl.length zip_table = 0 then
    match load_zip_data () with
    | Ok () -> ()
    | Error msg -> failwith msg
  else
    ()

================
File: lib/visualizer/ast_analyzer.ml
================
open Ppxlib

(** Type representing a function definition with metadata *)
type function_info = {
  name : string;
  location : Location.t;
  start_line : int;
  end_line : int;
  source_code : string;
  parameters : (string * string option) list; (* (name, type_annotation) *)
  doc_comment : string option;
  complexity_score : int;
  calls : string list;
  is_recursive : bool;
  module_path : string list;
  return_type : string option;
  file : string; (* Add file tracking *)
}

(** Type representing the complete analysis result *)
type analysis_result = {
  functions : function_info list;
  call_graph : (string * string) list;
  modules : string list;
  errors : string list;
}

(** Extract documentation from attributes and preceding comments *)
let extract_doc_attribute attrs =
  let find_doc_attr attr =
    match attr.attr_name.txt with
    | "ocaml.doc" -> 
        (match attr.attr_payload with
         | PStr [{pstr_desc = Pstr_eval ({pexp_desc = Pexp_constant (Pconst_string (doc, _, _)); _}, _); _}] ->
             Some doc
         | _ -> None)
    | _ -> None
  in
  List.find_map find_doc_attr attrs

(** Extract source code from location and file content *)
let extract_source_code content location =
  let lines = String.split_on_char '\n' content in
  let start_line = location.loc_start.pos_lnum in
  let end_line = location.loc_end.pos_lnum in
  let start_char = location.loc_start.pos_cnum - location.loc_start.pos_bol in
  let end_char = location.loc_end.pos_cnum - location.loc_end.pos_bol in
  
  if start_line = end_line then
    (* Single line *)
    let line = List.nth lines (start_line - 1) in
    String.sub line start_char (end_char - start_char)
  else
    (* Multiple lines *)
    let selected_lines = 
      List.mapi (fun i line ->
        let line_num = i + 1 in
        if line_num < start_line || line_num > end_line then
          None
        else if line_num = start_line then
          Some (String.sub line start_char (String.length line - start_char))
        else if line_num = end_line then
          Some (String.sub line 0 end_char)
        else
          Some line
      ) lines
      |> List.filter_map (fun x -> x)
    in
    String.concat "\n" selected_lines

(** Calculate cyclomatic complexity *)
let calculate_complexity expr =
  let complexity = ref 1 in
  let rec traverse expr =
    match expr.pexp_desc with
    | Pexp_ifthenelse (cond, then_expr, else_opt) ->
        incr complexity;
        traverse cond;
        traverse then_expr;
        Option.iter traverse else_opt
    | Pexp_match (expr, cases) ->
        complexity := !complexity + List.length cases - 1;
        traverse expr;
        List.iter (fun case -> traverse case.pc_rhs) cases
    | Pexp_try (expr, cases) ->
        complexity := !complexity + List.length cases;
        traverse expr;
        List.iter (fun case -> traverse case.pc_rhs) cases
    | Pexp_while (cond, body) ->
        incr complexity;
        traverse cond;
        traverse body
    | Pexp_for (_, start, stop, _, body) ->
        incr complexity;
        traverse start;
        traverse stop;
        traverse body
    | Pexp_function cases ->
        complexity := !complexity + List.length cases - 1;
        List.iter (fun case -> traverse case.pc_rhs) cases
    | Pexp_let (_, bindings, expr) ->
        List.iter (fun vb -> traverse vb.pvb_expr) bindings;
        traverse expr
    | Pexp_sequence (e1, e2) ->
        traverse e1;
        traverse e2
    | Pexp_apply (func, args) ->
        traverse func;
        List.iter (fun (_, arg) -> traverse arg) args
    | _ -> ()
  in
  traverse expr;
  !complexity

(** Extract function calls *)
let extract_calls expr =
  let calls = ref [] in
  let rec extract_from_expr expr =
    match expr.pexp_desc with
    | Pexp_apply ({pexp_desc = Pexp_ident {txt = Lident name; _}; _}, args) ->
        (* This is a function application - filter out operators *)
        let is_operator = String.length name <= 2 && String.for_all (fun c -> 
          c = '+' || c = '-' || c = '*' || c = '/' || c = '=' || c = '<' || c = '>' || 
          c = '!' || c = '&' || c = '|' || c = '^' || c = '%' || c = '@'
        ) name in
        if not is_operator then
          calls := name :: !calls;
        List.iter (fun (_, arg) -> extract_from_expr arg) args
    | Pexp_apply ({pexp_desc = Pexp_ident {txt = Ldot (_, name); _}; _}, args) ->
        (* Module.function application *)
        calls := name :: !calls;
        List.iter (fun (_, arg) -> extract_from_expr arg) args
    | Pexp_apply (func, args) ->
        extract_from_expr func;
        List.iter (fun (_, arg) -> extract_from_expr arg) args
    | Pexp_let (_, bindings, expr) ->
        List.iter (fun vb -> extract_from_expr vb.pvb_expr) bindings;
        extract_from_expr expr
    | Pexp_match (expr, cases) ->
        extract_from_expr expr;
        List.iter (fun case -> extract_from_expr case.pc_rhs) cases
    | Pexp_ifthenelse (cond, then_expr, else_opt) ->
        extract_from_expr cond;
        extract_from_expr then_expr;
        Option.iter extract_from_expr else_opt
    | Pexp_sequence (e1, e2) ->
        extract_from_expr e1;
        extract_from_expr e2
    | Pexp_try (expr, cases) ->
        extract_from_expr expr;
        List.iter (fun case -> extract_from_expr case.pc_rhs) cases
    | _ -> ()
  in
  extract_from_expr expr;
  List.rev !calls |> List.sort_uniq String.compare

(** Enhanced parameter extraction with type information *)
let extract_parameters pattern =
  let rec extract_pattern_names pattern =
    match pattern.ppat_desc with
    | Ppat_var {txt; _} -> [(txt, None)]
    | Ppat_constraint (inner_pattern, core_type) ->
        let names = extract_pattern_names inner_pattern in
        List.map (fun (name, _) -> (name, Some (string_of_core_type core_type))) names
    | Ppat_tuple patterns ->
        List.concat_map extract_pattern_names patterns
    | Ppat_record (fields, _) ->
        List.concat_map (fun (_, pattern) -> extract_pattern_names pattern) fields
    | _ -> []
  and string_of_core_type core_type =
    (* Simple type to string conversion - can be enhanced *)
    match core_type.ptyp_desc with
    | Ptyp_constr ({txt = Lident name; _}, []) -> name
    | Ptyp_constr ({txt = Ldot (_, name); _}, []) -> name
    | Ptyp_arrow (_, _, _) -> "function"
    | _ -> "unknown"
  in
  extract_pattern_names pattern

(** Process a value binding *)
let process_value_binding filename content module_path binding =
  match binding.pvb_pat.ppat_desc with
  | Ppat_var {txt = name; _} ->
      let doc = extract_doc_attribute binding.pvb_attributes in
      (* Extract the actual function body for analysis *)
      let rec get_function_body expr =
        match expr.pexp_desc with
        | Pexp_fun (_, _, _, body) -> get_function_body body
        | _ -> expr
      in
      let body_expr = get_function_body binding.pvb_expr in
      let calls = extract_calls body_expr in
      let complexity = calculate_complexity body_expr in
      let source_code = extract_source_code content binding.pvb_loc in
      let start_line = binding.pvb_loc.loc_start.pos_lnum in
      let end_line = binding.pvb_loc.loc_end.pos_lnum in
      let parameters = 
        let rec extract_fun_params = function
          | {pexp_desc = Pexp_fun (_, _, pattern, body); _} ->
              extract_parameters pattern @ extract_fun_params body
          | _ -> []
        in
        extract_fun_params binding.pvb_expr
      in
      let return_type = 
        let string_of_core_type core_type =
          match core_type.ptyp_desc with
          | Ptyp_constr ({txt = Lident name; _}, []) -> name
          | Ptyp_constr ({txt = Ldot (_, name); _}, []) -> name
          | Ptyp_arrow (_, _, return_type) -> string_of_core_type return_type
          | _ -> "unknown"
        in
        match binding.pvb_expr.pexp_desc with
        | Pexp_constraint (_, core_type) -> Some (string_of_core_type core_type)
        | _ -> None
      in
      Some {
        name;
        location = binding.pvb_loc;
        start_line;
        end_line;
        source_code;
        parameters;
        doc_comment = doc;
        complexity_score = complexity;
        calls;
        is_recursive = false;
        module_path;
        return_type;
        file = filename;
      }
  | _ -> None

(** Analyze a structure item *)
let rec analyze_structure_item filename content module_path item =
  match item.pstr_desc with
  | Pstr_value (rec_flag, bindings) ->
      let functions = List.filter_map (process_value_binding filename content module_path) bindings in
      let is_recursive = match rec_flag with Recursive -> true | Nonrecursive -> false in
      List.map (fun f -> {f with is_recursive}) functions
  | Pstr_module {pmb_name = {txt; _}; pmb_expr; _} ->
      (* Handle module definitions *)
      let module_name = Option.value txt ~default:"_" in
      let new_module_path = module_path @ [module_name] in
      analyze_module_expr filename content new_module_path pmb_expr
  | _ -> []

and analyze_module_expr filename content module_path mexpr =
  match mexpr.pmod_desc with
  | Pmod_structure structure ->
      List.concat_map (analyze_structure_item filename content module_path) structure
  | _ -> []

(** Main analysis function *)
let analyze_file filename =
  try
    let ic = open_in filename in
    let content = really_input_string ic (in_channel_length ic) in
    close_in ic;
    let lexbuf = Lexing.from_string content in
    let ast = Ppxlib.Parse.implementation lexbuf in
    let functions = List.concat_map (analyze_structure_item filename content []) ast in
    let call_graph = 
      List.concat_map (fun f -> 
        List.map (fun callee -> (f.name, callee)) f.calls
      ) functions 
    in
    let modules = [Filename.basename filename] in
    {functions; call_graph; modules; errors = []}
  with
  | exn -> 
      {functions = []; call_graph = []; modules = []; errors = [Printexc.to_string exn]}

(** Analyze multiple files *)
let analyze_files filenames =
  let results = List.map analyze_file filenames in
  let all_functions = List.concat_map (fun r -> r.functions) results in
  let all_call_graph = List.concat_map (fun r -> r.call_graph) results in
  let all_errors = List.concat_map (fun r -> r.errors) results in
  {functions = all_functions; call_graph = all_call_graph; modules = []; errors = all_errors}

(** Find functions that call a specific function *)
let find_callers target_function analysis =
  analysis.call_graph
  |> List.filter (fun (_, callee) -> callee = target_function)
  |> List.map fst
  |> List.sort_uniq String.compare

(** Find functions called by a specific function *)
let find_callees source_function analysis =
  analysis.call_graph
  |> List.filter (fun (caller, _) -> caller = source_function)
  |> List.map snd
  |> List.sort_uniq String.compare

(** Get function information by name *)
let get_function_info name analysis =
  List.find_opt (fun f -> f.name = name) analysis.functions

================
File: lib/visualizer/call_graph.ml
================
open Ast_analyzer

(** Simple graph representation using adjacency lists *)
type simple_graph = {
  vertices : function_info list;
  edges : (string * string) list; (* (source, target) *)
}

(** Function metrics type *)
type function_metrics = {
  in_degree : int;
  out_degree : int;
  dependency_count : int;
  reverse_dependency_count : int;
}

(** Enhanced call graph with metadata *)
type enhanced_call_graph = {
  graph : simple_graph;
  function_map : (string, function_info) Hashtbl.t;
  entry_points : function_info list;
  cycles : function_info list list;
  complexity_stats : (int * int * float);
}

(** Build call graph from analysis result *)
let build_call_graph analysis =
  let function_map = Hashtbl.create (List.length analysis.functions) in
  
  List.iter (fun func ->
    Hashtbl.add function_map func.name func
  ) analysis.functions;
  
  let graph = {
    vertices = analysis.functions;
    edges = analysis.call_graph;
  } in
  
  graph, function_map

(** Calculate in-degree for a function *)
let in_degree graph function_name =
  List.fold_left (fun acc (_, target) ->
    if target = function_name then acc + 1 else acc
  ) 0 graph.edges

(** Calculate out-degree for a function *)
let out_degree graph function_name =
  List.fold_left (fun acc (source, _) ->
    if source = function_name then acc + 1 else acc
  ) 0 graph.edges

(** Find entry points *)
let find_entry_points graph function_map =
  Hashtbl.fold (fun _ func acc ->
    if in_degree graph func.name = 0 then func :: acc else acc
  ) function_map []

(** Calculate complexity statistics *)
let calculate_complexity_stats functions =
  let complexities = List.map (fun f -> f.complexity_score) functions in
  match complexities with
  | [] -> (0, 0, 0.0)
  | _ ->
      let min_complexity = List.fold_left min (List.hd complexities) complexities in
      let max_complexity = List.fold_left max (List.hd complexities) complexities in
      let avg_complexity = 
        float_of_int (List.fold_left (+) 0 complexities) /. float_of_int (List.length complexities)
      in
      (min_complexity, max_complexity, avg_complexity)

(** Create enhanced call graph *)
let create_enhanced_call_graph analysis =
  let graph, function_map = build_call_graph analysis in
  let entry_points = find_entry_points graph function_map in
  let cycles = [] in
  let complexity_stats = calculate_complexity_stats analysis.functions in
  {
    graph;
    function_map;
    entry_points;
    cycles;
    complexity_stats;
  }

(** Get function dependencies *)
let get_dependencies enhanced_graph function_name =
  let rec get_callees visited name =
    if List.mem name visited then []
    else
      let new_visited = name :: visited in
      let direct_callees = 
        List.fold_left (fun acc (source, target) ->
          if source = name then target :: acc else acc
        ) [] enhanced_graph.graph.edges
      in
      let transitive_callees = 
        List.concat_map (get_callees new_visited) direct_callees
      in
      direct_callees @ transitive_callees
  in
  let callees = get_callees [] function_name in
  List.filter_map (fun name ->
    Hashtbl.find_opt enhanced_graph.function_map name
  ) (List.sort_uniq String.compare callees)

(** Get reverse dependencies *)
let get_reverse_dependencies enhanced_graph function_name =
  let rec get_callers visited name =
    if List.mem name visited then []
    else
      let new_visited = name :: visited in
      let direct_callers = 
        List.fold_left (fun acc (source, target) ->
          if target = name then source :: acc else acc
        ) [] enhanced_graph.graph.edges
      in
      let transitive_callers = 
        List.concat_map (get_callers new_visited) direct_callers
      in
      direct_callers @ transitive_callers
  in
  let callers = get_callers [] function_name in
  List.filter_map (fun name ->
    Hashtbl.find_opt enhanced_graph.function_map name
  ) (List.sort_uniq String.compare callers)

(** Get function metrics *)
let get_function_metrics enhanced_graph function_name =
  match Hashtbl.find_opt enhanced_graph.function_map function_name with
  | Some func ->
      let in_deg = in_degree enhanced_graph.graph func.name in
      let out_deg = out_degree enhanced_graph.graph func.name in
      let dependencies = get_dependencies enhanced_graph function_name in
      let reverse_deps = get_reverse_dependencies enhanced_graph function_name in
      let metrics = {
        in_degree = in_deg;
        out_degree = out_deg;
        dependency_count = List.length dependencies;
        reverse_dependency_count = List.length reverse_deps;
      } in
      (Some func, metrics)
  | None -> 
      let empty_metrics = {
        in_degree = 0; 
        out_degree = 0; 
        dependency_count = 0; 
        reverse_dependency_count = 0;
      } in
      (None, empty_metrics)

================
File: lib/visualizer/doc_extractor.ml
================
open Ast_analyzer

(** Type representing parsed documentation *)
type parsed_doc = {
  summary : string option;
  description : string option;
  parameters : (string * string) list; (* (param_name, description) *)
  returns : string option;
  examples : string list;
  see_also : string list;
  since : string option;
  deprecated : string option;
  raises : (string * string) list; (* (exception, description) *)
  tags : (string * string) list; (* Custom tags *)
}

(** Empty documentation *)
let empty_doc = {
  summary = None;
  description = None;
  parameters = [];
  returns = None;
  examples = [];
  see_also = [];
  since = None;
  deprecated = None;
  raises = [];
  tags = [];
}

(** Simple documentation comment parser *)
let parse_simple_doc_comment comment_text =
  let lines = String.split_on_char '\n' comment_text in
  let first_line = match lines with
    | [] -> ""
    | hd :: _ -> String.trim hd
  in
  let summary = if String.length first_line > 0 then Some first_line else None in
  let description = if List.length lines > 1 then Some (String.concat "\n" (List.tl lines)) else None in
  {
    summary;
    description;
    parameters = [];
    returns = None;
    examples = [];
    see_also = [];
    since = None;
    deprecated = None;
    raises = [];
    tags = [];
  }

(** Parse a single documentation comment *)
let parse_doc_comment comment_text =
  try
    Some (parse_simple_doc_comment comment_text)
  with
  | _ -> None

(** Extract documentation for a function *)
let extract_function_doc func =
  match func.doc_comment with
  | Some comment -> parse_doc_comment comment
  | None -> Some empty_doc

(** Extract all documentation from analysis result *)
let extract_all_docs analysis =
  List.fold_left (fun acc func ->
    match extract_function_doc func with
    | Some doc -> (func.name, doc) :: acc
    | None -> (func.name, empty_doc) :: acc
  ) [] analysis.functions

(** HTML escape utility *)
module Html = struct
  let escape s =
    let buffer = Buffer.create (String.length s * 2) in
    String.iter (function
      | '<' -> Buffer.add_string buffer "&lt;"
      | '>' -> Buffer.add_string buffer "&gt;"
      | '&' -> Buffer.add_string buffer "&amp;"
      | '"' -> Buffer.add_string buffer "&quot;"
      | '\'' -> Buffer.add_string buffer "&#x27;"
      | c -> Buffer.add_char buffer c
    ) s;
    Buffer.contents buffer
end

(** Format documentation as HTML *)
let format_doc_as_html doc =
  let buffer = Buffer.create 1024 in
  
  (* Summary *)
  (match doc.summary with
   | Some summary -> 
       Buffer.add_string buffer "<div class=\"doc-summary\">";
       Buffer.add_string buffer (Html.escape summary);
       Buffer.add_string buffer "</div>\n"
   | None -> ());
  
  (* Description *)
  (match doc.description with
   | Some desc -> 
       Buffer.add_string buffer "<div class=\"doc-description\">";
       Buffer.add_string buffer (Html.escape desc);
       Buffer.add_string buffer "</div>\n"
   | None -> ());
  
  (* Parameters *)
  if List.length doc.parameters > 0 then begin
    Buffer.add_string buffer "<div class=\"doc-parameters\">\n";
    Buffer.add_string buffer "<h4>Parameters:</h4>\n<ul>\n";
    List.iter (fun (param, desc) ->
      Buffer.add_string buffer "<li><code>";
      Buffer.add_string buffer (Html.escape param);
      Buffer.add_string buffer "</code> - ";
      Buffer.add_string buffer (Html.escape desc);
      Buffer.add_string buffer "</li>\n"
    ) doc.parameters;
    Buffer.add_string buffer "</ul>\n</div>\n"
  end;
  
  (* Returns *)
  (match doc.returns with
   | Some ret -> 
       Buffer.add_string buffer "<div class=\"doc-returns\">\n";
       Buffer.add_string buffer "<h4>Returns:</h4>\n<p>";
       Buffer.add_string buffer (Html.escape ret);
       Buffer.add_string buffer "</p>\n</div>\n"
   | None -> ());
  
  (* Examples *)
  if List.length doc.examples > 0 then begin
    Buffer.add_string buffer "<div class=\"doc-examples\">\n";
    Buffer.add_string buffer "<h4>Examples:</h4>\n";
    List.iter (fun example ->
      Buffer.add_string buffer "<pre><code>";
      Buffer.add_string buffer (Html.escape example);
      Buffer.add_string buffer "</code></pre>\n"
    ) doc.examples
  end;
  
  (* Raises *)
  if List.length doc.raises > 0 then begin
    Buffer.add_string buffer "<div class=\"doc-raises\">\n";
    Buffer.add_string buffer "<h4>Raises:</h4>\n<ul>\n";
    List.iter (fun (exc, desc) ->
      Buffer.add_string buffer "<li><code>";
      Buffer.add_string buffer (Html.escape exc);
      Buffer.add_string buffer "</code> - ";
      Buffer.add_string buffer (Html.escape desc);
      Buffer.add_string buffer "</li>\n"
    ) doc.raises;
    Buffer.add_string buffer "</ul>\n</div>\n"
  end;
  
  (* Since/Deprecated *)
  (match doc.since with
   | Some since -> 
       Buffer.add_string buffer "<div class=\"doc-since\">Since: ";
       Buffer.add_string buffer (Html.escape since);
       Buffer.add_string buffer "</div>\n"
   | None -> ());
  
  (match doc.deprecated with
   | Some deprecated -> 
       Buffer.add_string buffer "<div class=\"doc-deprecated\">⚠️ Deprecated: ";
       Buffer.add_string buffer (Html.escape deprecated);
       Buffer.add_string buffer "</div>\n"
   | None -> ());
  
  Buffer.contents buffer

(** Convert documentation to markdown *)
let format_doc_as_markdown doc =
  let buffer = Buffer.create 1024 in
  
  (* Summary *)
  (match doc.summary with
   | Some summary -> 
       Buffer.add_string buffer summary;
       Buffer.add_string buffer "\n\n"
   | None -> ());
  
  (* Description *)
  (match doc.description with
   | Some desc -> 
       Buffer.add_string buffer desc;
       Buffer.add_string buffer "\n\n"
   | None -> ());
  
  (* Parameters *)
  if List.length doc.parameters > 0 then begin
    Buffer.add_string buffer "## Parameters\n\n";
    List.iter (fun (param, desc) ->
      Buffer.add_string buffer "- `";
      Buffer.add_string buffer param;
      Buffer.add_string buffer "` - ";
      Buffer.add_string buffer desc;
      Buffer.add_string buffer "\n"
    ) doc.parameters;
    Buffer.add_string buffer "\n"
  end;
  
  (* Returns *)
  (match doc.returns with
   | Some ret -> 
       Buffer.add_string buffer "## Returns\n\n";
       Buffer.add_string buffer ret;
       Buffer.add_string buffer "\n\n"
   | None -> ());
  
  (* Examples *)
  if List.length doc.examples > 0 then begin
    Buffer.add_string buffer "## Examples\n\n";
    List.iter (fun example ->
      Buffer.add_string buffer "```ocaml\n";
      Buffer.add_string buffer example;
      Buffer.add_string buffer "\n```\n\n"
    ) doc.examples
  end;
  
  Buffer.contents buffer

================
File: lib/visualizer/json_serializer.ml
================
open Yojson.Safe
open Ast_analyzer
open Call_graph
open Doc_extractor

(** Convert Location.t to JSON *)
let location_to_json loc =
  `Assoc [
    ("file", `String loc.Location.loc_start.pos_fname);
    ("start_line", `Int loc.Location.loc_start.pos_lnum);
    ("start_col", `Int (loc.Location.loc_start.pos_cnum - loc.Location.loc_start.pos_bol));
    ("end_line", `Int loc.Location.loc_end.pos_lnum);
    ("end_col", `Int (loc.Location.loc_end.pos_cnum - loc.Location.loc_end.pos_bol));
  ]

(** Convert parsed documentation to JSON *)
let doc_to_json doc =
  let option_to_json f = function
    | Some v -> f v
    | None -> `Null
  in
  let string_pairs_to_json pairs =
    `List (List.map (fun (k, v) -> `Assoc [("name", `String k); ("description", `String v)]) pairs)
  in
  `Assoc [
    ("summary", option_to_json (fun s -> `String s) doc.summary);
    ("description", option_to_json (fun s -> `String s) doc.description);
    ("parameters", string_pairs_to_json doc.parameters);
    ("returns", option_to_json (fun s -> `String s) doc.returns);
    ("examples", `List (List.map (fun s -> `String s) doc.examples));
    ("see_also", `List (List.map (fun s -> `String s) doc.see_also));
    ("since", option_to_json (fun s -> `String s) doc.since);
    ("deprecated", option_to_json (fun s -> `String s) doc.deprecated);
    ("raises", string_pairs_to_json doc.raises);
    ("tags", string_pairs_to_json doc.tags);
  ]

(** Convert function info to JSON *)
let function_to_json func docs_map =
  let doc = match List.assoc_opt func.name docs_map with
    | Some d -> d
    | None -> empty_doc
  in
  let parameters_json = List.map (fun (name, type_opt) ->
    match type_opt with
    | Some typ -> `Assoc [("name", `String name); ("type", `String typ)]
    | None -> `Assoc [("name", `String name); ("type", `Null)]
  ) func.parameters in
  let return_type_json = match func.return_type with
    | Some typ -> `String typ
    | None -> `Null
  in
  `Assoc [
    ("name", `String func.name);
    ("location", location_to_json func.location);
    ("start_line", `Int func.start_line);
    ("end_line", `Int func.end_line);
    ("source_code", `String func.source_code);
    ("parameters", `List parameters_json);
    ("return_type", return_type_json);
    ("complexity_score", `Int func.complexity_score);
    ("calls", `List (List.map (fun c -> `String c) func.calls));
    ("is_recursive", `Bool func.is_recursive);
    ("module_path", `List (List.map (fun m -> `String m) func.module_path));
    ("documentation", doc_to_json doc);
    ("file", `String func.file);
  ]

(** Convert enhanced call graph to JSON with metrics *)
let enhanced_call_graph_to_json enhanced_graph docs_map =
  let functions_json = 
    enhanced_graph.graph.vertices
    |> List.map (fun func -> function_to_json func docs_map)
  in
  
  let edges_json = 
    enhanced_graph.graph.edges
    |> List.map (fun (source, target) ->
        `Assoc [
          ("source", `String source);
          ("target", `String target);
        ])
  in
  
  let entry_points_json = 
    `List (List.map (fun f -> `String f.name) enhanced_graph.entry_points)
  in
  
  let cycles_json = 
    `List (List.map (fun cycle ->
      `List (List.map (fun f -> `String f.name) cycle)
    ) enhanced_graph.cycles)
  in
  
  let (min_complexity, max_complexity, avg_complexity) = enhanced_graph.complexity_stats in
  let complexity_stats_json = 
    `Assoc [
      ("min", `Int min_complexity);
      ("max", `Int max_complexity);
      ("average", `Float avg_complexity);
    ]
  in
  
  `Assoc [
    ("functions", `List functions_json);
    ("edges", `List edges_json);
    ("entry_points", entry_points_json);
    ("cycles", cycles_json);
    ("complexity_stats", complexity_stats_json);
  ]

(** Generate Mermaid diagram syntax *)
let generate_mermaid_diagram enhanced_graph ?(max_complexity = None) ?(show_modules = true) () =
  let buffer = Buffer.create 4096 in
  
  Buffer.add_string buffer "%%{init: {\"flowchart\": {\"defaultRenderer\": \"elk\"}} }%%\n";
  Buffer.add_string buffer "flowchart TD\n";
  
  let functions = enhanced_graph.graph.vertices in
  List.iter (fun func ->
    let should_include = match max_complexity with
      | Some threshold -> func.complexity_score <= threshold
      | None -> true
    in
    if should_include then begin
      let node_id = func.name in
      let module_prefix = if show_modules && List.length func.module_path > 0 then
        String.concat "." func.module_path ^ "."
      else ""
      in
      let display_name = module_prefix ^ func.name in
      
      let complexity_class = match func.complexity_score with
        | score when score > 10 -> "high-complexity"
        | score when score > 5 -> "medium-complexity"
        | _ -> "low-complexity"
      in
      
      let recursive_indicator = if func.is_recursive then " 🔄" else "" in
      
      Buffer.add_string buffer (Printf.sprintf "    %s[\"%s%s\"]:::%s\n" 
        node_id display_name recursive_indicator complexity_class);
    end
  ) functions;
  
  List.iter (fun (source, target) ->
    let src_func = List.find_opt (fun f -> f.name = source) functions in
    let dst_func = List.find_opt (fun f -> f.name = target) functions in
    let src_include = match max_complexity, src_func with
      | Some threshold, Some f -> f.complexity_score <= threshold
      | None, Some _ -> true
      | _ -> false
    in
    let dst_include = match max_complexity, dst_func with
      | Some threshold, Some f -> f.complexity_score <= threshold
      | None, Some _ -> true
      | _ -> false
    in
    if src_include && dst_include then
      Buffer.add_string buffer (Printf.sprintf "    %s --> %s\n" source target)
  ) enhanced_graph.graph.edges;
  
  List.iter (fun func ->
    let should_include = match max_complexity with
      | Some threshold -> func.complexity_score <= threshold
      | None -> true
    in
    if should_include then
      Buffer.add_string buffer (Printf.sprintf "    click %s callback \"Show details for %s\"\n" 
        func.name func.name)
  ) functions;
  
  Buffer.add_string buffer "\n";
  Buffer.add_string buffer "    classDef low-complexity fill:#d4edda,stroke:#28a745,stroke-width:2px\n";
  Buffer.add_string buffer "    classDef medium-complexity fill:#fff3cd,stroke:#ffc107,stroke-width:2px\n";
  Buffer.add_string buffer "    classDef high-complexity fill:#f8d7da,stroke:#dc3545,stroke-width:2px\n";
  
  Buffer.contents buffer

(** Generate complete visualization data package *)
let generate_visualization_data analysis =
  let docs_map = extract_all_docs analysis in
  let enhanced_graph = create_enhanced_call_graph analysis in
  
  let main_diagram = generate_mermaid_diagram enhanced_graph () in
  
  `Assoc [
    ("analysis", enhanced_call_graph_to_json enhanced_graph docs_map);
    ("diagrams", `Assoc [
      ("main", `String main_diagram);
    ]);
    ("metadata", `Assoc [
      ("total_functions", `Int (List.length analysis.functions));
      ("total_modules", `Int (List.length analysis.modules));
      ("entry_point_count", `Int (List.length enhanced_graph.entry_points));
      ("cycle_count", `Int (List.length enhanced_graph.cycles));
      ("generated_at", `String (Printf.sprintf "%.0f" (Unix.time ())));
    ]);
  ]

(** Save visualization data to file *)
let save_visualization_data analysis output_file =
  let data = generate_visualization_data analysis in
  let json_string = pretty_to_string data in
  let oc = open_out output_file in
  output_string oc json_string;
  close_out oc;
  Printf.printf "Visualization data saved to %s\n" output_file

(** Generate source code data for viewer *)
let generate_source_data filenames =
  let source_map = List.fold_left (fun acc filename ->
    try
      let content = 
        let ic = open_in filename in
        let content = really_input_string ic (in_channel_length ic) in
        close_in ic;
        content
      in
      (filename, content) :: acc
    with
    | _ -> acc
  ) [] filenames in
  
  `Assoc [
    ("files", `Assoc (List.map (fun (filename, content) -> 
      (filename, `String content)
    ) source_map));
  ]

(** Complete export function *)
let export_complete_visualization filenames output_dir =
  let analysis = analyze_files filenames in
  
  (try Unix.mkdir output_dir 0o755 with Unix.Unix_error (Unix.EEXIST, _, _) -> ());
  
  let viz_file = Filename.concat output_dir "visualization.json" in
  save_visualization_data analysis viz_file;
  
  let source_data = generate_source_data filenames in
  let source_file = Filename.concat output_dir "source_data.json" in
  let oc = open_out source_file in
  output_string oc (pretty_to_string source_data);
  close_out oc;
  
  Printf.printf "Complete visualization data exported to %s/\n" output_dir;
  
  analysis

================
File: lib/scheduler.ml
================
module Date_time = Date_time
module Config = Config
module Types = Types
module Contact = Contact
module Email_scheduler = Email_scheduler
module Load_balancer = Load_balancer
module Simple_date = Simple_date
module Dsl = Dsl
module Date_calc = Date_calc
module Exclusion_window = Exclusion_window
module Zip_data = Zip_data
module Audit = Audit_simple

module Db = struct
  module Database = Database (* Use native SQLite for maximum performance *)
end

================
File: standalone_visualizer/visualizer_cli.ml
================
open Cmdliner
open Visualizer.Ast_analyzer
open Visualizer.Json_serializer

(** Take first n elements from a list *)
let rec take n = function
  | [] -> []
  | _ when n <= 0 -> []
  | x :: xs -> x :: take (n - 1) xs

(** Configuration for the visualizer *)
type config = {
  input_files : string list;
  output_dir : string;
  web_port : int option;
  serve : bool;
  verbose : bool;
  max_complexity : int option;
}

(** Default configuration *)
let default_config = {
  input_files = [];
  output_dir = "visualizer_output";
  web_port = None;
  serve = false;
  verbose = false;
  max_complexity = None;
}

(** Find OCaml files recursively in a directory *)
let rec find_ocaml_files dir =
  let open Unix in
  if Sys.is_directory dir then
    let files = Sys.readdir dir in
    Array.fold_left (fun acc file ->
      let full_path = Filename.concat dir file in
      if Sys.is_directory full_path then
        (find_ocaml_files full_path) @ acc
      else if Filename.check_suffix file ".ml" || Filename.check_suffix file ".mli" then
        full_path :: acc
      else
        acc
    ) [] files
  else
    [dir]

(** Collect all input files *)
let collect_input_files paths =
  List.concat_map (fun path ->
    if Sys.file_exists path then
      if Sys.is_directory path then
        find_ocaml_files path
      else
        [path]
    else begin
      Printf.eprintf "Warning: File or directory '%s' does not exist\n" path;
      []
    end
  ) paths

(** Copy web assets to output directory *)
let copy_web_assets output_dir =
  let web_files = [
    ("web/index.html", "index.html");
    ("web/visualizer.js", "visualizer.js");
  ] in
  
  List.iter (fun (src, dst) ->
    let dst_path = Filename.concat output_dir dst in
    if Sys.file_exists src then
      let content = 
        let ic = open_in src in
        let content = really_input_string ic (in_channel_length ic) in
        close_in ic;
        content
      in
      let oc = open_out dst_path in
      output_string oc content;
      close_out oc;
      Printf.printf "Copied %s -> %s\n" src dst_path
    else
      Printf.eprintf "Warning: Web asset '%s' not found\n" src
  ) web_files

(** Start a simple HTTP server *)
let start_server output_dir port =
  let open Unix in
  Printf.printf "Starting web server on port %d...\n" port;
  Printf.printf "Visit http://localhost:%d to view the visualization\n" port;
  
  (* Create a simple Python HTTP server command *)
  let server_cmd = Printf.sprintf "cd %s && python3 -m http.server %d" output_dir port in
  let exit_code = Sys.command server_cmd in
  if exit_code <> 0 then
    Printf.eprintf "Failed to start web server (exit code: %d)\n" exit_code

(** Print analysis summary *)
let print_summary analysis config =
  Printf.printf "\n=== OCaml Program Flow Analysis Summary ===\n";
  Printf.printf "Files analyzed: %d\n" (List.length config.input_files);
  Printf.printf "Functions found: %d\n" (List.length analysis.functions);
  Printf.printf "Modules found: %d\n" (List.length analysis.modules);
  
  if List.length analysis.errors > 0 then begin
    Printf.printf "\nErrors encountered:\n";
    List.iter (Printf.printf "  - %s\n") analysis.errors
  end;
  
  (* Print complexity statistics *)
  let complexities = List.map (fun f -> f.complexity_score) analysis.functions in
  if List.length complexities > 0 then begin
    let min_complexity = List.fold_left min (List.hd complexities) complexities in
    let max_complexity = List.fold_left max (List.hd complexities) complexities in
    let avg_complexity = 
      float_of_int (List.fold_left (+) 0 complexities) /. float_of_int (List.length complexities)
    in
    Printf.printf "\nComplexity Statistics:\n";
    Printf.printf "  Min: %d, Max: %d, Average: %.1f\n" min_complexity max_complexity avg_complexity;
  end;
  
  (* Print top-level functions by complexity *)
  let sorted_functions = 
    analysis.functions 
    |> List.sort (fun a b -> compare b.complexity_score a.complexity_score)
    |> (fun l -> if List.length l > 10 then take 10 l else l)
  in
  if List.length sorted_functions > 0 then begin
    Printf.printf "\nMost Complex Functions:\n";
    List.iter (fun f ->
      Printf.printf "  %s (complexity: %d, calls: %d)\n" 
        f.name f.complexity_score (List.length f.calls)
    ) sorted_functions
  end;
  
  Printf.printf "\nVisualization generated in: %s/\n" config.output_dir

(** Main analysis and generation function *)
let run_analysis config =
  if config.verbose then
    Printf.printf "Analyzing %d OCaml files...\n" (List.length config.input_files);
  
  (* Ensure opam environment is loaded *)
  let _ = Sys.command "eval $(opam env) 2>/dev/null" in
  
  (* Run the analysis *)
  let analysis = analyze_files config.input_files in
  
  if config.verbose then begin
    Printf.printf "Analysis complete. Found %d functions.\n" (List.length analysis.functions);
    if List.length analysis.errors > 0 then
      Printf.printf "Encountered %d errors during analysis.\n" (List.length analysis.errors)
  end;
  
  (* Generate visualization data *)
  let result = export_complete_visualization config.input_files config.output_dir in
  
  (* Copy web assets *)
  copy_web_assets config.output_dir;
  
  (* Print summary *)
  print_summary result config;
  
  (* Start web server if requested *)
  if config.serve then begin
    let port = Option.value config.web_port ~default:8000 in
    start_server config.output_dir port
  end else begin
    let port = Option.value config.web_port ~default:8000 in
    Printf.printf "To view the visualization, run:\n";
    Printf.printf "  cd %s && python3 -m http.server %d\n" config.output_dir port;
    Printf.printf "Then visit http://localhost:%d\n" port
  end

(** Command line argument definitions *)
let input_files =
  let doc = "OCaml source files or directories to analyze" in
  Arg.(non_empty & pos_all string [] & info [] ~docv:"FILES" ~doc)

let output_dir =
  let doc = "Output directory for visualization files" in
  Arg.(value & opt string default_config.output_dir & info ["o"; "output"] ~docv:"DIR" ~doc)

let web_port =
  let doc = "Port for the web server (default: 8000)" in
  Arg.(value & opt (some int) None & info ["p"; "port"] ~docv:"PORT" ~doc)

let serve =
  let doc = "Start a web server after generating the visualization" in
  Arg.(value & flag & info ["s"; "serve"] ~doc)

let verbose =
  let doc = "Enable verbose output" in
  Arg.(value & flag & info ["v"; "verbose"] ~doc)

let max_complexity =
  let doc = "Filter functions by maximum complexity" in
  Arg.(value & opt (some int) None & info ["c"; "max-complexity"] ~docv:"N" ~doc)

(** Build configuration from command line arguments *)
let build_config input_files output_dir web_port serve verbose max_complexity =
  let collected_files = collect_input_files input_files in
  if List.length collected_files = 0 then begin
    Printf.eprintf "Error: No OCaml files found to analyze\n";
    exit 1
  end;
  {
    input_files = collected_files;
    output_dir;
    web_port;
    serve;
    verbose;
    max_complexity;
  }

(** Main command definition *)
let main_cmd =
  let doc = "Generate interactive visualizations for OCaml program flow" in
  let man = [
    `S Manpage.s_description;
    `P "The OCaml Program Flow Visualizer analyzes OCaml source code to extract function definitions, call relationships, and documentation. It generates an interactive web-based visualization that allows users to explore the code structure dynamically.";
    `S Manpage.s_examples;
    `P "Analyze a single file:";
    `Pre "  $(tname) src/main.ml";
    `P "Analyze all files in a directory:";
    `Pre "  $(tname) src/";
    `P "Generate visualization and start web server:";
    `Pre "  $(tname) --serve --port 9000 src/";
    `P "Filter by complexity:";
    `Pre "  $(tname) --max-complexity 10 src/";
    `S Manpage.s_see_also;
    `P "For more information, see the project documentation.";
  ] in
  Term.(const run_analysis $ (const build_config $ input_files $ output_dir $ web_port $ serve $ verbose $ max_complexity)),
  Cmd.info "ocaml-visualizer" ~version:"1.0.0" ~doc ~man

(** Main entry point *)
let () =
  exit (Cmd.eval (Cmd.v (snd main_cmd) (fst main_cmd)))



================================================================
End of Codebase
================================================================
